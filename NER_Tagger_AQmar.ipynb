{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iWElrVtJHP7q",
        "outputId": "63efc6e0-242d-4251-df1d-6525fa7dfcbe"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install h5py==2.10.0\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install seqeval\n",
        "!pip install flair\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras \n",
        "from math import nan \n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras_contrib.layers import CRF\n",
        "from future.utils import iteritems\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical # tensor flow vesion 1 \n",
        "from keras.models import Model, Input\n",
        "import tensorflow as tf\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from keras.initializers import RandomUniform\n",
        "from keras.layers import TimeDistributed,Conv1D,Conv2D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional,MaxPooling1D,Flatten,concatenate,MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "#!pip install keras-self-attention\n",
        "#from keras_self_attention import SeqSelfAttention\n",
        "from keras.layers.merge import Concatenate\n",
        "import flair.datasets\n",
        "from flair.data import Sentence\n",
        "from flair.embeddings import WordEmbeddings,TransformerWordEmbeddings,StackedEmbeddings, CharacterEmbeddings, FlairEmbeddings\n",
        "import sklearn \n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from keras.models import Model, model_from_json\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 15.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-3192zsbd\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-3192zsbd\n",
            "Requirement already satisfied: keras in /tensorflow-1.15.2/python3.7 (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101077 sha256=7a232d9c823caa26626349d68c55393e7f84dc425d3a12f8a984df3cf610d964\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xvanc3rq/wheels/bb/1f/f2/b57495012683b6b20bbae94a3915ec79753111452d79886abc\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=87e9e45185c8e5e4cd1f1ba4ac5f920b4b3c281b0267d02067891ec39f18649e\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Collecting flair\n",
            "  Downloading flair-0.11.1-py3-none-any.whl (401 kB)\n",
            "\u001b[K     |████████████████████████████████| 401 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.64.0)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.0.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 18.6 MB/s \n",
            "\u001b[?25hCollecting conllu>=4.0\n",
            "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 42.9 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.11.0+cu113)\n",
            "Collecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Collecting gdown==3.12.2\n",
            "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Collecting pptree\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting more-itertools~=8.8.0\n",
            "  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting hyperopt>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 57.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.14.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (5.2.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (1.3.0)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 71.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (4.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.4.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 46.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 60.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 12.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Building wheels for collected packages: gdown, mpld3, overrides, sqlitedict, langdetect, pptree, wikipedia-api\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9692 sha256=9eae4c6da026393bdfdf6635927457d4f146eab2d95fef639759c5eef938f228\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=f405fc01d206792f4d47936f5e200b52cd3e145eae351aa5b4daf36c6c3e27da\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=3a966dbe3904098f91156a5612b18ff12b7ba6e944681536731c3c4423c766b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15736 sha256=2d4ffba0c7d6c210dcddd5edf4a7007e2c1f34078a0aa3d45a31f15615519c36\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/dd/2e/0ed4a25cb73fc30c7ea8d10b50acb7226175736067e40a7ea3\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=538ccecef2e1ca7b7f1517fd9b2e5e4fc11ab820eee63dcaeb608ac94766d994\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=5b8739ff0c264282c184ca1812355bb2c45d91144cf083d9185e76e7a369e2ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/e8/7d/a9c3c19b4722608a0d8b05a38c36bc3f230c43becd2a46794b\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=37d51081df34f023cfba94eef9a6aaaaadcb67b8606004bb4cf0e667a993f380\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built gdown mpld3 overrides sqlitedict langdetect pptree wikipedia-api\n",
            "Installing collected packages: requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, sacremoses, py4j, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, pptree, mpld3, more-itertools, langdetect, konoha, janome, hyperopt, gdown, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.3\n",
            "    Uninstalling importlib-metadata-4.11.3:\n",
            "      Successfully uninstalled importlib-metadata-4.11.3\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 8.12.0\n",
            "    Uninstalling more-itertools-8.12.0:\n",
            "      Successfully uninstalled more-itertools-8.12.0\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lucid 0.3.10 requires umap-learn, which is not installed.\n",
            "lucid 0.3.10 requires numpy<=1.19, but you have numpy 1.21.6 which is incompatible.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.4.1 deprecated-1.2.13 flair-0.11.1 ftfy-6.1.1 gdown-3.12.2 huggingface-hub-0.5.1 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.5 pyyaml-6.0 requests-2.27.1 sacremoses-0.0.49 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.0.0 tokenizers-0.12.1 transformers-4.18.0 wikipedia-api-0.5.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKTQSUA4HX41",
        "outputId": "d9dda6c6-21f0-4a7d-9d24-19ee7df81f0f"
      },
      "source": [
        "print(\"keras version: \",keras.__version__)\n",
        "print(\"tensorflow version: \",tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keras version:  2.3.1\n",
            "tensorflow version:  1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbVwpkYDIE7N"
      },
      "source": [
        "#reading data\n",
        "\n",
        "def load_data(fix_length, length):\n",
        "\n",
        "  split_idx=55575\n",
        "  #split_idx=135047\n",
        "  data = pd.read_csv('/content/drive/MyDrive/Ali lotfy/Colab Notebooks/paper/Aqmar_fixed_features.csv')\n",
        "  if(fix_length):\n",
        "    for i, row in data.iterrows():\n",
        "      data.at[i,'sentence_idx']=i//length\n",
        "  for  i, row in data.iterrows():\n",
        "    if data.at[i,\"word\"][-1] in ['*', ',', '.', ':', '=', '،', '؛' ] and len( data.at[i,\"word\"]) >1 : #remove punctuation if connected to word\n",
        "      data.at[i, \"word\"]= data.at[i, \"word\"][0:-1]\n",
        "    if 'ـ' in data.at[i,\"word\"] and len( data.at[i,\"word\"]) >2 : #remove tatweel تطويــــل\n",
        "      data.at[i, \"word\"]= data.at[i, \"word\"] .replace(\"ـ\", \"\")\n",
        "\n",
        "  data_tr=data[0:split_idx]\n",
        "  data_te=data[split_idx:]\n",
        "  \n",
        "  return data, data_tr, data_te"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqK5dIrTIehe"
      },
      "source": [
        "\n",
        "# every sentence in a an array\n",
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.n_sent = 1\n",
        "        self.dataset = dataset\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n",
        "                                                        s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "def find_last(list , word, sent_len):\n",
        "  l= sent_len-1\n",
        "  while True:\n",
        "    if list[l][0]==word:\n",
        "      return l\n",
        "    if l < int(sent_len*3/5):\n",
        "      return sent_len-1\n",
        "    else:\n",
        "      l-=1\n",
        "\n",
        "def group_sentences(sentences1, sent_len):\n",
        "  sentences_tr=[]\n",
        "  sent=[]\n",
        "  i=0\n",
        "  while (i<len(sentences1)):\n",
        "    sent= sentences1[i]\n",
        "    if len(sent) > sent_len:\n",
        "      split= find_last(sent, \"،\", sent_len) +1\n",
        "      sentences_tr.append(sent[0:split])\n",
        "      sent=sent[split:]\n",
        "      if (len(sent)<sent_len):\n",
        "        try:\n",
        "          while (len(sent)+len(sentences1[i+1])<=sent_len):\n",
        "            sent=sent+sentences1[i+1]\n",
        "            i+=1\n",
        "          sentences_tr.append(sent)\n",
        "        except:\n",
        "          sentences_tr.append(sent)\n",
        "      else:\n",
        "        countVar=0\n",
        "        while(countVar*sent_len<len(sent)):\n",
        "          sentTemp=sent[sent_len*countVar:sent_len*(countVar+1)]\n",
        "          sentences_tr.append(sentTemp)\n",
        "          countVar+=1\n",
        "\n",
        "    else:\n",
        "      try:\n",
        "        while (len(sent)+len(sentences1[i+1])<=sent_len):\n",
        "          sent=sent+sentences1[i+1]\n",
        "          i+=1\n",
        "        sentences_tr.append(sent)\n",
        "      except:\n",
        "          sentences_tr.append(sent)\n",
        "\n",
        "    i+=1\n",
        "  return sentences_tr\n",
        "\n",
        "\n",
        "def count2d(sentences):\n",
        "  count=0\n",
        "  for x in sentences:\n",
        "    count+=len(x)\n",
        "  return count\n",
        "\n",
        "\n",
        "def load_sentences( sent_len):\n",
        "\n",
        "  getter1 = SentenceGetter(data_tr)\n",
        "  sentences1 = getter1.sentences\n",
        "  getter2 = SentenceGetter(data_te)\n",
        "  sentences2 = getter2.sentences\n",
        "\n",
        "  sentences_tr = group_sentences(sentences1, sent_len)\n",
        "  sentences_te = group_sentences(sentences2, sent_len)\n",
        "\n",
        "\n",
        "  ### paddding sentences to have equal length\n",
        "  sentences_tr= pad_sequences(maxlen=sent_len, sequences=sentences_tr, padding=\"post\",value=('ENDPAD', 'O'),dtype=object)\n",
        "  sentences_te= pad_sequences(maxlen=sent_len, sequences=sentences_te, padding=\"post\",value=('ENDPAD', 'O'),dtype=object)\n",
        "  sentences   = np.concatenate((sentences_tr , sentences_te), axis =0)\n",
        "  ratio = np.shape(sentences_tr)[0] /(np.shape(sentences_te)[0]+np.shape(sentences_tr)[0]) \n",
        "\n",
        "\n",
        "  print(\"shape of training sentences: \",np.shape(sentences_tr))\n",
        "  print(\"total padding: \" , (np.shape(sentences_tr)[0]*np.shape(sentences_tr)[1])- count2d(sentences1))\n",
        "  print(\"shape of testing sentences: \",np.shape(sentences_te))\n",
        "  print(\"total padding: \" , (np.shape(sentences_te)[0]*np.shape(sentences_te)[1])- count2d(sentences2))\n",
        "  print(\"shape of all sentences: \",np.shape(sentences))\n",
        "\n",
        "  return sentences, ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrHpLTpOJUvC"
      },
      "source": [
        "#creating word and tag dictionary \n",
        "  \n",
        "def create_dictionaries():\n",
        "  words = list((set((data[\"word\"]).values)))\n",
        "  words.append(\"ENDPAD\")\n",
        "  n_words = len(words); \n",
        "  print(\"number of unique words is: \",n_words)\n",
        "\n",
        "  '''tags = []\n",
        "  for tag in set(data[\"tag\"].values):\n",
        "      if tag is nan or isinstance(tag, float):\n",
        "          tags.append('unk')\n",
        "      else:\n",
        "          tags.append(tag)'''\n",
        "  tags=['I-LOC', 'I-MISC', 'B-MISC','B-ORG', 'B-PERS', 'O', 'B-LOC', 'I-ORG', 'I-PERS']\n",
        "\n",
        "  print(\"tags that we have: \\n\",tags)\n",
        "  n_tags = len(tags); \n",
        "  print( 'number of tags is: ', n_tags)\n",
        "\n",
        "  from future.utils import iteritems\n",
        "  word2idx = {w: i for i, w in enumerate(words)}\n",
        "  tag2idx = {t: i for i, t in enumerate(tags)}\n",
        "  idx2tag = {v: k for k, v in iteritems(tag2idx)} \n",
        "  #print(\"index of word إبراهيم :\",word2idx['علي'])\n",
        "  print(\"index of tag I_PERS: \",tag2idx[\"I-PERS\"])\n",
        "\n",
        "  ##replace words and tags with indecies\n",
        "  X_words = [[w[0] for w in s] for s in sentences]\n",
        "  X_idx = [[word2idx[w[0]] for w in s] for s in sentences]  ##\n",
        "\n",
        "  Y_idx = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
        "  Y_oneHot = [to_categorical(i, num_classes=n_tags) for i in Y_idx]\n",
        "\n",
        "  print(\"shape of X_words\", np.shape(X_words) )\n",
        "  print(\"shape of X_idx\", np.shape(X_idx) )\n",
        "  print(\"shape of Y_idx\", np.shape(Y_idx) )\n",
        "  print(\"shape of Y_oneHot\", np.shape(Y_oneHot) )\n",
        "\n",
        "  return X_words, X_idx, Y_idx, Y_oneHot, words, tags, word2idx, tag2idx, idx2tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARWJrQ2DHt5h"
      },
      "source": [
        "##======================methods for generating embeddings ==========================================\n",
        "# parameters \n",
        "#\n",
        "''' How to call theses methods\n",
        "def arabert(X_words, model, layers, layer_mean, subtoken_pooling, fine_tune, use_context, size):\n",
        "arabert(X_words, \"aubmindlab/bert-large-arabertv02\", \"all\", True,  \"mean\", False, False,1024 )\n",
        "fasttext(X_words)\n",
        "aravec(X_words)\n",
        "glove(X_words)'''\n",
        "\n",
        "\n",
        "#===================================================================================================\n",
        "def fasttext(X_words):\n",
        "  stacked_embedding = WordEmbeddings('ar')\n",
        "  embedding_name=\"FastText\"\n",
        "\n",
        "  #adding arabert embeddings\n",
        "  arabert_sents=[]\n",
        "  for sent in X_words:\n",
        "    text=\"\"\n",
        "    for w in sent:\n",
        "      if( w != \"ENDPAD\"):\n",
        "        text+=w\n",
        "        text+=\" \"\n",
        "    if(len(text.rstrip().split(\" \")) >sent_len):\n",
        "      print(len(text.rstrip().split(\" \")))  \n",
        "    bert_sent=Sentence(text=text.rstrip(), use_tokenizer=False)\n",
        "    arabert_sents.append(bert_sent)\n",
        "\n",
        "\n",
        "  for i, sent in enumerate(arabert_sents):\n",
        "    print(i)\n",
        "    stacked_embedding.embed(sent)\n",
        "\n",
        "      \n",
        "  X_arabert=[]\n",
        "  for sent in arabert_sents:\n",
        "    sent_vect=[]\n",
        "    for w in sent:\n",
        "      we=w.embedding.cpu().detach().numpy()\n",
        "      if(len(we)!=300):\n",
        "        print(w)\n",
        "      sent_vect.append(we)\n",
        "    X_arabert.append(sent_vect)\n",
        "\n",
        "\n",
        "  print(np.shape(X_arabert))\n",
        "\n",
        "  tt =X_arabert[0][0]\n",
        "  tt[0:]=0\n",
        "  X_arabert= pad_sequences(maxlen=sent_len, sequences=X_arabert, padding=\"post\",value=tt,dtype=object)\n",
        "  print(np.shape(X_arabert))\n",
        "\n",
        "  return X_arabert, embedding_name\n",
        "#===================================================================================================\n",
        "def glove(X_words):\n",
        "  #f = open(\"/content/drive/MyDrive/Colab Notebooks/glove_ANER2.txt\", \"r\")\n",
        "  f = open(\"/content/drive/MyDrive/Ali lotfy/ANER_embeddings/glove_ANER2.txt\", \"r\")\n",
        "\n",
        "  aravec_embeddings=[]\n",
        "  embedding_name=\"GloVE\"\n",
        "  for line in f:\n",
        "    stringArray = np.array(line.split(\" \")[1:])\n",
        "    floatArray = stringArray.astype(float)\n",
        "    aravec_embeddings.append(floatArray)\n",
        "\n",
        "  #f = open(\"/content/drive/MyDrive/Colab Notebooks/glove_ANER2.txt\", \"r\")\n",
        "  f = open(\"/content/drive/MyDrive/Ali lotfy/ANER_embeddings/glove_ANER2.txt\", \"r\")\n",
        "  \n",
        "  myWords=[]\n",
        "  for line in f:\n",
        "    myWords.append(line.split(\" \")[0])\n",
        "\n",
        "  X_aravec=[]\n",
        "  count=0\n",
        "  for sentence in X_words:\n",
        "    count+=1\n",
        "    print(count)\n",
        "    sen=[]\n",
        "    for w in sentence: \n",
        "        if w in myWords:\n",
        "          try:\n",
        "            sen.append(aravec_embeddings[myWords.index(w)])\n",
        "          except:\n",
        "            sen.append(np.zeros(256))\n",
        "        else:\n",
        "            sen.append(np.zeros(256))    \n",
        "    X_aravec.append(sen)\n",
        "    \n",
        "  print(np.shape(X_aravec))\n",
        "  return X_aravec, embedding_name\n",
        "#===================================================================================================\n",
        "def aravec(X_words):\n",
        "  #f = open(\"/content/drive/MyDrive/Colab Notebooks/aravec_300.txt\", \"r\")\n",
        "  f = open(\"/content/drive/MyDrive/Ali lotfy/ANER_embeddings/aravec_300.txt\", \"r\")\n",
        "  aravec_embeddings=[]\n",
        "  embedding_name=\"AraVec\"\n",
        "\n",
        "  for line in f:\n",
        "    stringArray = np.array(line.split(\" \")[1:])\n",
        "    floatArray = stringArray.astype(float)\n",
        "    aravec_embeddings.append(floatArray)\n",
        "\n",
        " #f = open(\"/content/drive/MyDrive/Colab Notebooks/aravec_300.txt\", \"r\")\n",
        "  f = open(\"/content/drive/MyDrive/Ali lotfy/ANER_embeddings/aravec_300.txt\", \"r\")\n",
        "  \n",
        "  myWords=[]\n",
        "  for line in f:\n",
        "    myWords.append(line.split(\" \")[0])\n",
        "\n",
        "  X_aravec=[]\n",
        "  count=0\n",
        "  for sentence in X_words:\n",
        "    count+=1\n",
        "    print(count)\n",
        "    sen=[]\n",
        "    for w in sentence: \n",
        "        if w in myWords:\n",
        "          try:\n",
        "            sen.append(aravec_embeddings[myWords.index(w)])\n",
        "          except:\n",
        "            sen.append(np.zeros(300))\n",
        "        else:\n",
        "            sen.append(np.zeros(300))    \n",
        "    X_aravec.append(sen)\n",
        "    \n",
        "  print(np.shape(X_aravec))\n",
        "  return X_aravec, embedding_name\n",
        "\n",
        "#===================================================================================================\n",
        "def arabert(X_words, model, layers, layer_mean, subtoken_pooling, fine_tune, use_context, size):\n",
        "  stacked_embedding = StackedEmbeddings([   \n",
        "    TransformerWordEmbeddings(model=model, layers=layers, layer_mean=layer_mean,\n",
        "                              subtoken_pooling=subtoken_pooling, fine_tune = fine_tune, use_context =use_context )\n",
        "    ])\n",
        "  if (size== 1024):\n",
        "    embedding_name=\"AraBertLarge\"\n",
        "  elif (size==768):\n",
        "    embedding_name=\"AraBertBase\"\n",
        "  \n",
        "\n",
        "  #adding arabert embeddings\n",
        "  arabert_sents=[]\n",
        "  for sent in X_words:\n",
        "    text=\"\"\n",
        "    for w in sent:\n",
        "      if( w != \"ENDPAD\"):\n",
        "        text+=w\n",
        "        text+=\" \"\n",
        "    if(len(text.rstrip().split(\" \")) >sent_len):\n",
        "      print(len(text.rstrip().split(\" \")))  \n",
        "    bert_sent=Sentence(text=text.rstrip(), use_tokenizer=False)\n",
        "    arabert_sents.append(bert_sent)\n",
        "\n",
        "\n",
        "  for i, sent in enumerate(arabert_sents):\n",
        "    print(i)\n",
        "    stacked_embedding.embed(sent)\n",
        "\n",
        "      \n",
        "  X_arabert=[]\n",
        "  for sent in arabert_sents:\n",
        "    sent_vect=[]\n",
        "    for w in sent:\n",
        "      we=w.embedding.cpu().detach().numpy()\n",
        "      if(len(we)!=size):\n",
        "        print(w)\n",
        "      sent_vect.append(we)\n",
        "    X_arabert.append(sent_vect)\n",
        "\n",
        "\n",
        "  print(np.shape(X_arabert))\n",
        "\n",
        "  tt =X_arabert[0][0]\n",
        "  tt[0:]=0\n",
        "  X_arabert= pad_sequences(maxlen=sent_len, sequences=X_arabert, padding=\"post\",value=tt,dtype=object)\n",
        "  print(np.shape(X_arabert))\n",
        "\n",
        "\n",
        "  return X_arabert, embedding_name\n",
        "\n",
        "  #========================== Flair embeddings =======================================\n",
        "\n",
        "def flair(X_words, model):\n",
        "  stacked_embedding = StackedEmbeddings([   \n",
        "      FlairEmbeddings(model)\n",
        "    ])\n",
        "  embedding_name=model\n",
        "\n",
        "  #adding arabert embeddings\n",
        "  arabert_sents=[]\n",
        "  for sent in X_words:\n",
        "    text=\"\"\n",
        "    for w in sent:\n",
        "      if( w != \"ENDPAD\"):\n",
        "        text+=w\n",
        "        text+=\" \"\n",
        "    if(len(text.rstrip().split(\" \")) >sent_len):\n",
        "      print(len(text.rstrip().split(\" \")))  \n",
        "    bert_sent=Sentence(text=text.rstrip(), use_tokenizer=False)\n",
        "    arabert_sents.append(bert_sent)\n",
        "\n",
        "\n",
        "  for i, sent in enumerate(arabert_sents):\n",
        "    print(i)\n",
        "    stacked_embedding.embed(sent)\n",
        "\n",
        "      \n",
        "  X_arabert=[]\n",
        "  for sent in arabert_sents:\n",
        "    sent_vect=[]\n",
        "    for w in sent:\n",
        "      we=w.embedding.cpu().detach().numpy()\n",
        "      sent_vect.append(we)\n",
        "    X_arabert.append(sent_vect)\n",
        "\n",
        "\n",
        "  print(np.shape(X_arabert))\n",
        "\n",
        "  tt =X_arabert[0][0]\n",
        "  tt[0:]=0\n",
        "  X_arabert= pad_sequences(maxlen=sent_len, sequences=X_arabert, padding=\"post\",value=tt,dtype=object)\n",
        "  print(np.shape(X_arabert))\n",
        "\n",
        "\n",
        "  return X_arabert, embedding_name\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIazhMqSW2nI"
      },
      "source": [
        "##================================== =========================== Character embedding =========================== =====================================\n",
        "#character embedding enum\n",
        "char_len=16\n",
        "from enum import Enum\n",
        "class Char_type(Enum):\n",
        "  NONE = \"NONE\"\n",
        "  LSTM = \"LSTM\"\n",
        "  CNN = \"CNN\"\n",
        "\n",
        "'''from IPython.display import clear_output\n",
        "\n",
        "chars = set([w_i for w in words for w_i in w])\n",
        "\n",
        "char_dict={}\n",
        "for c in chars:\n",
        "  print(c)\n",
        "  x=input()\n",
        "  char_dict[c]=x\n",
        "  clear_output()\n",
        "  '''\n",
        "\n",
        "  \n",
        "\n",
        "def char(X_words):\n",
        "\n",
        "  char_dict ={'!': '.', '\"': '.', '#': '.', '%': '.', '&': '.', \"'\": '.', '(': '(', ')': ')', '*': '.', '+': '.', ',': '.', '-': '.',\n",
        "              '.': '.', '/': '.', '0': '0', '1': '0', '2': '0', '3': '0', '4': '0', '5': '0', '6': '0', '7': '0', '8': '0', '9': '0',\n",
        "              ':': '.', '=': '.', '>': '.', '?': '.', 'A': 'x', 'B': 'x', 'C': 'x', 'D': 'x', 'E': 'x', 'F': 'x', 'G': 'x', 'H': 'x',\n",
        "              'I': 'x', 'J': 'x', 'K': 'x', 'L': 'x', 'M': 'x', 'N': 'x', 'O': 'x', 'P': 'x', 'R': 'x', 'S': 'x', 'T': 'x', 'U': 'x',\n",
        "              'V': 'x', 'W': 'x', 'X': 'x', 'Y': 'x', 'Z': 'x', '[': '(', ']': ')', 'a': 'x', 'b': 'x', 'c': 'x', 'd': 'x', 'e': 'x',\n",
        "              'f': 'x', 'g': 'x', 'h': 'x', 'i': 'x', 'k': 'x', 'l': 'x', 'm': 'x', 'n': 'x', 'o': 'x', 'p': 'x', 'q': 'x', 'r': 'x',\n",
        "              's': 'x', 't': 'x', 'u': 'x', 'v': 'x', 'w': 'x', 'x': 'x', 'y': 'x', '«': '.', '»': '.', 'í': 'x', 'ü': 'x', '،': '.',\n",
        "              '؛': '.', '؟': '.', 'ء': 'ء', 'آ': 'ء ا', 'أ': 'ء', 'ؤ': 'ء', 'إ': 'ء', 'ئ': 'ء', 'ا': 'ا', 'ب': 'ب', 'ة': 'ة', 'ت': 'ت',\n",
        "              'ث': 'ث', 'ج': 'ج', 'ح': 'ح', 'خ': 'خ', 'د': 'د', 'ذ': 'ذ', 'ر': 'ر', 'ز': 'ز', 'س': 'س', 'ش': 'ش', 'ص': 'ص', 'ض': 'ض',\n",
        "              'ط': 'ط', 'ظ': 'ظ', 'ع': 'ع', 'غ': 'غ', 'ـ': '.', 'ف': 'ف', 'ق': 'ق', 'ك': 'ك', 'ل': 'ل', 'م': 'م', 'ن': 'ن', 'ه': 'ه',\n",
        "              'و': 'و', 'ى': 'ا', 'ي': 'ي', '–': '.', '’': '.', '“': '.', '”': '.', '…': '.', 'ﻷ': 'ل ء', 'ﻹ': 'ل ء'}\n",
        "\n",
        "  chars = set([w_i for w in words for w_i in w])\n",
        "  new_chars=set([char_dict[w] for w in chars ])\n",
        "  n_chars = len(new_chars)\n",
        "  print(\"number of characters is :\", n_chars)\n",
        "\n",
        "\n",
        "  char2idx = {c: i + 2 for i, c in enumerate(new_chars)}\n",
        "  char2idx[\"UNK\"] = 1\n",
        "  char2idx[\"PAD\"] = 0\n",
        "\n",
        "\n",
        "  X_char = []\n",
        "  for sentence in X_words:\n",
        "    sent_seq = []\n",
        "    for i in range(len(sentence)): #sequence length\n",
        "        word_seq = []\n",
        "        j=0\n",
        "        var=0\n",
        "        while j < char_len - var:\n",
        "          try:\n",
        "            char=char_dict[sentence[i][j]]\n",
        "            if (char2idx.get(char)==None):\n",
        "              word_seq.append(0) ## char2idx[\"PAD\"] = 0\n",
        "            else:\n",
        "              char=char_dict[sentence[i][j]]\n",
        "              if (len(char)==3):\n",
        "                char1=char_dict[char[0]]\n",
        "                char1= char2idx.get(char1)\n",
        "                word_seq.append(char1)\n",
        "\n",
        "                char2=char_dict[char[2]]\n",
        "                char2= char2idx.get(char2)\n",
        "                word_seq.append(char2)\n",
        "                var+=1\n",
        "\n",
        "              else:\n",
        "                char= char2idx.get(char)\n",
        "                word_seq.append(char)\n",
        "          except:\n",
        "            word_seq.append(0)\n",
        "\n",
        "          j+=1\n",
        "        sent_seq.append(word_seq)\n",
        "    X_char.append(np.array(sent_seq))\n",
        "\n",
        "  print(np.shape(X_char))\n",
        "\n",
        "  return X_char, n_chars\n",
        "\n",
        "\n",
        "\n",
        "def char1(X_words):\n",
        "  chars = set([w_i for w in words for w_i in w])\n",
        "  n_chars = len(chars)\n",
        "  print(\"number of characters is :\", n_chars)\n",
        "\n",
        "  char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
        "  char2idx[\"UNK\"] = 1\n",
        "  char2idx[\"PAD\"] = 0\n",
        "  X_char = []\n",
        "  for sentence in sentences:\n",
        "      sent_seq = []\n",
        "      for i in range(sent_len): #sequence length\n",
        "          word_seq = []\n",
        "          for j in range(char_len):\n",
        "              try:\n",
        "                  if(char2idx.get(sentence[i][0][j])==None):\n",
        "                    word_seq.append(0) ## char2idx[\"PAD\"] = 0\n",
        "                  else:\n",
        "                    word_seq.append(char2idx.get(sentence[i][0][j]))\n",
        "              except:\n",
        "                  word_seq.append(0)\n",
        "          sent_seq.append(word_seq)\n",
        "      X_char.append(np.array(sent_seq))\n",
        "\n",
        "  return X_char, n_chars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q32T6SxlY8jc"
      },
      "source": [
        "\n",
        "##================================== =========================== ALL Features =========================== =====================================\n",
        "\n",
        "\n",
        "max_fea_len=123\n",
        "quote1 =['«', '\"', '(']\n",
        "quote2 =['»', '\"', ')']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def features1( X_words):\n",
        "  X_fea = []\n",
        "  i=0\n",
        "  idx=0\n",
        "  add_quote = False\n",
        "  quote_count = 0\n",
        "  quote_index=-1\n",
        "  even_flag=True, True, True ##to assure the second quote is not considered\n",
        "  while i<len(X_words):\n",
        "    sent_seq = []\n",
        "    j=0\n",
        "    sent=X_words[i]\n",
        "    while (j<len(sent)):\n",
        "      word=sent[j]\n",
        "      if (word==\"ENDPAD\"):\n",
        "        feature_vector = np.zeros(max_fea_len)\n",
        "      else:\n",
        "        feature_vector=[]\n",
        "        feature_vector+= one_hot1(data.at[idx,'pos'], pos_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'enc0'], enc0_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'stt'], stt_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'num'], num_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'gen'], gen_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'prc0'], prc0_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'prc1'], prc1_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'prc2'], prc2_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'prc3'], prc3_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'per'], per_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'vox'], vox_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'asp'], asp_values)\n",
        "        feature_vector+= one_hot1(data.at[idx, 'cas'], cas_values)\n",
        "        feature_vector+= one_hot1(data.at[idx, 'mod'], mod_values)\n",
        "\n",
        "        try:\n",
        "          if(data.at[idx,\"gloss\"][0].isupper()):\n",
        "            feature_vector+=[1.0]\n",
        "          else:\n",
        "            feature_vector+=[0.0]\n",
        "        except:\n",
        "          feature_vector+=[0.0]\n",
        "        idx+=1\n",
        "        ##quote feature\n",
        "        if add_quote :   ## add values\n",
        "          feature_vector+= [quote_index+1]\n",
        "          feature_vector+= [quote_count]\n",
        "          quote_count -= 1\n",
        "        else:\n",
        "          feature_vector+=[0,0]\n",
        "\n",
        "        if not add_quote and word in quote1: # check if words are between quotes\n",
        "          quote_index= quote1.index(word)\n",
        "          if (even_flag or word!='\"'):\n",
        "            for k in [1,2,3,4]:\n",
        "              try:\n",
        "                if sent[i+k] == quote2[quote_index]:\n",
        "                  add_quote= True\n",
        "                  quote_count=4\n",
        "                  break\n",
        "              except:\n",
        "                add_quote= False\n",
        "          if (word =='\"'):  #to avoid the second quote\n",
        "            even_flag= not even_flag\n",
        "             \n",
        "        if (quote_count ==1): #stop adding values\n",
        "          add_quote = False\n",
        "      sent_seq.append(feature_vector)\n",
        "      j+=1\n",
        "      \n",
        "    X_fea.append(sent_seq)\n",
        "    i+=1\n",
        "  \n",
        "  print(np.shape(X_fea))\n",
        "  return X_fea\n",
        "\n",
        "\n",
        "\n",
        "def one_hot1( value, list):\n",
        "  x=np.zeros(len(list))\n",
        "  idx= list.index(value)\n",
        "  x[idx]=1\n",
        "  return x.tolist()\n",
        "\n",
        "pos_values= ['pron_interrog', 'part_fut', 'punc', 'part', 'noun', 'adv', 'interj', 'verb', 'conj_sub', 'adv_interrog', 'noun_prop', 'verb_pseudo', 'part_focus', 'part_interrog', 'conj', 'adj', 'part_voc', 'digit', 'abbrev', 'pron', 'pron_rel', 'part_det', 'part_neg', 'part_verb', 'prep', 'pron_dem', 'adv_rel', 'pron_exclam', 'noun_quant']\n",
        "cas_values= ['na', 'n', 'u', 'a', 'g']\n",
        "enc0_values= ['3fp_poss', '3fp_pron', '2mp_poss', 'mA_sub', '3mp_pron', '3ms_dobj', '1s_dobj', '2ms_poss', '1s_pron', '3d_dobj', '1p_dobj', '2ms_pron', '3mp_dobj', '1p_poss', 'ma_interrog', '2fs_pron', '2mp_dobj', '2ms_dobj', 'man_rel', '3ms_poss', '3mp_poss', '3d_poss', '3fs_dobj', '3fs_poss', '2fp_poss', '1p_pron', 'mA_rel', 'lA_neg', '3d_pron', 'na', '2fs_poss', '3ms_pron', '1s_poss', '2fs_dobj', '0', '3fp_dobj', '3fs_pron', '2mp_pron']\n",
        "stt_values= ['c', 'i', 'd', 'na']\n",
        "num_values= ['d', 'p', 'na', 's']\n",
        "gen_values= ['f', 'm', 'na']\n",
        "vox_values= ['a', 'p', 'na']\n",
        "asp_values= ['c', 'i', 'p', 'na']\n",
        "per_values= ['1', '3', 'na', '2']\n",
        "prc0_values= ['mA_rel', 'mA_neg', 'lA_neg', 'na', 'Al_det', '0']\n",
        "prc1_values= ['na', 'ka_prep', 'bi_prep', 'li_prep', 'la_emph', '0', 'la_rc', 'sa_fut']\n",
        "prc2_values = ['na', 'wa_sub', 'wa_conj', 'wa_part', 'fa_conj', '0']\n",
        "prc3_values= ['>a_ques', '0', 'na']\n",
        "mod_values= ['i', 'na', 'u']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In_wgLIhDDyy"
      },
      "source": [
        "#create model\n",
        "def create_model(lstm_units, embedding_dropout, lstm_dropout,activation_function, optimizer, \n",
        "                 dense_dropout , second_layer, dense_units, variational_dropout,):\n",
        "\n",
        "  ##word input \n",
        "  if (emb_size==1):\n",
        "    word_input = Input(shape=(sent_len,),name='word_input') ##sent_len is sentence length \n",
        "    embeddings=Embedding(input_dim=len(words) + 1, output_dim=20,)(word_input)\n",
        "  else:\n",
        "    word_input = Input(shape=(sent_len,emb_size,),name='word_input') ##sent_len is sentence length \n",
        "    embeddings=word_input\n",
        "\n",
        "  \n",
        "  ##Feature input \n",
        "  if (use_features):\n",
        "    feature_input = Input(shape=(sent_len,max_fea_len,),name='feature_input')\n",
        "    embeddings = concatenate([embeddings, feature_input])\n",
        "\n",
        "  ## Character embedding\n",
        "  if (character_embedding  is Char_type.LSTM):\n",
        "    char_input = Input(shape=(sent_len, char_len,),name='char_input')\n",
        "    emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2 , output_dim=25, \n",
        "                              input_length=char_len))(char_input)\n",
        "    char_enc = TimeDistributed(LSTM(units=25, return_sequences=False, \n",
        "                                    recurrent_dropout=0.5))(emb_char)\n",
        "    embeddings = concatenate([embeddings, char_enc])\n",
        "\n",
        "  if (character_embedding  is Char_type.CNN):\n",
        "    char_input=Input(shape=(sent_len,char_len,1,),name='char_input')\n",
        "    emb_char=TimeDistributed(Embedding(input_dim=n_chars + 2,output_dim=25,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(char_input)\n",
        "    conv2d_out= TimeDistributed(Conv2D(kernel_size=3, filters=25, padding='same',activation='tanh', strides=1))(emb_char)\n",
        "    maxpool_out=TimeDistributed(MaxPooling2D(1))(conv2d_out)\n",
        "    char_enc = TimeDistributed(Flatten())(maxpool_out)\n",
        "    embeddings = concatenate([embeddings, char_enc])\n",
        "\n",
        "  ##dropout layer on embedding layer\n",
        "  model= Dropout(embedding_dropout, trainable = variational_dropout)(embeddings)\n",
        "\n",
        "  \n",
        "  ## 2 bidirectional LSTM layers \n",
        "  model = Bidirectional(LSTM(units=lstm_units, \n",
        "                            return_sequences=True, \n",
        "                            dropout=lstm_dropout, \n",
        "                            recurrent_dropout=lstm_dropout, \n",
        "                            kernel_initializer=keras.initializers.he_normal()))(model)\n",
        "  if (second_layer):\n",
        "    model = (LSTM(units=lstm_units*2 , \n",
        "                            return_sequences=True, \n",
        "                            dropout=lstm_dropout,\n",
        "                            recurrent_dropout=lstm_dropout, \n",
        "                            kernel_initializer=keras.initializers.he_normal()))(model)\n",
        "\n",
        "\n",
        "  model = TimeDistributed(Dense(dense_units, activation=activation_function))(model)  # previously softmax output layer\n",
        "  model= Dropout(dense_dropout)(model)\n",
        "  '''if (use_features):\n",
        "    feature_input = Input(shape=(sent_len,max_fea_len,),name='feature_input')\n",
        "    model = concatenate([model, feature_input])'''\n",
        "  ##CRF layer\n",
        "  crf = CRF(9)  \n",
        "  out = crf(model) \n",
        "\n",
        "  \n",
        "  if (use_features and character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "      inputs = [word_input,char_input, feature_input]\n",
        "  elif (character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "      inputs = [word_input,char_input]\n",
        "  elif (use_features):\n",
        "      inputs = [word_input,feature_input]\n",
        "  else:\n",
        "    inputs = word_input\n",
        "\n",
        "  ##compile model \n",
        "  model = Model(inputs, out)\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss=crf.loss_function, metrics=[crf.accuracy, \"accuracy\"])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "\n",
        " \n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model, batch, epochs,validation_split, callbacks_list):\n",
        "  if (use_features and character_embedding  is Char_type.LSTM ):\n",
        "    history = model.fit([np.array(X_train), np.array(X_char_tr), np.array(X_fea_tr)],\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "  elif (character_embedding is Char_type.LSTM):\n",
        "    history = model.fit([np.array(X_train), np.array(X_char_tr)],\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "  elif (use_features and character_embedding  is Char_type.CNN ):\n",
        "    history = model.fit([np.array(X_train), np.array(X_char_tr).reshape(len(X_char_tr), sent_len, char_len, 1), np.array(X_fea_tr)],\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "  elif (character_embedding is Char_type.CNN):\n",
        "    history = model.fit([np.array(X_train), np.array(X_char_tr).reshape(len(X_char_tr), sent_len, char_len, 1)],\n",
        "    #history = model.fit( np.array(X_char_tr).reshape(len(X_char_tr), sent_len, char_len, 1),\n",
        "\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "    \n",
        "  elif (use_features):\n",
        "    history = model.fit([np.array(X_train), np.array(X_fea_tr)],\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "  else:\n",
        "\n",
        "    history = model.fit(np.array(X_train),\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "    \n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i])\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "\n",
        "def eval_model(model):\n",
        "  if (use_features and character_embedding  is Char_type.LSTM):\n",
        "    test_pred = model.predict([np.array(X_test), np.array(X_char_te), np.array(X_fea_te) ], verbose=1)   \n",
        "\n",
        "  elif (character_embedding  is Char_type.LSTM):\n",
        "    test_pred = model.predict([np.array(X_test), np.array(X_char_te) ], verbose=1)\n",
        "\n",
        "  elif (use_features and character_embedding  is Char_type.CNN):\n",
        "    test_pred = model.predict([np.array(X_test), np.array(X_char_te).reshape(len(X_char_te), sent_len, char_len, 1), np.array(X_fea_te) ], verbose=1)   \n",
        "\n",
        "  elif (character_embedding  is  Char_type.CNN):\n",
        "    test_pred = model.predict([np.array(X_test), np.array(X_char_te).reshape(len(X_char_te), sent_len, char_len, 1) ], verbose=1)   \n",
        "\n",
        "  elif (use_features):\n",
        "    test_pred = model.predict([np.array(X_test), np.array(X_fea_te) ], verbose=1)   \n",
        "\n",
        "  else:\n",
        "    test_pred = model.predict(np.array(X_test), verbose=1)   \n",
        "  pred_labels = pred2label(test_pred)\n",
        "  test_labels = pred2label(Y_test)\n",
        "  results=[]\n",
        "  results+=[round(precision_score(test_labels, pred_labels)*100, 2)]\n",
        "  results+=[round(recall_score(test_labels, pred_labels)*100, 2)]\n",
        "  results+=[round(f1_score(test_labels, pred_labels)*100, 2)]\n",
        "  return(results)\n",
        "  #classification_report(test_labels, pred_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtPCQ1NaAD6m"
      },
      "source": [
        "## method to split data\n",
        "\n",
        "def split(X_embeddings):\n",
        "  try:\n",
        "    emb_size = np.shape(X_embeddings)[2]\n",
        "  except:\n",
        "    emb_size =1\n",
        "  results=[]\n",
        "\n",
        "  if(random_split):  ## random split \n",
        "    if (use_features and character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "      X_fin = np.dstack((X_embeddings,X_char, X_fea))\n",
        "\n",
        "    elif (use_features):\n",
        "      X_fin = np.dstack((X_embeddings, X_fea))\n",
        "\n",
        "    elif (character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "      X_fin = np.dstack((X_embeddings,X_char))\n",
        "\n",
        "    else:\n",
        "      X_fin=X_embeddings\n",
        "\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X_fin, Y_oneHot, test_size=0.1,random_state=2018)\n",
        "\n",
        "    if (use_features and character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "      X_fea_tr =[[w[emb_size + char_len:] for w in s] for s in X_train]\n",
        "      X_fea_te =[[w[emb_size + char_len:] for w in s] for s in X_test]\n",
        "      X_char_tr =[[w[emb_size:emb_size + char_len] for w in s] for s in X_train]\n",
        "      X_char_te =[[w[emb_size:emb_size + char_len] for w in s] for s in X_test]\n",
        "      X_train =[[w[0:emb_size] for w in s] for s in X_train]\n",
        "      X_test =[[w[0:emb_size] for w in s] for s in X_test]\n",
        "      results +=[X_char_tr, X_char_te, X_fea_tr, X_fea_te]\n",
        "\n",
        "      print(\"X_char_tr \",np.shape(X_char_tr))\n",
        "      print(\"X_char_te \",np.shape(X_char_te))\n",
        "      print(\"X_fea_tr \",np.shape(X_fea_tr))\n",
        "      print(\"X_fea_te \", np.shape(X_fea_te))\n",
        "    elif (use_features):\n",
        "      X_fea_tr =[[w[emb_size :] for w in s] for s in X_train]\n",
        "      X_fea_te =[[w[emb_size:] for w in s] for s in X_test]\n",
        "      X_train =[[w[0:emb_size] for w in s] for s in X_train]\n",
        "      X_test =[[w[0:emb_size] for w in s] for s in X_test]\n",
        "      results +=[X_fea_tr, X_fea_te]\n",
        "\n",
        "      print(\"X_fea_tr \",np.shape(X_fea_tr))\n",
        "      print(\"X_fea_te \", np.shape(X_fea_te))\n",
        "    elif (character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "      X_char_tr =[[w[emb_size:] for w in s] for s in X_train]\n",
        "      X_char_te =[[w[emb_size:] for w in s] for s in X_test]\n",
        "      X_train =[[w[0:emb_size] for w in s] for s in X_train]\n",
        "      X_test =[[w[0:emb_size] for w in s] for s in X_test]\n",
        "      results +=[X_char_tr, X_char_te]\n",
        "\n",
        "      print(\"X_char_tr \",np.shape(X_char_tr))\n",
        "      print(\"X_char_te \",np.shape(X_char_te))\n",
        "    ## these to lines if one hot embeddings are used \n",
        "    #X_train= [[f[0] for f in e] for e in X_train ]\n",
        "    #X_test= [[f[0] for f in e] for e in X_test ]\n",
        "\n",
        "\n",
        "    results =[X_train, X_test, Y_train, Y_test]+results +[emb_size]\n",
        "\n",
        "    print(\"X_train \",np.shape(X_train))\n",
        "    print(\"X_test \",np.shape(X_test))\n",
        "    print(\"Y_train \", np.shape(X_test))\n",
        "    print(\"Y_test \", np.shape(Y_test))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "  else: # camel split\n",
        "    print(\"X_embedding \",np.shape(X_embeddings)) \n",
        "    print(\"Y_oneHot \", np.shape(Y_oneHot))\n",
        "\n",
        "    split_idx =int(ratio*np.shape(sentences)[0])\n",
        "\n",
        "\n",
        "    X_train    =X_embeddings   [0:split_idx]\n",
        "    X_test     =X_embeddings    [split_idx: ]\n",
        "    Y_train    =Y_oneHot [0:split_idx]\n",
        "    Y_test     =Y_oneHot [split_idx: ]\n",
        "    print(\"X_train \",np.shape(X_train))\n",
        "    print(\"X_test \",np.shape(X_test))\n",
        "    print(\"Y_train \", np.shape(Y_train))\n",
        "    print(\"Y_test \", np.shape(Y_test))\n",
        "    results+=[X_train, X_test, Y_train, Y_test]\n",
        "\n",
        "\n",
        "    if ( character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "      X_char_tr    =X_char    [0:split_idx]\n",
        "      X_char_te  =X_char    [split_idx: ]\n",
        "      \n",
        "      print(\"X_char_tr \",np.shape(X_char_tr))\n",
        "      print(\"X_char_tr \",np.shape(X_char_te))\n",
        "      results+=[X_char_tr, X_char_te]\n",
        "\n",
        "    if (use_features):\n",
        "      X_fea_tr    =X_fea    [0:split_idx]\n",
        "      X_fea_te  =X_fea    [split_idx: ]\n",
        "      \n",
        "      print(\"X_fea_tr \",np.shape(X_fea_tr))\n",
        "      print(\"X_fea_te \", np.shape(X_fea_te))\n",
        "      results+=[X_fea_tr, X_fea_te]\n",
        "\n",
        "    return results+ [emb_size]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2noW0c_EV_AE"
      },
      "source": [
        "##method that runs the model\n",
        "\n",
        "def experiment(count, repeate, name, epochs):\n",
        "  \n",
        "  model= create_model(lstm_units, embedding_dropout, lstm_dropout,activation_function, optimizer,dense_dropout , second_layer, dense_units, variational_dropout)\n",
        "  epochs_temp=epochs\n",
        "  epochs=0\n",
        "  highest=0\n",
        "  NoImprove=0\n",
        "  df = pd.DataFrame(columns = ['embedding', 'dimension', 'features', 'character','F1', 'Precision', 'Recall',\n",
        "                             'epochs', 'batch','validation', 'activation function', 'optimizer','lstm units',    \n",
        "                             'sentence length', 'fixed length', 'emb dropout', 'lstm dropout', 'dense dropout', 'second layer',\n",
        "                             'dense units','variational_dropout' \n",
        "                             ])\n",
        "  results=\"\"\n",
        "  path=\"/content/drive/MyDrive/Ali lotfy/saved models AQMAR/\"+name\n",
        "  path_temp=\"/content/drive/MyDrive/Ali lotfy/saved models AQMAR/\"+name\n",
        "  os.mkdir(path)\n",
        "  for o in range(count):\n",
        "    if (repeate):\n",
        "      model= create_model(lstm_units, embedding_dropout, lstm_dropout,activation_function, optimizer,dense_dropout , second_layer, dense_units, variational_dropout)\n",
        "      epochs= epochs_temp\n",
        "    else:\n",
        "      epochs+= epochs_temp\n",
        "\n",
        "\n",
        "    if (NoImprove<9):\n",
        "      es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "      reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, min_lr=0.0001)\n",
        "      callbacks_list=[ es, reduce_lr]\n",
        "      train_model(model=model, batch=batch_size, epochs=epochs_temp, validation_split=val, callbacks_list=callbacks_list )\n",
        "      \n",
        "      eval=eval_model(model)\n",
        "      \n",
        "\n",
        "      if (eval[2]> highest or o%10==9 ):\n",
        "        df = df.append({'embedding': name, 'dimension': emb_size, 'features': use_features,\n",
        "                    'character': character_embedding.name, 'F1': eval[2], 'Precision': eval[0], 'Recall': eval[1],\n",
        "                    'epochs': epochs, 'batch': batch_size, 'validation': val, 'activation function': activation_function,\n",
        "                    'optimizer': optimizer, 'lstm units': lstm_units, 'sentence length': sent_len,'fixed length': fix_length, 'emb dropout': embedding_dropout,\n",
        "                    'lstm dropout': lstm_dropout, 'dense dropout': dense_dropout, 'second layer': second_layer,\n",
        "                    'dense units': dense_units, 'variational_dropout': variational_dropout}, \n",
        "                    ignore_index = True)\n",
        "        results+=\"F1-score= {} Precision= {} Recall={}\".format(eval[2], eval[0], eval[1])\n",
        "        results+=\" epochs= {} lstm_units= {} embedding_dropout= {} lstm_dropout= {} activation_function= {} optimizer= {} dense_dropout= {} second_layer= {} dense_units= {} validation= {} batch_size= {} variational_dropout= {}\".format(epochs,lstm_units,embedding_dropout,lstm_dropout,activation_function,optimizer,dense_dropout,second_layer,dense_units,val,batch_size, variational_dropout)\n",
        "        results+=\"\\n\"\n",
        "        print(results)\n",
        "      \n",
        "      if (eval[2]> highest):\n",
        "        highest= eval[2]\n",
        "        os.rename(path, path_temp+\" \"+str(highest))\n",
        "        path=path_temp+\" \"+str(highest)\n",
        "        save_model(model, weights_file=path+\"/weights.h5\", params_file=path+\"/params.json\")\n",
        "        best={'embedding': name, 'dimension': emb_size, 'features': use_features,\n",
        "                    'character': character_embedding.name, 'F1': eval[2], 'Precision': eval[0], 'Recall': eval[1],\n",
        "                    'epochs': epochs, 'batch': batch_size, 'validation': val, 'activation function': activation_function,\n",
        "                    'optimizer': optimizer, 'lstm units': lstm_units, 'sentence length': sent_len,'fixed length': fix_length, 'emb dropout': embedding_dropout,\n",
        "                    'lstm dropout': lstm_dropout, 'dense dropout': dense_dropout, 'second layer': second_layer,\n",
        "                    'dense units': dense_units, 'variational_dropout': variational_dropout}\n",
        "        NoImprove=0\n",
        "      else:\n",
        "        NoImprove+=1\n",
        "\n",
        "\n",
        "  dfAll = pd.read_csv('/content/drive/MyDrive/Ali lotfy/results_AQMAR.csv')\n",
        "  dfAll=dfAll.append(best,ignore_index = True)\n",
        "  try:\n",
        "    dfAll=dfAll.drop('Unnamed: 0', axis=1)\n",
        "  except:\n",
        "    idle=0\n",
        "  dfAll.to_csv(\"/content/drive/MyDrive/Ali lotfy/results_AQMAR.csv\")  ## name of the experiment\n",
        "\n",
        "\n",
        "  df.to_csv(path+\"/results.csv\")  ## name of the experiment\n",
        "  return df\n",
        "  \n",
        "def save_model(model, weights_file, params_file):\n",
        "    with open(params_file, 'w') as f:\n",
        "        params = model.to_json()\n",
        "        json.dump(json.loads(params), f, sort_keys=True, indent=4)\n",
        "        model.save_weights(weights_file)\n",
        "\n",
        "\n",
        "def load_model(weights_file, params_file):\n",
        "    with open(params_file) as f:\n",
        "        model = model_from_json(f.read(), custom_objects={'CRF': CRF})\n",
        "        model.load_weights(weights_file)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pox0e4cIEZ8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8621f68b-ffb3-407a-bc47-4f89b5fde6ed"
      },
      "source": [
        "#=========load dataset, preproceesing=======================\n",
        "fix_length=False\n",
        "sent_len=100\n",
        "\n",
        "data, data_tr, data_te= load_data(fix_length, sent_len)\n",
        "\n",
        "sentences, ratio= load_sentences(sent_len)\n",
        "X_words, X_idx, Y_idx, Y_oneHot, words, tags, word2idx, tag2idx, idx2tag=create_dictionaries()\n",
        "\n",
        "\n",
        "#==========================embedding========================\n",
        "#def arabert(X_words, model, layers, layer_mean, subtoken_pooling, fine_tune, use_context, size):\n",
        "#X_arabert, X_arabert_name= arabert(X_words, \"aubmindlab/bert-large-arabertv02\", \"all\", True,  \"mean\", False, False,1024 )\n",
        "X_fasttext, X_fasttext_name= fasttext(X_words)\n",
        "#X_aravec, X_aravec_name = aravec(X_words)\n",
        "#X_glove, X_glove_name= glove(X_words)\n",
        "#X_flair, X_flair_name  =flair(X_words, \"ar-forward\")\n",
        "\n",
        "\n",
        "#======================= characyer embedding and features =========\n",
        "X_char, n_chars =char1(X_words)\n",
        "#max_fea_len = 123      ## 123 for all, 1 for cap, 2 for quote, 29 for pos, 91 for analysis\n",
        "X_fea=features1(X_words)\n",
        "\n",
        "\n",
        "#============concatenate two embeddings ================\n",
        "#X_embeddings= np.dstack((X_arabert, X_fasttext))\n",
        "#embedding_name=\"ArabertLarge+ Fasttext\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of training sentences:  (681, 100, 2)\n",
            "total padding:  12525\n",
            "shape of testing sentences:  (228, 100, 2)\n",
            "total padding:  4521\n",
            "shape of all sentences:  (909, 100, 2)\n",
            "number of unique words is:  17936\n",
            "tags that we have: \n",
            " ['I-LOC', 'I-MISC', 'B-MISC', 'B-ORG', 'B-PERS', 'O', 'B-LOC', 'I-ORG', 'I-PERS']\n",
            "number of tags is:  9\n",
            "index of tag I_PERS:  8\n",
            "shape of X_words (909, 100)\n",
            "shape of X_idx (909, 100)\n",
            "shape of Y_idx (909, 100)\n",
            "shape of Y_oneHot (909, 100, 9)\n",
            "2022-04-28 07:59:37,659 https://flair.informatik.hu-berlin.de/resources/embeddings/token/ar-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpu81wrs97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 733171328/733171328 [01:23<00:00, 8775377.59B/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-28 08:01:02,347 copying /tmp/tmpu81wrs97 to cache at /root/.flair/embeddings/ar-wiki-fasttext-300d-1M.vectors.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-28 08:01:04,779 removing temp file /tmp/tmpu81wrs97\n",
            "2022-04-28 08:01:06,084 https://flair.informatik.hu-berlin.de/resources/embeddings/token/ar-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmp7n_pop6n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26704903/26704903 [00:03<00:00, 7171734.64B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-28 08:01:10,548 copying /tmp/tmp7n_pop6n to cache at /root/.flair/embeddings/ar-wiki-fasttext-300d-1M\n",
            "2022-04-28 08:01:10,615 removing temp file /tmp/tmp7n_pop6n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(909,)\n",
            "(909, 100, 300)\n",
            "number of characters is : 136\n",
            "(909, 100, 123)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R04unWslSQyA"
      },
      "source": [
        "`#fine tune arabertlargev02 with features_2019 and CNN, sent_len = 256 \n",
        "#for lstm_units in [50, 100, 150, 200, 250, 300, 350, 400, 450, 500(), 550, 600, 650, 700, 750, 800, 750, 900]:\n",
        "#for optimizer in [\"adam\", \"nadam\", \"adagrad\", \"adamax\", \"RMSprop\", \"adadelta\"]:\n",
        "#for activation_function in [\"relu\", \"tanh\", \"softplus\", \"linear\", \"softsign\", \"hard_sigmoid\"]:\n",
        "#for embedding_dropout in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
        "#for lstm_dropout in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
        "#for dense_dropout in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
        "#for dense_units in [10,32,64,100,150,200, 500]:\n",
        "#for val in [0, 0.05, 0.11111111, 0.15, 0.2, 0.25 ]:\n",
        "#for batch_size in [8, 16, 32, 64]:\n",
        "#for sent_len in [50, 100 ,200, 300, 512]:\n",
        "\n",
        "\n",
        "#sentence length fix length \n",
        "#epochs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8KzWQAx349n",
        "outputId": "ff782130-16f8-460b-f3d0-3048717eadf0"
      },
      "source": [
        "\n",
        "X_embeddings= X_fasttext \n",
        "embedding_name=X_fasttext_name\n",
        "\n",
        "random_split=False\n",
        "use_features=False \n",
        "character_embedding =Char_type(\"NONE\")\n",
        "\n",
        "\n",
        "if (use_features and character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (use_features):\n",
        "  X_train, X_test, Y_train, Y_test, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, emb_size=split(X_embeddings)\n",
        "\n",
        "else:\n",
        "  X_train, X_test, Y_train, Y_test, emb_size=split(X_embeddings)\n",
        "\n",
        "\n",
        "lstm_units=200 #500\n",
        "activation_function=\"hard_sigmoid\" # relu\n",
        "embedding_dropout=0.3\n",
        "lstm_dropout=0.5\n",
        "optimizer=\"nadam\"\n",
        "dense_dropout=0.3 \n",
        "second_layer=False\n",
        "dense_units=150\n",
        "val=0.0\n",
        "batch_size=5\n",
        "epochs=1\n",
        "variational_dropout= False\n",
        "\n",
        "for cc in range(6):\n",
        "    df1= experiment(40, False, \"FastText\", epochs) ## experiment ( number of epochs, repeate runs or increase epochs , name of csv file)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_embedding  (909, 100, 300)\n",
            "Y_oneHot  (909, 100, 9)\n",
            "X_train  (681, 100, 300)\n",
            "X_test  (228, 100, 300)\n",
            "Y_train  (681, 100, 9)\n",
            "Y_test  (228, 100, 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "word_input (InputLayer)      (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_31 (Bidirectio (None, 100, 400)          801600    \n",
            "_________________________________________________________________\n",
            "time_distributed_65 (TimeDis (None, 100, 150)          60150     \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 100, 150)          0         \n",
            "_________________________________________________________________\n",
            "crf_29 (CRF)                 (None, 100, 9)            1458      \n",
            "=================================================================\n",
            "Total params: 863,208\n",
            "Trainable params: 863,208\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 46s 67ms/step - loss: 0.4552 - crf_viterbi_accuracy: 0.8916 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 8s 36ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.2585 - crf_viterbi_accuracy: 0.9238 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.2098 - crf_viterbi_accuracy: 0.9339 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1778 - crf_viterbi_accuracy: 0.9390 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1497 - crf_viterbi_accuracy: 0.9453 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1305 - crf_viterbi_accuracy: 0.9486 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1125 - crf_viterbi_accuracy: 0.9531 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1014 - crf_viterbi_accuracy: 0.9564 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0908 - crf_viterbi_accuracy: 0.9568 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0789 - crf_viterbi_accuracy: 0.9608 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0706 - crf_viterbi_accuracy: 0.9623 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0659 - crf_viterbi_accuracy: 0.9612 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.45 Precision= 69.09 Recall=63.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0573 - crf_viterbi_accuracy: 0.9639 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0519 - crf_viterbi_accuracy: 0.9655 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.45 Precision= 69.09 Recall=63.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.29 Precision= 71.35 Recall=63.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0458 - crf_viterbi_accuracy: 0.9665 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0400 - crf_viterbi_accuracy: 0.9683 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.45 Precision= 69.09 Recall=63.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.29 Precision= 71.35 Recall=63.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.89 Precision= 70.76 Recall=67.11 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0345 - crf_viterbi_accuracy: 0.9686 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0284 - crf_viterbi_accuracy: 0.9700 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0241 - crf_viterbi_accuracy: 0.9711 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.45 Precision= 69.09 Recall=63.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.29 Precision= 71.35 Recall=63.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.89 Precision= 70.76 Recall=67.11 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.27 Precision= 71.57 Recall=67.11 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0192 - crf_viterbi_accuracy: 0.9720 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.45 Precision= 69.09 Recall=63.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.29 Precision= 71.35 Recall=63.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.89 Precision= 70.76 Recall=67.11 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.27 Precision= 71.57 Recall=67.11 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.48 Precision= 71.41 Recall=65.78 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0130 - crf_viterbi_accuracy: 0.9732 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0089 - crf_viterbi_accuracy: 0.9745 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0065 - crf_viterbi_accuracy: 0.9738 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -8.5603e-04 - crf_viterbi_accuracy: 0.9745 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0050 - crf_viterbi_accuracy: 0.9758 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.45 Precision= 69.09 Recall=63.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.29 Precision= 71.35 Recall=63.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.89 Precision= 70.76 Recall=67.11 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.27 Precision= 71.57 Recall=67.11 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.48 Precision= 71.41 Recall=65.78 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.46 Precision= 73.51 Recall=65.84 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0076 - crf_viterbi_accuracy: 0.9764 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.45 Precision= 69.09 Recall=63.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.29 Precision= 71.35 Recall=63.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.89 Precision= 70.76 Recall=67.11 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.27 Precision= 71.57 Recall=67.11 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.48 Precision= 71.41 Recall=65.78 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.46 Precision= 73.51 Recall=65.84 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.53 Precision= 72.25 Recall=68.89 epochs= 26 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0115 - crf_viterbi_accuracy: 0.9768 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.45 Precision= 69.09 Recall=63.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.29 Precision= 71.35 Recall=63.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.89 Precision= 70.76 Recall=67.11 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.27 Precision= 71.57 Recall=67.11 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.48 Precision= 71.41 Recall=65.78 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.46 Precision= 73.51 Recall=65.84 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.53 Precision= 72.25 Recall=68.89 epochs= 26 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.07 Precision= 76.01 Recall=66.73 epochs= 27 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0159 - crf_viterbi_accuracy: 0.9771 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0207 - crf_viterbi_accuracy: 0.9776 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0244 - crf_viterbi_accuracy: 0.9777 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.45 Precision= 69.09 Recall=63.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.29 Precision= 71.35 Recall=63.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.89 Precision= 70.76 Recall=67.11 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.27 Precision= 71.57 Recall=67.11 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.48 Precision= 71.41 Recall=65.78 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.46 Precision= 73.51 Recall=65.84 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.53 Precision= 72.25 Recall=68.89 epochs= 26 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.07 Precision= 76.01 Recall=66.73 epochs= 27 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.99 Precision= 74.58 Recall=64.19 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0258 - crf_viterbi_accuracy: 0.9767 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0320 - crf_viterbi_accuracy: 0.9790 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0356 - crf_viterbi_accuracy: 0.9796 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.45 Precision= 69.09 Recall=63.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.29 Precision= 71.35 Recall=63.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.89 Precision= 70.76 Recall=67.11 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.27 Precision= 71.57 Recall=67.11 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.48 Precision= 71.41 Recall=65.78 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.46 Precision= 73.51 Recall=65.84 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.53 Precision= 72.25 Recall=68.89 epochs= 26 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.07 Precision= 76.01 Recall=66.73 epochs= 27 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.99 Precision= 74.58 Recall=64.19 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.25 Precision= 74.22 Recall=68.51 epochs= 33 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0379 - crf_viterbi_accuracy: 0.9792 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0431 - crf_viterbi_accuracy: 0.9806 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0460 - crf_viterbi_accuracy: 0.9805 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0495 - crf_viterbi_accuracy: 0.9802 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: -0.0533 - crf_viterbi_accuracy: 0.9807 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0572 - crf_viterbi_accuracy: 0.9818 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0601 - crf_viterbi_accuracy: 0.9815 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 19.08 Precision= 30.58 Recall=13.87 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.9 Precision= 46.91 Recall=36.26 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.46 Precision= 54.05 Recall=50.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.97 Precision= 65.23 Recall=52.16 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.14 Precision= 70.52 Recall=55.53 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.79 Precision= 69.81 Recall=57.06 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.36 Precision= 73.27 Recall=57.38 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 72.14 Recall=57.32 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.65 Precision= 68.85 Recall=62.72 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.45 Precision= 69.09 Recall=63.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.29 Precision= 71.35 Recall=63.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.89 Precision= 70.76 Recall=67.11 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.27 Precision= 71.57 Recall=67.11 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.48 Precision= 71.41 Recall=65.78 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.46 Precision= 73.51 Recall=65.84 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.53 Precision= 72.25 Recall=68.89 epochs= 26 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.07 Precision= 76.01 Recall=66.73 epochs= 27 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.99 Precision= 74.58 Recall=64.19 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.25 Precision= 74.22 Recall=68.51 epochs= 33 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.69 Precision= 72.54 Recall=67.05 epochs= 40 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "word_input (InputLayer)      (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_32 (Bidirectio (None, 100, 400)          801600    \n",
            "_________________________________________________________________\n",
            "time_distributed_66 (TimeDis (None, 100, 150)          60150     \n",
            "_________________________________________________________________\n",
            "dropout_62 (Dropout)         (None, 100, 150)          0         \n",
            "_________________________________________________________________\n",
            "crf_30 (CRF)                 (None, 100, 9)            1458      \n",
            "=================================================================\n",
            "Total params: 863,208\n",
            "Trainable params: 863,208\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.4429 - crf_viterbi_accuracy: 0.8924 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 8s 37ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: 0.2605 - crf_viterbi_accuracy: 0.9245 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: 0.2076 - crf_viterbi_accuracy: 0.9338 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: 0.1715 - crf_viterbi_accuracy: 0.9401 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 40s 59ms/step - loss: 0.1488 - crf_viterbi_accuracy: 0.9440 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 40s 59ms/step - loss: 0.1281 - crf_viterbi_accuracy: 0.9483 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: 0.1128 - crf_viterbi_accuracy: 0.9512 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: 0.1019 - crf_viterbi_accuracy: 0.9528 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: 0.0880 - crf_viterbi_accuracy: 0.9572 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: 0.0806 - crf_viterbi_accuracy: 0.9588 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.8 Precision= 65.87 Recall=58.21 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: 0.0700 - crf_viterbi_accuracy: 0.9608 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.8 Precision= 65.87 Recall=58.21 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.51 Precision= 70.98 Recall=55.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: 0.0616 - crf_viterbi_accuracy: 0.9629 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.8 Precision= 65.87 Recall=58.21 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.51 Precision= 70.98 Recall=55.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.62 Precision= 68.77 Recall=60.94 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0551 - crf_viterbi_accuracy: 0.9634 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.8 Precision= 65.87 Recall=58.21 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.51 Precision= 70.98 Recall=55.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.62 Precision= 68.77 Recall=60.94 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 66.84 Recall=64.38 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0480 - crf_viterbi_accuracy: 0.9652 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.8 Precision= 65.87 Recall=58.21 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.51 Precision= 70.98 Recall=55.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.62 Precision= 68.77 Recall=60.94 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 66.84 Recall=64.38 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.76 Precision= 70.22 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0443 - crf_viterbi_accuracy: 0.9666 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0372 - crf_viterbi_accuracy: 0.9680 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0307 - crf_viterbi_accuracy: 0.9686 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.8 Precision= 65.87 Recall=58.21 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.51 Precision= 70.98 Recall=55.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.62 Precision= 68.77 Recall=60.94 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 66.84 Recall=64.38 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.76 Precision= 70.22 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.33 Precision= 72.57 Recall=62.79 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0267 - crf_viterbi_accuracy: 0.9690 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0203 - crf_viterbi_accuracy: 0.9714 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.8 Precision= 65.87 Recall=58.21 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.51 Precision= 70.98 Recall=55.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.62 Precision= 68.77 Recall=60.94 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 66.84 Recall=64.38 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.76 Precision= 70.22 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.33 Precision= 72.57 Recall=62.79 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 69.35 Recall=65.65 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0135 - crf_viterbi_accuracy: 0.9714 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.8 Precision= 65.87 Recall=58.21 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.51 Precision= 70.98 Recall=55.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.62 Precision= 68.77 Recall=60.94 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 66.84 Recall=64.38 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.76 Precision= 70.22 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.33 Precision= 72.57 Recall=62.79 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 69.35 Recall=65.65 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.05 Precision= 71.52 Recall=63.1 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0112 - crf_viterbi_accuracy: 0.9727 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.8 Precision= 65.87 Recall=58.21 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.51 Precision= 70.98 Recall=55.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.62 Precision= 68.77 Recall=60.94 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 66.84 Recall=64.38 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.76 Precision= 70.22 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.33 Precision= 72.57 Recall=62.79 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 69.35 Recall=65.65 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.05 Precision= 71.52 Recall=63.1 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.3 Precision= 70.08 Recall=66.6 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0062 - crf_viterbi_accuracy: 0.9734 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0023 - crf_viterbi_accuracy: 0.9730 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.8 Precision= 65.87 Recall=58.21 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.51 Precision= 70.98 Recall=55.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.62 Precision= 68.77 Recall=60.94 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 66.84 Recall=64.38 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.76 Precision= 70.22 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.33 Precision= 72.57 Recall=62.79 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 69.35 Recall=65.65 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.05 Precision= 71.52 Recall=63.1 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.3 Precision= 70.08 Recall=66.6 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.75 Precision= 69.06 Recall=68.45 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0040 - crf_viterbi_accuracy: 0.9760 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0088 - crf_viterbi_accuracy: 0.9765 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0116 - crf_viterbi_accuracy: 0.9767 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0146 - crf_viterbi_accuracy: 0.9763 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: -0.0215 - crf_viterbi_accuracy: 0.9781 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0227 - crf_viterbi_accuracy: 0.9772 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0257 - crf_viterbi_accuracy: 0.9766 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 26.13 Precision= 43.36 Recall=18.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.62 Precision= 46.3 Recall=46.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.66 Precision= 57.17 Recall=43.89 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.8 Precision= 63.78 Recall=45.04 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.81 Precision= 67.11 Recall=44.91 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.51 Precision= 66.37 Recall=47.71 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.47 Precision= 65.38 Recall=56.23 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.8 Precision= 65.87 Recall=58.21 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.51 Precision= 70.98 Recall=55.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.62 Precision= 68.77 Recall=60.94 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 66.84 Recall=64.38 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.76 Precision= 70.22 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.33 Precision= 72.57 Recall=62.79 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 69.35 Recall=65.65 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.05 Precision= 71.52 Recall=63.1 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.3 Precision= 70.08 Recall=66.6 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.75 Precision= 69.06 Recall=68.45 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.39 Precision= 69.36 Recall=65.52 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0308 - crf_viterbi_accuracy: 0.9790 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0335 - crf_viterbi_accuracy: 0.9787 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "word_input (InputLayer)      (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_33 (Bidirectio (None, 100, 400)          801600    \n",
            "_________________________________________________________________\n",
            "time_distributed_67 (TimeDis (None, 100, 150)          60150     \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 100, 150)          0         \n",
            "_________________________________________________________________\n",
            "crf_31 (CRF)                 (None, 100, 9)            1458      \n",
            "=================================================================\n",
            "Total params: 863,208\n",
            "Trainable params: 863,208\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 46s 67ms/step - loss: 0.4417 - crf_viterbi_accuracy: 0.8847 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 9s 38ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.2469 - crf_viterbi_accuracy: 0.9236 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1995 - crf_viterbi_accuracy: 0.9340 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1687 - crf_viterbi_accuracy: 0.9400 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1474 - crf_viterbi_accuracy: 0.9429 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1286 - crf_viterbi_accuracy: 0.9489 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1129 - crf_viterbi_accuracy: 0.9510 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1022 - crf_viterbi_accuracy: 0.9533 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.84 Precision= 67.18 Recall=55.6 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0888 - crf_viterbi_accuracy: 0.9564 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.84 Precision= 67.18 Recall=55.6 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.21 Precision= 63.75 Recall=60.75 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0813 - crf_viterbi_accuracy: 0.9574 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.84 Precision= 67.18 Recall=55.6 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.21 Precision= 63.75 Recall=60.75 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.7 Precision= 57.81 Recall=66.16 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0753 - crf_viterbi_accuracy: 0.9589 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.84 Precision= 67.18 Recall=55.6 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.21 Precision= 63.75 Recall=60.75 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.7 Precision= 57.81 Recall=66.16 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.67 Precision= 66.15 Recall=59.54 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0663 - crf_viterbi_accuracy: 0.9615 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.84 Precision= 67.18 Recall=55.6 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.21 Precision= 63.75 Recall=60.75 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.7 Precision= 57.81 Recall=66.16 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.67 Precision= 66.15 Recall=59.54 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 69.67 Recall=61.96 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0583 - crf_viterbi_accuracy: 0.9635 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0529 - crf_viterbi_accuracy: 0.9640 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0448 - crf_viterbi_accuracy: 0.9659 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0399 - crf_viterbi_accuracy: 0.9677 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.84 Precision= 67.18 Recall=55.6 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.21 Precision= 63.75 Recall=60.75 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.7 Precision= 57.81 Recall=66.16 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.67 Precision= 66.15 Recall=59.54 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 69.67 Recall=61.96 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.46 Precision= 65.63 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0359 - crf_viterbi_accuracy: 0.9674 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.84 Precision= 67.18 Recall=55.6 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.21 Precision= 63.75 Recall=60.75 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.7 Precision= 57.81 Recall=66.16 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.67 Precision= 66.15 Recall=59.54 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 69.67 Recall=61.96 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.46 Precision= 65.63 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.08 Precision= 72.59 Recall=62.34 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0291 - crf_viterbi_accuracy: 0.9689 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.84 Precision= 67.18 Recall=55.6 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.21 Precision= 63.75 Recall=60.75 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.7 Precision= 57.81 Recall=66.16 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.67 Precision= 66.15 Recall=59.54 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 69.67 Recall=61.96 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.46 Precision= 65.63 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.08 Precision= 72.59 Recall=62.34 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 74.28 Recall=64.31 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0223 - crf_viterbi_accuracy: 0.9711 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0183 - crf_viterbi_accuracy: 0.9724 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.84 Precision= 67.18 Recall=55.6 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.21 Precision= 63.75 Recall=60.75 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.7 Precision= 57.81 Recall=66.16 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.67 Precision= 66.15 Recall=59.54 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 69.67 Recall=61.96 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.46 Precision= 65.63 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.08 Precision= 72.59 Recall=62.34 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 74.28 Recall=64.31 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.34 Precision= 71.11 Recall=65.78 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0151 - crf_viterbi_accuracy: 0.9705 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0091 - crf_viterbi_accuracy: 0.9739 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0055 - crf_viterbi_accuracy: 0.9735 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.84 Precision= 67.18 Recall=55.6 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.21 Precision= 63.75 Recall=60.75 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.7 Precision= 57.81 Recall=66.16 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.67 Precision= 66.15 Recall=59.54 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 69.67 Recall=61.96 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.46 Precision= 65.63 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.08 Precision= 72.59 Recall=62.34 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 74.28 Recall=64.31 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.34 Precision= 71.11 Recall=65.78 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.18 Precision= 73.99 Recall=68.58 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 6.8505e-04 - crf_viterbi_accuracy: 0.9741 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0023 - crf_viterbi_accuracy: 0.9745 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0073 - crf_viterbi_accuracy: 0.9751 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0128 - crf_viterbi_accuracy: 0.9768 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0158 - crf_viterbi_accuracy: 0.9771 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0207 - crf_viterbi_accuracy: 0.9768 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: -0.0228 - crf_viterbi_accuracy: 0.9770 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 14.31 Precision= 34.47 Recall=9.03 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.0 Precision= 53.88 Recall=34.41 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 44.33 Precision= 58.84 Recall=35.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.88 Precision= 62.98 Recall=47.07 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.52 Precision= 67.47 Recall=50.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.84 Precision= 67.18 Recall=55.6 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.21 Precision= 63.75 Recall=60.75 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.7 Precision= 57.81 Recall=66.16 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.67 Precision= 66.15 Recall=59.54 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.59 Precision= 69.67 Recall=61.96 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.46 Precision= 65.63 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.08 Precision= 72.59 Recall=62.34 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 74.28 Recall=64.31 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.34 Precision= 71.11 Recall=65.78 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.18 Precision= 73.99 Recall=68.58 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.07 Precision= 72.63 Recall=65.84 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0272 - crf_viterbi_accuracy: 0.9778 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0315 - crf_viterbi_accuracy: 0.9787 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "word_input (InputLayer)      (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "dropout_65 (Dropout)         (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_34 (Bidirectio (None, 100, 400)          801600    \n",
            "_________________________________________________________________\n",
            "time_distributed_68 (TimeDis (None, 100, 150)          60150     \n",
            "_________________________________________________________________\n",
            "dropout_66 (Dropout)         (None, 100, 150)          0         \n",
            "_________________________________________________________________\n",
            "crf_32 (CRF)                 (None, 100, 9)            1458      \n",
            "=================================================================\n",
            "Total params: 863,208\n",
            "Trainable params: 863,208\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 46s 68ms/step - loss: 0.4926 - crf_viterbi_accuracy: 0.8832 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 9s 39ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.2784 - crf_viterbi_accuracy: 0.9208 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.2231 - crf_viterbi_accuracy: 0.9312 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1882 - crf_viterbi_accuracy: 0.9378 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1603 - crf_viterbi_accuracy: 0.9432 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1417 - crf_viterbi_accuracy: 0.9458 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1242 - crf_viterbi_accuracy: 0.9506 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1122 - crf_viterbi_accuracy: 0.9524 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1025 - crf_viterbi_accuracy: 0.9546 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.71 Precision= 64.26 Recall=59.35 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0914 - crf_viterbi_accuracy: 0.9584 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.71 Precision= 64.26 Recall=59.35 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.96 Precision= 68.84 Recall=59.73 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0819 - crf_viterbi_accuracy: 0.9599 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.71 Precision= 64.26 Recall=59.35 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.96 Precision= 68.84 Recall=59.73 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.54 Precision= 70.99 Recall=59.16 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0725 - crf_viterbi_accuracy: 0.9625 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.71 Precision= 64.26 Recall=59.35 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.96 Precision= 68.84 Recall=59.73 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.54 Precision= 70.99 Recall=59.16 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.46 Precision= 72.04 Recall=59.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0664 - crf_viterbi_accuracy: 0.9638 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.71 Precision= 64.26 Recall=59.35 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.96 Precision= 68.84 Recall=59.73 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.54 Precision= 70.99 Recall=59.16 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.46 Precision= 72.04 Recall=59.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.22 Precision= 70.37 Recall=62.53 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0621 - crf_viterbi_accuracy: 0.9634 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0554 - crf_viterbi_accuracy: 0.9657 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0480 - crf_viterbi_accuracy: 0.9668 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0449 - crf_viterbi_accuracy: 0.9670 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.71 Precision= 64.26 Recall=59.35 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.96 Precision= 68.84 Recall=59.73 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.54 Precision= 70.99 Recall=59.16 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.46 Precision= 72.04 Recall=59.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.22 Precision= 70.37 Recall=62.53 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.88 Precision= 72.1 Recall=64.12 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0390 - crf_viterbi_accuracy: 0.9687 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.71 Precision= 64.26 Recall=59.35 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.96 Precision= 68.84 Recall=59.73 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.54 Precision= 70.99 Recall=59.16 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.46 Precision= 72.04 Recall=59.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.22 Precision= 70.37 Recall=62.53 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.88 Precision= 72.1 Recall=64.12 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.88 Precision= 73.55 Recall=64.76 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0332 - crf_viterbi_accuracy: 0.9685 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0301 - crf_viterbi_accuracy: 0.9697 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.71 Precision= 64.26 Recall=59.35 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.96 Precision= 68.84 Recall=59.73 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.54 Precision= 70.99 Recall=59.16 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.46 Precision= 72.04 Recall=59.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.22 Precision= 70.37 Recall=62.53 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.88 Precision= 72.1 Recall=64.12 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.88 Precision= 73.55 Recall=64.76 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.31 Precision= 69.69 Recall=66.98 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0225 - crf_viterbi_accuracy: 0.9726 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.71 Precision= 64.26 Recall=59.35 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.96 Precision= 68.84 Recall=59.73 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.54 Precision= 70.99 Recall=59.16 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.46 Precision= 72.04 Recall=59.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.22 Precision= 70.37 Recall=62.53 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.88 Precision= 72.1 Recall=64.12 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.88 Precision= 73.55 Recall=64.76 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.31 Precision= 69.69 Recall=66.98 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.9 Precision= 71.29 Recall=66.67 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0184 - crf_viterbi_accuracy: 0.9726 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.71 Precision= 64.26 Recall=59.35 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.96 Precision= 68.84 Recall=59.73 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.54 Precision= 70.99 Recall=59.16 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.46 Precision= 72.04 Recall=59.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.22 Precision= 70.37 Recall=62.53 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.88 Precision= 72.1 Recall=64.12 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.88 Precision= 73.55 Recall=64.76 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.31 Precision= 69.69 Recall=66.98 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.9 Precision= 71.29 Recall=66.67 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.3 Precision= 75.48 Recall=67.56 epochs= 22 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0129 - crf_viterbi_accuracy: 0.9734 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0110 - crf_viterbi_accuracy: 0.9730 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0042 - crf_viterbi_accuracy: 0.9753 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0031 - crf_viterbi_accuracy: 0.9742 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0038 - crf_viterbi_accuracy: 0.9767 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0062 - crf_viterbi_accuracy: 0.9760 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0129 - crf_viterbi_accuracy: 0.9781 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0157 - crf_viterbi_accuracy: 0.9782 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 28.0 Precision= 30.32 Recall=26.02 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 40.79 Precision= 57.46 Recall=31.62 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.58 Precision= 54.19 Recall=44.02 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.23 Precision= 66.21 Recall=43.13 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.98 Precision= 63.5 Recall=48.47 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.95 Precision= 68.31 Recall=50.32 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.03 Precision= 65.73 Recall=53.56 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.71 Precision= 64.26 Recall=59.35 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.96 Precision= 68.84 Recall=59.73 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.54 Precision= 70.99 Recall=59.16 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.46 Precision= 72.04 Recall=59.99 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.22 Precision= 70.37 Recall=62.53 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.88 Precision= 72.1 Recall=64.12 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.88 Precision= 73.55 Recall=64.76 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.31 Precision= 69.69 Recall=66.98 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.9 Precision= 71.29 Recall=66.67 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.3 Precision= 75.48 Recall=67.56 epochs= 22 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.17 Precision= 74.62 Recall=66.22 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0188 - crf_viterbi_accuracy: 0.9783 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "word_input (InputLayer)      (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "dropout_67 (Dropout)         (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_35 (Bidirectio (None, 100, 400)          801600    \n",
            "_________________________________________________________________\n",
            "time_distributed_69 (TimeDis (None, 100, 150)          60150     \n",
            "_________________________________________________________________\n",
            "dropout_68 (Dropout)         (None, 100, 150)          0         \n",
            "_________________________________________________________________\n",
            "crf_33 (CRF)                 (None, 100, 9)            1458      \n",
            "=================================================================\n",
            "Total params: 863,208\n",
            "Trainable params: 863,208\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 46s 67ms/step - loss: 0.4374 - crf_viterbi_accuracy: 0.8949 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 9s 39ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.2624 - crf_viterbi_accuracy: 0.9243 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.2112 - crf_viterbi_accuracy: 0.9331 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1784 - crf_viterbi_accuracy: 0.9395 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1523 - crf_viterbi_accuracy: 0.9446 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1325 - crf_viterbi_accuracy: 0.9482 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1162 - crf_viterbi_accuracy: 0.9523 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1039 - crf_viterbi_accuracy: 0.9544 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0903 - crf_viterbi_accuracy: 0.9578 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0811 - crf_viterbi_accuracy: 0.9602 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0717 - crf_viterbi_accuracy: 0.9614 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0666 - crf_viterbi_accuracy: 0.9624 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0596 - crf_viterbi_accuracy: 0.9645 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0518 - crf_viterbi_accuracy: 0.9666 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 71.79 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0465 - crf_viterbi_accuracy: 0.9675 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 71.79 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.1 Precision= 72.93 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0430 - crf_viterbi_accuracy: 0.9676 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 71.79 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.1 Precision= 72.93 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.93 Precision= 72.76 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0350 - crf_viterbi_accuracy: 0.9701 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0314 - crf_viterbi_accuracy: 0.9702 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0270 - crf_viterbi_accuracy: 0.9703 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0219 - crf_viterbi_accuracy: 0.9716 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 71.79 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.1 Precision= 72.93 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.93 Precision= 72.76 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.97 Precision= 73.59 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0155 - crf_viterbi_accuracy: 0.9731 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0108 - crf_viterbi_accuracy: 0.9724 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0062 - crf_viterbi_accuracy: 0.9739 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0026 - crf_viterbi_accuracy: 0.9746 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0051 - crf_viterbi_accuracy: 0.9758 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 71.79 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.1 Precision= 72.93 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.93 Precision= 72.76 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.97 Precision= 73.59 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.05 Precision= 73.1 Recall=67.24 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0040 - crf_viterbi_accuracy: 0.9741 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0086 - crf_viterbi_accuracy: 0.9760 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0129 - crf_viterbi_accuracy: 0.9765 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0180 - crf_viterbi_accuracy: 0.9778 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0237 - crf_viterbi_accuracy: 0.9800 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 71.79 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.1 Precision= 72.93 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.93 Precision= 72.76 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.97 Precision= 73.59 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.05 Precision= 73.1 Recall=67.24 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.11 Precision= 73.0 Recall=67.43 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0266 - crf_viterbi_accuracy: 0.9792 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 71.79 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.1 Precision= 72.93 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.93 Precision= 72.76 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.97 Precision= 73.59 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.05 Precision= 73.1 Recall=67.24 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.11 Precision= 73.0 Recall=67.43 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.66 Precision= 74.14 Recall=67.49 epochs= 31 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0298 - crf_viterbi_accuracy: 0.9794 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0337 - crf_viterbi_accuracy: 0.9794 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 71.79 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.1 Precision= 72.93 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.93 Precision= 72.76 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.97 Precision= 73.59 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.05 Precision= 73.1 Recall=67.24 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.11 Precision= 73.0 Recall=67.43 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.66 Precision= 74.14 Recall=67.49 epochs= 31 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.37 Recall=67.94 epochs= 33 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0351 - crf_viterbi_accuracy: 0.9791 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0401 - crf_viterbi_accuracy: 0.9802 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 71.79 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.1 Precision= 72.93 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.93 Precision= 72.76 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.97 Precision= 73.59 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.05 Precision= 73.1 Recall=67.24 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.11 Precision= 73.0 Recall=67.43 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.66 Precision= 74.14 Recall=67.49 epochs= 31 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.37 Recall=67.94 epochs= 33 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.13 Precision= 74.34 Recall=68.19 epochs= 35 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0445 - crf_viterbi_accuracy: 0.9802 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0469 - crf_viterbi_accuracy: 0.9808 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0508 - crf_viterbi_accuracy: 0.9807 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0552 - crf_viterbi_accuracy: 0.9819 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 71.79 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.1 Precision= 72.93 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.93 Precision= 72.76 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.97 Precision= 73.59 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.05 Precision= 73.1 Recall=67.24 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.11 Precision= 73.0 Recall=67.43 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.66 Precision= 74.14 Recall=67.49 epochs= 31 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.37 Recall=67.94 epochs= 33 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.13 Precision= 74.34 Recall=68.19 epochs= 35 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.35 Precision= 71.97 Recall=70.74 epochs= 39 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0569 - crf_viterbi_accuracy: 0.9817 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 27.77 Precision= 31.75 Recall=24.68 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 38.71 Precision= 40.42 Recall=37.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.98 Precision= 62.36 Recall=46.06 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.61 Precision= 66.54 Recall=46.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.36 Precision= 70.23 Recall=48.47 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.09 Precision= 70.1 Recall=54.13 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 73.72 Recall=52.29 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.88 Precision= 65.64 Recall=62.21 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.09 Precision= 68.32 Recall=62.15 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.44 Precision= 72.57 Recall=61.26 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 71.79 Recall=63.61 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.1 Precision= 72.93 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.93 Precision= 72.76 Recall=67.3 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.97 Precision= 73.59 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.05 Precision= 73.1 Recall=67.24 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.11 Precision= 73.0 Recall=67.43 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.66 Precision= 74.14 Recall=67.49 epochs= 31 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.37 Recall=67.94 epochs= 33 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.13 Precision= 74.34 Recall=68.19 epochs= 35 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.35 Precision= 71.97 Recall=70.74 epochs= 39 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.66 Precision= 72.73 Recall=68.7 epochs= 40 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "word_input (InputLayer)      (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "dropout_69 (Dropout)         (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_36 (Bidirectio (None, 100, 400)          801600    \n",
            "_________________________________________________________________\n",
            "time_distributed_70 (TimeDis (None, 100, 150)          60150     \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 100, 150)          0         \n",
            "_________________________________________________________________\n",
            "crf_34 (CRF)                 (None, 100, 9)            1458      \n",
            "=================================================================\n",
            "Total params: 863,208\n",
            "Trainable params: 863,208\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 46s 68ms/step - loss: 0.4328 - crf_viterbi_accuracy: 0.8918 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 9s 40ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.2486 - crf_viterbi_accuracy: 0.9249 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.2052 - crf_viterbi_accuracy: 0.9336 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1700 - crf_viterbi_accuracy: 0.9408 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1463 - crf_viterbi_accuracy: 0.9448 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.1273 - crf_viterbi_accuracy: 0.9490 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1132 - crf_viterbi_accuracy: 0.9514 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1009 - crf_viterbi_accuracy: 0.9528 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0878 - crf_viterbi_accuracy: 0.9568 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0769 - crf_viterbi_accuracy: 0.9589 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0685 - crf_viterbi_accuracy: 0.9611 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.55 Precision= 66.35 Recall=62.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0613 - crf_viterbi_accuracy: 0.9621 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0556 - crf_viterbi_accuracy: 0.9638 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.55 Precision= 66.35 Recall=62.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.9 Precision= 69.53 Recall=66.35 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0463 - crf_viterbi_accuracy: 0.9656 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0410 - crf_viterbi_accuracy: 0.9665 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0348 - crf_viterbi_accuracy: 0.9682 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0301 - crf_viterbi_accuracy: 0.9688 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0228 - crf_viterbi_accuracy: 0.9699 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0194 - crf_viterbi_accuracy: 0.9708 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.55 Precision= 66.35 Recall=62.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.9 Precision= 69.53 Recall=66.35 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.37 Precision= 71.24 Recall=65.71 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0130 - crf_viterbi_accuracy: 0.9730 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.55 Precision= 66.35 Recall=62.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.9 Precision= 69.53 Recall=66.35 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.37 Precision= 71.24 Recall=65.71 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.2 Precision= 71.88 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0097 - crf_viterbi_accuracy: 0.9730 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.55 Precision= 66.35 Recall=62.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.9 Precision= 69.53 Recall=66.35 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.37 Precision= 71.24 Recall=65.71 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.2 Precision= 71.88 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.11 Precision= 71.73 Recall=66.67 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0054 - crf_viterbi_accuracy: 0.9735 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0021 - crf_viterbi_accuracy: 0.9730 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0055 - crf_viterbi_accuracy: 0.9757 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0097 - crf_viterbi_accuracy: 0.9760 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.55 Precision= 66.35 Recall=62.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.9 Precision= 69.53 Recall=66.35 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.37 Precision= 71.24 Recall=65.71 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.2 Precision= 71.88 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.11 Precision= 71.73 Recall=66.67 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.22 Precision= 70.54 Recall=67.94 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0129 - crf_viterbi_accuracy: 0.9765 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0164 - crf_viterbi_accuracy: 0.9768 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0219 - crf_viterbi_accuracy: 0.9786 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0267 - crf_viterbi_accuracy: 0.9786 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0291 - crf_viterbi_accuracy: 0.9792 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.55 Precision= 66.35 Recall=62.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.9 Precision= 69.53 Recall=66.35 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.37 Precision= 71.24 Recall=65.71 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.2 Precision= 71.88 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.11 Precision= 71.73 Recall=66.67 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.22 Precision= 70.54 Recall=67.94 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.98 Precision= 72.65 Recall=63.87 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0343 - crf_viterbi_accuracy: 0.9800 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.55 Precision= 66.35 Recall=62.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.9 Precision= 69.53 Recall=66.35 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.37 Precision= 71.24 Recall=65.71 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.2 Precision= 71.88 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.11 Precision= 71.73 Recall=66.67 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.22 Precision= 70.54 Recall=67.94 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.98 Precision= 72.65 Recall=63.87 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.23 Precision= 73.71 Recall=65.27 epochs= 31 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0372 - crf_viterbi_accuracy: 0.9800 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.55 Precision= 66.35 Recall=62.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.9 Precision= 69.53 Recall=66.35 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.37 Precision= 71.24 Recall=65.71 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.2 Precision= 71.88 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.11 Precision= 71.73 Recall=66.67 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.22 Precision= 70.54 Recall=67.94 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.98 Precision= 72.65 Recall=63.87 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.23 Precision= 73.71 Recall=65.27 epochs= 31 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.54 Precision= 73.21 Recall=66.22 epochs= 32 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0394 - crf_viterbi_accuracy: 0.9803 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0415 - crf_viterbi_accuracy: 0.9786 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.55 Precision= 66.35 Recall=62.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.9 Precision= 69.53 Recall=66.35 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.37 Precision= 71.24 Recall=65.71 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.2 Precision= 71.88 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.11 Precision= 71.73 Recall=66.67 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.22 Precision= 70.54 Recall=67.94 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.98 Precision= 72.65 Recall=63.87 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.23 Precision= 73.71 Recall=65.27 epochs= 31 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.54 Precision= 73.21 Recall=66.22 epochs= 32 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.13 Precision= 72.03 Recall=68.32 epochs= 34 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0477 - crf_viterbi_accuracy: 0.9815 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0509 - crf_viterbi_accuracy: 0.9810 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0539 - crf_viterbi_accuracy: 0.9812 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0580 - crf_viterbi_accuracy: 0.9821 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0609 - crf_viterbi_accuracy: 0.9820 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0650 - crf_viterbi_accuracy: 0.9823 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 23.16 Precision= 31.85 Recall=18.19 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 41.8 Precision= 52.92 Recall=34.54 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.87 Precision= 61.98 Recall=44.59 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.93 Precision= 58.98 Recall=51.4 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.69 Precision= 63.47 Recall=49.62 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.0 Precision= 69.93 Recall=49.55 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.94 Precision= 67.04 Recall=57.57 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.3 Precision= 68.05 Recall=57.44 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.55 Precision= 66.35 Recall=62.85 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.9 Precision= 69.53 Recall=66.35 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.37 Precision= 71.24 Recall=65.71 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.2 Precision= 71.88 Recall=64.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.11 Precision= 71.73 Recall=66.67 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.22 Precision= 70.54 Recall=67.94 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.98 Precision= 72.65 Recall=63.87 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.23 Precision= 73.71 Recall=65.27 epochs= 31 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.54 Precision= 73.21 Recall=66.22 epochs= 32 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.13 Precision= 72.03 Recall=68.32 epochs= 34 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.07 Precision= 72.03 Recall=66.35 epochs= 40 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS8bGv91JIdJ",
        "outputId": "654b6afc-0761-4146-a510-c5526832f571"
      },
      "source": [
        "\n",
        "X_embeddings= X_fasttext \n",
        "embedding_name=X_fasttext_name\n",
        "\n",
        "random_split=False\n",
        "use_features=True \n",
        "character_embedding =Char_type(\"NONE\")\n",
        "\n",
        "\n",
        "if (use_features and character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (use_features):\n",
        "  X_train, X_test, Y_train, Y_test, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, emb_size=split(X_embeddings)\n",
        "\n",
        "else:\n",
        "  X_train, X_test, Y_train, Y_test, emb_size=split(X_embeddings)\n",
        "\n",
        "\n",
        "lstm_units=200 #500\n",
        "activation_function=\"hard_sigmoid\" # relu\n",
        "embedding_dropout=0.3\n",
        "lstm_dropout=0.5\n",
        "optimizer=\"nadam\"\n",
        "dense_dropout=0.3 \n",
        "second_layer=False\n",
        "dense_units=150\n",
        "val=0.0\n",
        "batch_size=5\n",
        "epochs=1\n",
        "variational_dropout= False\n",
        "\n",
        "for cc in range(6):\n",
        "    df1= experiment(40, False, \"FastText_Fea\", epochs) ## experiment ( number of epochs, repeate runs or increase epochs , name of csv file)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_embedding  (909, 100, 300)\n",
            "Y_oneHot  (909, 100, 9)\n",
            "X_train  (681, 100, 300)\n",
            "X_test  (228, 100, 300)\n",
            "Y_train  (681, 100, 9)\n",
            "Y_test  (228, 100, 9)\n",
            "X_fea_tr  (681, 100, 123)\n",
            "X_fea_te  (228, 100, 123)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_35\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_input (InputLayer)      (None, 100, 123)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 100, 423)     0           word_input[0][0]                 \n",
            "                                                                 feature_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 100, 423)     0           concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_37 (Bidirectional (None, 100, 400)     998400      dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_71 (TimeDistri (None, 100, 150)     60150       bidirectional_37[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 100, 150)     0           time_distributed_71[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "crf_35 (CRF)                    (None, 100, 9)       1458        dropout_72[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,060,008\n",
            "Trainable params: 1,060,008\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 46s 68ms/step - loss: 0.4100 - crf_viterbi_accuracy: 0.9015 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 9s 42ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.2387 - crf_viterbi_accuracy: 0.9285 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1933 - crf_viterbi_accuracy: 0.9378 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1601 - crf_viterbi_accuracy: 0.9433 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.99 Precision= 64.05 Recall=51.34 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1369 - crf_viterbi_accuracy: 0.9495 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1218 - crf_viterbi_accuracy: 0.9508 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.99 Precision= 64.05 Recall=51.34 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.39 Precision= 58.13 Recall=58.65 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1086 - crf_viterbi_accuracy: 0.9543 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0960 - crf_viterbi_accuracy: 0.9573 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.99 Precision= 64.05 Recall=51.34 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.39 Precision= 58.13 Recall=58.65 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.56 Precision= 67.67 Recall=59.92 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0847 - crf_viterbi_accuracy: 0.9604 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.99 Precision= 64.05 Recall=51.34 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.39 Precision= 58.13 Recall=58.65 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.56 Precision= 67.67 Recall=59.92 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.8 Precision= 68.14 Recall=59.99 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0769 - crf_viterbi_accuracy: 0.9623 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.99 Precision= 64.05 Recall=51.34 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.39 Precision= 58.13 Recall=58.65 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.56 Precision= 67.67 Recall=59.92 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.8 Precision= 68.14 Recall=59.99 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.56 Precision= 71.31 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0673 - crf_viterbi_accuracy: 0.9634 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0615 - crf_viterbi_accuracy: 0.9635 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.99 Precision= 64.05 Recall=51.34 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.39 Precision= 58.13 Recall=58.65 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.56 Precision= 67.67 Recall=59.92 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.8 Precision= 68.14 Recall=59.99 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.56 Precision= 71.31 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.68 Precision= 73.65 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0527 - crf_viterbi_accuracy: 0.9677 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.99 Precision= 64.05 Recall=51.34 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.39 Precision= 58.13 Recall=58.65 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.56 Precision= 67.67 Recall=59.92 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.8 Precision= 68.14 Recall=59.99 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.56 Precision= 71.31 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.68 Precision= 73.65 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 72.98 Recall=64.44 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0483 - crf_viterbi_accuracy: 0.9666 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0424 - crf_viterbi_accuracy: 0.9677 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0368 - crf_viterbi_accuracy: 0.9699 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.99 Precision= 64.05 Recall=51.34 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.39 Precision= 58.13 Recall=58.65 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.56 Precision= 67.67 Recall=59.92 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.8 Precision= 68.14 Recall=59.99 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.56 Precision= 71.31 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.68 Precision= 73.65 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 72.98 Recall=64.44 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.2 Precision= 76.7 Recall=63.04 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0302 - crf_viterbi_accuracy: 0.9705 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.99 Precision= 64.05 Recall=51.34 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.39 Precision= 58.13 Recall=58.65 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.56 Precision= 67.67 Recall=59.92 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.8 Precision= 68.14 Recall=59.99 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.56 Precision= 71.31 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.68 Precision= 73.65 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 72.98 Recall=64.44 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.2 Precision= 76.7 Recall=63.04 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.63 Precision= 71.13 Recall=68.19 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0257 - crf_viterbi_accuracy: 0.9714 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.99 Precision= 64.05 Recall=51.34 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.39 Precision= 58.13 Recall=58.65 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.56 Precision= 67.67 Recall=59.92 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.8 Precision= 68.14 Recall=59.99 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.56 Precision= 71.31 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.68 Precision= 73.65 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 72.98 Recall=64.44 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.2 Precision= 76.7 Recall=63.04 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.63 Precision= 71.13 Recall=68.19 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.89 Precision= 77.65 Recall=65.2 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0204 - crf_viterbi_accuracy: 0.9721 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0148 - crf_viterbi_accuracy: 0.9737 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 35.55 Precision= 43.29 Recall=30.15 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.95 Precision= 54.19 Recall=39.89 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.74 Precision= 60.85 Recall=43.51 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.99 Precision= 64.05 Recall=51.34 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.39 Precision= 58.13 Recall=58.65 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.56 Precision= 67.67 Recall=59.92 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.8 Precision= 68.14 Recall=59.99 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.56 Precision= 71.31 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.68 Precision= 73.65 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 72.98 Recall=64.44 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.2 Precision= 76.7 Recall=63.04 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.63 Precision= 71.13 Recall=68.19 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.89 Precision= 77.65 Recall=65.2 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 72.28 Recall=66.67 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0119 - crf_viterbi_accuracy: 0.9743 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0061 - crf_viterbi_accuracy: 0.9751 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0027 - crf_viterbi_accuracy: 0.9754 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0018 - crf_viterbi_accuracy: 0.9766 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0057 - crf_viterbi_accuracy: 0.9764 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0112 - crf_viterbi_accuracy: 0.9779 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0144 - crf_viterbi_accuracy: 0.9776 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_36\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_input (InputLayer)      (None, 100, 123)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 100, 423)     0           word_input[0][0]                 \n",
            "                                                                 feature_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 100, 423)     0           concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_38 (Bidirectional (None, 100, 400)     998400      dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_72 (TimeDistri (None, 100, 150)     60150       bidirectional_38[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 100, 150)     0           time_distributed_72[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "crf_36 (CRF)                    (None, 100, 9)       1458        dropout_74[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,060,008\n",
            "Trainable params: 1,060,008\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 46s 68ms/step - loss: 0.4067 - crf_viterbi_accuracy: 0.9005 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 10s 42ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.2362 - crf_viterbi_accuracy: 0.9276 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1889 - crf_viterbi_accuracy: 0.9372 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1560 - crf_viterbi_accuracy: 0.9424 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1326 - crf_viterbi_accuracy: 0.9489 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1167 - crf_viterbi_accuracy: 0.9521 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1053 - crf_viterbi_accuracy: 0.9541 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0935 - crf_viterbi_accuracy: 0.9567 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0813 - crf_viterbi_accuracy: 0.9583 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.35 Precision= 71.66 Recall=58.4 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0732 - crf_viterbi_accuracy: 0.9620 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.35 Precision= 71.66 Recall=58.4 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 69.77 Recall=62.53 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0635 - crf_viterbi_accuracy: 0.9639 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0570 - crf_viterbi_accuracy: 0.9646 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.35 Precision= 71.66 Recall=58.4 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 69.77 Recall=62.53 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.77 Precision= 73.87 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0505 - crf_viterbi_accuracy: 0.9659 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.35 Precision= 71.66 Recall=58.4 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 69.77 Recall=62.53 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.77 Precision= 73.87 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.09 Precision= 74.1 Recall=62.98 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0456 - crf_viterbi_accuracy: 0.9670 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.35 Precision= 71.66 Recall=58.4 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 69.77 Recall=62.53 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.77 Precision= 73.87 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.09 Precision= 74.1 Recall=62.98 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.29 Precision= 75.11 Recall=64.31 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0392 - crf_viterbi_accuracy: 0.9686 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.35 Precision= 71.66 Recall=58.4 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 69.77 Recall=62.53 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.77 Precision= 73.87 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.09 Precision= 74.1 Recall=62.98 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.29 Precision= 75.11 Recall=64.31 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.73 Precision= 71.55 Recall=68.0 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0345 - crf_viterbi_accuracy: 0.9695 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0272 - crf_viterbi_accuracy: 0.9704 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0226 - crf_viterbi_accuracy: 0.9714 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.35 Precision= 71.66 Recall=58.4 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 69.77 Recall=62.53 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.77 Precision= 73.87 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.09 Precision= 74.1 Recall=62.98 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.29 Precision= 75.11 Recall=64.31 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.73 Precision= 71.55 Recall=68.0 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.03 Precision= 73.75 Recall=66.67 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0165 - crf_viterbi_accuracy: 0.9734 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0121 - crf_viterbi_accuracy: 0.9735 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.35 Precision= 71.66 Recall=58.4 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 69.77 Recall=62.53 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.77 Precision= 73.87 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.09 Precision= 74.1 Recall=62.98 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.29 Precision= 75.11 Recall=64.31 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.73 Precision= 71.55 Recall=68.0 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.03 Precision= 73.75 Recall=66.67 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.48 Precision= 74.36 Recall=66.98 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0086 - crf_viterbi_accuracy: 0.9735 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0026 - crf_viterbi_accuracy: 0.9756 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0025 - crf_viterbi_accuracy: 0.9756 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0038 - crf_viterbi_accuracy: 0.9750 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0092 - crf_viterbi_accuracy: 0.9765 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.35 Precision= 71.66 Recall=58.4 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 69.77 Recall=62.53 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.77 Precision= 73.87 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.09 Precision= 74.1 Recall=62.98 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.29 Precision= 75.11 Recall=64.31 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.73 Precision= 71.55 Recall=68.0 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.03 Precision= 73.75 Recall=66.67 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.48 Precision= 74.36 Recall=66.98 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.55 Precision= 72.22 Recall=68.96 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0132 - crf_viterbi_accuracy: 0.9771 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0164 - crf_viterbi_accuracy: 0.9775 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0219 - crf_viterbi_accuracy: 0.9782 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.35 Precision= 71.66 Recall=58.4 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 69.77 Recall=62.53 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.77 Precision= 73.87 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.09 Precision= 74.1 Recall=62.98 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.29 Precision= 75.11 Recall=64.31 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.73 Precision= 71.55 Recall=68.0 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.03 Precision= 73.75 Recall=66.67 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.48 Precision= 74.36 Recall=66.98 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.55 Precision= 72.22 Recall=68.96 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.79 Precision= 71.38 Recall=72.2 epochs= 28 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0231 - crf_viterbi_accuracy: 0.9774 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0299 - crf_viterbi_accuracy: 0.9801 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 34.96 Precision= 39.29 Recall=31.49 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.13 Precision= 60.6 Recall=42.75 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.39 Precision= 56.54 Recall=50.57 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.03 Precision= 64.36 Recall=49.62 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.64 Precision= 67.16 Recall=52.04 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.45 Precision= 64.66 Recall=62.28 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.65 Precision= 68.37 Recall=59.54 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.35 Precision= 71.66 Recall=58.4 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 69.77 Recall=62.53 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.77 Precision= 73.87 Recall=62.6 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.09 Precision= 74.1 Recall=62.98 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.29 Precision= 75.11 Recall=64.31 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.73 Precision= 71.55 Recall=68.0 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.03 Precision= 73.75 Recall=66.67 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.48 Precision= 74.36 Recall=66.98 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.55 Precision= 72.22 Recall=68.96 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.79 Precision= 71.38 Recall=72.2 epochs= 28 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.75 Precision= 72.17 Recall=65.65 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0329 - crf_viterbi_accuracy: 0.9800 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0366 - crf_viterbi_accuracy: 0.9810 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0396 - crf_viterbi_accuracy: 0.9798 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0432 - crf_viterbi_accuracy: 0.9805 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0461 - crf_viterbi_accuracy: 0.9811 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0517 - crf_viterbi_accuracy: 0.9815 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0544 - crf_viterbi_accuracy: 0.9822 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_37\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_input (InputLayer)      (None, 100, 123)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 100, 423)     0           word_input[0][0]                 \n",
            "                                                                 feature_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 100, 423)     0           concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_39 (Bidirectional (None, 100, 400)     998400      dropout_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_73 (TimeDistri (None, 100, 150)     60150       bidirectional_39[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, 100, 150)     0           time_distributed_73[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "crf_37 (CRF)                    (None, 100, 9)       1458        dropout_76[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,060,008\n",
            "Trainable params: 1,060,008\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 46s 68ms/step - loss: 0.3962 - crf_viterbi_accuracy: 0.9028 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 10s 43ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.2389 - crf_viterbi_accuracy: 0.9280 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1869 - crf_viterbi_accuracy: 0.9375 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1562 - crf_viterbi_accuracy: 0.9454 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1352 - crf_viterbi_accuracy: 0.9501 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: 0.1168 - crf_viterbi_accuracy: 0.9536 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1037 - crf_viterbi_accuracy: 0.9558 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0920 - crf_viterbi_accuracy: 0.9580 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.2 Precision= 74.57 Recall=54.83 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0823 - crf_viterbi_accuracy: 0.9604 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.2 Precision= 74.57 Recall=54.83 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.7 Precision= 74.58 Recall=57.12 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0736 - crf_viterbi_accuracy: 0.9615 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.2 Precision= 74.57 Recall=54.83 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.7 Precision= 74.58 Recall=57.12 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.34 Precision= 68.64 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0643 - crf_viterbi_accuracy: 0.9652 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.2 Precision= 74.57 Recall=54.83 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.7 Precision= 74.58 Recall=57.12 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.34 Precision= 68.64 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.43 Precision= 72.31 Recall=64.95 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0578 - crf_viterbi_accuracy: 0.9657 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.2 Precision= 74.57 Recall=54.83 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.7 Precision= 74.58 Recall=57.12 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.34 Precision= 68.64 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.43 Precision= 72.31 Recall=64.95 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 73.07 Recall=64.38 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0511 - crf_viterbi_accuracy: 0.9673 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.2 Precision= 74.57 Recall=54.83 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.7 Precision= 74.58 Recall=57.12 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.34 Precision= 68.64 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.43 Precision= 72.31 Recall=64.95 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 73.07 Recall=64.38 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.86 Precision= 72.7 Recall=67.24 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 62ms/step - loss: 0.0436 - crf_viterbi_accuracy: 0.9685 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.2 Precision= 74.57 Recall=54.83 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.7 Precision= 74.58 Recall=57.12 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.34 Precision= 68.64 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.43 Precision= 72.31 Recall=64.95 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 73.07 Recall=64.38 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.86 Precision= 72.7 Recall=67.24 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.64 Precision= 73.27 Recall=68.19 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0406 - crf_viterbi_accuracy: 0.9691 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0327 - crf_viterbi_accuracy: 0.9710 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0264 - crf_viterbi_accuracy: 0.9721 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0242 - crf_viterbi_accuracy: 0.9718 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0195 - crf_viterbi_accuracy: 0.9731 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0129 - crf_viterbi_accuracy: 0.9743 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.2 Precision= 74.57 Recall=54.83 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.7 Precision= 74.58 Recall=57.12 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.34 Precision= 68.64 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.43 Precision= 72.31 Recall=64.95 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 73.07 Recall=64.38 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.86 Precision= 72.7 Recall=67.24 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.64 Precision= 73.27 Recall=68.19 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.32 Precision= 73.63 Recall=67.3 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0097 - crf_viterbi_accuracy: 0.9745 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0029 - crf_viterbi_accuracy: 0.9770 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.2 Precision= 74.57 Recall=54.83 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.7 Precision= 74.58 Recall=57.12 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.34 Precision= 68.64 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.43 Precision= 72.31 Recall=64.95 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 73.07 Recall=64.38 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.86 Precision= 72.7 Recall=67.24 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.64 Precision= 73.27 Recall=68.19 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.32 Precision= 73.63 Recall=67.3 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.0 Precision= 74.12 Recall=68.13 epochs= 22 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -3.2127e-04 - crf_viterbi_accuracy: 0.9762 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.2 Precision= 74.57 Recall=54.83 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.7 Precision= 74.58 Recall=57.12 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.34 Precision= 68.64 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.43 Precision= 72.31 Recall=64.95 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 73.07 Recall=64.38 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.86 Precision= 72.7 Recall=67.24 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.64 Precision= 73.27 Recall=68.19 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.32 Precision= 73.63 Recall=67.3 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.0 Precision= 74.12 Recall=68.13 epochs= 22 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.68 Precision= 72.04 Recall=71.31 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0042 - crf_viterbi_accuracy: 0.9774 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0063 - crf_viterbi_accuracy: 0.9773 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0134 - crf_viterbi_accuracy: 0.9786 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0168 - crf_viterbi_accuracy: 0.9789 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0205 - crf_viterbi_accuracy: 0.9796 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0240 - crf_viterbi_accuracy: 0.9789 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0295 - crf_viterbi_accuracy: 0.9800 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 24.7 Precision= 22.68 Recall=27.1 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 48.08 Precision= 52.08 Recall=44.66 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 53.95 Precision= 57.97 Recall=50.45 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.6 Precision= 58.17 Recall=53.24 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.7 Precision= 66.25 Recall=54.33 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.49 Precision= 66.38 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.78 Precision= 72.76 Recall=55.22 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.2 Precision= 74.57 Recall=54.83 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.7 Precision= 74.58 Recall=57.12 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.34 Precision= 68.64 Recall=64.19 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.43 Precision= 72.31 Recall=64.95 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.45 Precision= 73.07 Recall=64.38 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.86 Precision= 72.7 Recall=67.24 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.64 Precision= 73.27 Recall=68.19 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.32 Precision= 73.63 Recall=67.3 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.0 Precision= 74.12 Recall=68.13 epochs= 22 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.68 Precision= 72.04 Recall=71.31 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.68 Precision= 74.49 Recall=69.08 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0314 - crf_viterbi_accuracy: 0.9808 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0363 - crf_viterbi_accuracy: 0.9809 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_38\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_input (InputLayer)      (None, 100, 123)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 100, 423)     0           word_input[0][0]                 \n",
            "                                                                 feature_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_77 (Dropout)            (None, 100, 423)     0           concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_40 (Bidirectional (None, 100, 400)     998400      dropout_77[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_74 (TimeDistri (None, 100, 150)     60150       bidirectional_40[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 100, 150)     0           time_distributed_74[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "crf_38 (CRF)                    (None, 100, 9)       1458        dropout_78[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,060,008\n",
            "Trainable params: 1,060,008\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 48s 71ms/step - loss: 0.4050 - crf_viterbi_accuracy: 0.9018 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 10s 45ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 64ms/step - loss: 0.2431 - crf_viterbi_accuracy: 0.9285 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.1887 - crf_viterbi_accuracy: 0.9386 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 64ms/step - loss: 0.1606 - crf_viterbi_accuracy: 0.9445 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.1368 - crf_viterbi_accuracy: 0.9486 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.39 Precision= 70.68 Recall=51.21 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.1193 - crf_viterbi_accuracy: 0.9525 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.39 Precision= 70.68 Recall=51.21 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.11 Precision= 72.76 Recall=52.67 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.1076 - crf_viterbi_accuracy: 0.9547 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.39 Precision= 70.68 Recall=51.21 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.11 Precision= 72.76 Recall=52.67 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.48 Precision= 70.93 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0952 - crf_viterbi_accuracy: 0.9565 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0832 - crf_viterbi_accuracy: 0.9596 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.39 Precision= 70.68 Recall=51.21 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.11 Precision= 72.76 Recall=52.67 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.48 Precision= 70.93 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.75 Precision= 69.46 Recall=64.25 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0729 - crf_viterbi_accuracy: 0.9623 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.39 Precision= 70.68 Recall=51.21 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.11 Precision= 72.76 Recall=52.67 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.48 Precision= 70.93 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.75 Precision= 69.46 Recall=64.25 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.35 Precision= 70.31 Recall=64.63 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0637 - crf_viterbi_accuracy: 0.9654 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.39 Precision= 70.68 Recall=51.21 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.11 Precision= 72.76 Recall=52.67 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.48 Precision= 70.93 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.75 Precision= 69.46 Recall=64.25 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.35 Precision= 70.31 Recall=64.63 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.83 Precision= 70.31 Recall=65.52 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0579 - crf_viterbi_accuracy: 0.9659 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.39 Precision= 70.68 Recall=51.21 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.11 Precision= 72.76 Recall=52.67 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.48 Precision= 70.93 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.75 Precision= 69.46 Recall=64.25 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.35 Precision= 70.31 Recall=64.63 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.83 Precision= 70.31 Recall=65.52 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.2 Precision= 73.48 Recall=65.39 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0518 - crf_viterbi_accuracy: 0.9675 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0451 - crf_viterbi_accuracy: 0.9674 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0363 - crf_viterbi_accuracy: 0.9706 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.39 Precision= 70.68 Recall=51.21 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.11 Precision= 72.76 Recall=52.67 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.48 Precision= 70.93 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.75 Precision= 69.46 Recall=64.25 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.35 Precision= 70.31 Recall=64.63 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.83 Precision= 70.31 Recall=65.52 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.2 Precision= 73.48 Recall=65.39 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 75.44 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0322 - crf_viterbi_accuracy: 0.9717 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0275 - crf_viterbi_accuracy: 0.9718 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0224 - crf_viterbi_accuracy: 0.9725 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.39 Precision= 70.68 Recall=51.21 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.11 Precision= 72.76 Recall=52.67 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.48 Precision= 70.93 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.75 Precision= 69.46 Recall=64.25 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.35 Precision= 70.31 Recall=64.63 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.83 Precision= 70.31 Recall=65.52 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.2 Precision= 73.48 Recall=65.39 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 75.44 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.87 Precision= 72.4 Recall=69.4 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0176 - crf_viterbi_accuracy: 0.9731 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.39 Precision= 70.68 Recall=51.21 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.11 Precision= 72.76 Recall=52.67 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.48 Precision= 70.93 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.75 Precision= 69.46 Recall=64.25 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.35 Precision= 70.31 Recall=64.63 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.83 Precision= 70.31 Recall=65.52 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.2 Precision= 73.48 Recall=65.39 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 75.44 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.87 Precision= 72.4 Recall=69.4 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.81 Precision= 74.91 Recall=68.96 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0116 - crf_viterbi_accuracy: 0.9749 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 25.98 Precision= 22.31 Recall=31.11 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 45.19 Precision= 44.53 Recall=45.87 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.8 Precision= 61.0 Recall=49.75 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.37 Precision= 70.95 Recall=46.76 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.39 Precision= 70.68 Recall=51.21 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.11 Precision= 72.76 Recall=52.67 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.48 Precision= 70.93 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.75 Precision= 69.46 Recall=64.25 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.35 Precision= 70.31 Recall=64.63 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.83 Precision= 70.31 Recall=65.52 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.2 Precision= 73.48 Recall=65.39 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 75.44 Recall=65.65 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.87 Precision= 72.4 Recall=69.4 epochs= 18 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.81 Precision= 74.91 Recall=68.96 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.59 Precision= 74.87 Recall=65.01 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0079 - crf_viterbi_accuracy: 0.9746 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0043 - crf_viterbi_accuracy: 0.9763 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -5.0813e-04 - crf_viterbi_accuracy: 0.9769 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0044 - crf_viterbi_accuracy: 0.9769 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0095 - crf_viterbi_accuracy: 0.9765 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0118 - crf_viterbi_accuracy: 0.9780 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0169 - crf_viterbi_accuracy: 0.9787 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0208 - crf_viterbi_accuracy: 0.9795 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_39\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_input (InputLayer)      (None, 100, 123)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 100, 423)     0           word_input[0][0]                 \n",
            "                                                                 feature_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 100, 423)     0           concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_41 (Bidirectional (None, 100, 400)     998400      dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_75 (TimeDistri (None, 100, 150)     60150       bidirectional_41[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, 100, 150)     0           time_distributed_75[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "crf_39 (CRF)                    (None, 100, 9)       1458        dropout_80[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,060,008\n",
            "Trainable params: 1,060,008\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 48s 71ms/step - loss: 0.4251 - crf_viterbi_accuracy: 0.8911 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 11s 47ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.2440 - crf_viterbi_accuracy: 0.9265 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.1909 - crf_viterbi_accuracy: 0.9373 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 64ms/step - loss: 0.1618 - crf_viterbi_accuracy: 0.9423 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.47 Precision= 66.75 Recall=53.63 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.1389 - crf_viterbi_accuracy: 0.9488 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.1199 - crf_viterbi_accuracy: 0.9520 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.47 Precision= 66.75 Recall=53.63 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.64 Precision= 71.51 Recall=55.73 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.1072 - crf_viterbi_accuracy: 0.9536 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.47 Precision= 66.75 Recall=53.63 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.64 Precision= 71.51 Recall=55.73 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.04 Precision= 74.01 Recall=54.9 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 64ms/step - loss: 0.0918 - crf_viterbi_accuracy: 0.9573 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 64ms/step - loss: 0.0842 - crf_viterbi_accuracy: 0.9588 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.47 Precision= 66.75 Recall=53.63 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.64 Precision= 71.51 Recall=55.73 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.04 Precision= 74.01 Recall=54.9 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.39 Precision= 69.07 Recall=62.09 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0735 - crf_viterbi_accuracy: 0.9616 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.47 Precision= 66.75 Recall=53.63 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.64 Precision= 71.51 Recall=55.73 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.04 Precision= 74.01 Recall=54.9 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.39 Precision= 69.07 Recall=62.09 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.96 Precision= 71.7 Recall=61.07 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0661 - crf_viterbi_accuracy: 0.9634 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.47 Precision= 66.75 Recall=53.63 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.64 Precision= 71.51 Recall=55.73 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.04 Precision= 74.01 Recall=54.9 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.39 Precision= 69.07 Recall=62.09 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.96 Precision= 71.7 Recall=61.07 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.0 Precision= 73.1 Recall=65.33 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0593 - crf_viterbi_accuracy: 0.9649 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0496 - crf_viterbi_accuracy: 0.9666 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0473 - crf_viterbi_accuracy: 0.9664 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.47 Precision= 66.75 Recall=53.63 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.64 Precision= 71.51 Recall=55.73 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.04 Precision= 74.01 Recall=54.9 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.39 Precision= 69.07 Recall=62.09 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.96 Precision= 71.7 Recall=61.07 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.0 Precision= 73.1 Recall=65.33 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.87 Precision= 74.11 Recall=66.09 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0402 - crf_viterbi_accuracy: 0.9689 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.47 Precision= 66.75 Recall=53.63 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.64 Precision= 71.51 Recall=55.73 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.04 Precision= 74.01 Recall=54.9 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.39 Precision= 69.07 Recall=62.09 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.96 Precision= 71.7 Recall=61.07 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.0 Precision= 73.1 Recall=65.33 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.87 Precision= 74.11 Recall=66.09 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.43 Precision= 76.43 Recall=67.05 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0358 - crf_viterbi_accuracy: 0.9694 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0283 - crf_viterbi_accuracy: 0.9713 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 65ms/step - loss: 0.0246 - crf_viterbi_accuracy: 0.9705 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0190 - crf_viterbi_accuracy: 0.9721 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0134 - crf_viterbi_accuracy: 0.9737 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.47 Precision= 66.75 Recall=53.63 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.64 Precision= 71.51 Recall=55.73 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.04 Precision= 74.01 Recall=54.9 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.39 Precision= 69.07 Recall=62.09 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.96 Precision= 71.7 Recall=61.07 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.0 Precision= 73.1 Recall=65.33 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.87 Precision= 74.11 Recall=66.09 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.43 Precision= 76.43 Recall=67.05 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.39 Precision= 76.1 Recall=67.24 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0086 - crf_viterbi_accuracy: 0.9737 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.0037 - crf_viterbi_accuracy: 0.9754 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 8.0012e-04 - crf_viterbi_accuracy: 0.9755 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0031 - crf_viterbi_accuracy: 0.9755 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.47 Precision= 66.75 Recall=53.63 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.64 Precision= 71.51 Recall=55.73 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.04 Precision= 74.01 Recall=54.9 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.39 Precision= 69.07 Recall=62.09 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.96 Precision= 71.7 Recall=61.07 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.0 Precision= 73.1 Recall=65.33 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.87 Precision= 74.11 Recall=66.09 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.43 Precision= 76.43 Recall=67.05 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.39 Precision= 76.1 Recall=67.24 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.44 Precision= 72.48 Recall=72.39 epochs= 24 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0078 - crf_viterbi_accuracy: 0.9763 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0106 - crf_viterbi_accuracy: 0.9767 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0172 - crf_viterbi_accuracy: 0.9778 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0213 - crf_viterbi_accuracy: 0.9787 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0250 - crf_viterbi_accuracy: 0.9796 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0297 - crf_viterbi_accuracy: 0.9798 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 31.01 Precision= 32.97 Recall=29.26 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.06 Precision= 58.15 Recall=42.43 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 50.76 Precision= 47.21 Recall=54.9 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.47 Precision= 66.75 Recall=53.63 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 62.64 Precision= 71.51 Recall=55.73 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.04 Precision= 74.01 Recall=54.9 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.39 Precision= 69.07 Recall=62.09 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.96 Precision= 71.7 Recall=61.07 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.0 Precision= 73.1 Recall=65.33 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.87 Precision= 74.11 Recall=66.09 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.43 Precision= 76.43 Recall=67.05 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.39 Precision= 76.1 Recall=67.24 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.44 Precision= 72.48 Recall=72.39 epochs= 24 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.61 Precision= 74.33 Recall=67.24 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0308 - crf_viterbi_accuracy: 0.9798 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0370 - crf_viterbi_accuracy: 0.9807 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 64ms/step - loss: -0.0380 - crf_viterbi_accuracy: 0.9805 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_40\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_input (InputLayer)      (None, 100, 123)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 100, 423)     0           word_input[0][0]                 \n",
            "                                                                 feature_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_81 (Dropout)            (None, 100, 423)     0           concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_42 (Bidirectional (None, 100, 400)     998400      dropout_81[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_76 (TimeDistri (None, 100, 150)     60150       bidirectional_42[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_82 (Dropout)            (None, 100, 150)     0           time_distributed_76[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "crf_40 (CRF)                    (None, 100, 9)       1458        dropout_82[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,060,008\n",
            "Trainable params: 1,060,008\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 48s 70ms/step - loss: 0.4247 - crf_viterbi_accuracy: 0.8947 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 11s 47ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.2345 - crf_viterbi_accuracy: 0.9288 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.1873 - crf_viterbi_accuracy: 0.9368 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.1539 - crf_viterbi_accuracy: 0.9442 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.1341 - crf_viterbi_accuracy: 0.9476 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.1146 - crf_viterbi_accuracy: 0.9524 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.1043 - crf_viterbi_accuracy: 0.9545 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0895 - crf_viterbi_accuracy: 0.9568 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0792 - crf_viterbi_accuracy: 0.9593 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0706 - crf_viterbi_accuracy: 0.9612 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0637 - crf_viterbi_accuracy: 0.9625 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 64ms/step - loss: 0.0567 - crf_viterbi_accuracy: 0.9647 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0485 - crf_viterbi_accuracy: 0.9671 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0412 - crf_viterbi_accuracy: 0.9682 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.27 Precision= 71.79 Recall=65.08 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0377 - crf_viterbi_accuracy: 0.9679 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.27 Precision= 71.79 Recall=65.08 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 75.15 Recall=63.68 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 64ms/step - loss: 0.0297 - crf_viterbi_accuracy: 0.9700 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0248 - crf_viterbi_accuracy: 0.9702 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.27 Precision= 71.79 Recall=65.08 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 75.15 Recall=63.68 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.04 Precision= 70.39 Recall=67.75 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0194 - crf_viterbi_accuracy: 0.9723 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0156 - crf_viterbi_accuracy: 0.9718 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.27 Precision= 71.79 Recall=65.08 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 75.15 Recall=63.68 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.04 Precision= 70.39 Recall=67.75 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.55 Precision= 71.17 Recall=68.0 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0096 - crf_viterbi_accuracy: 0.9731 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.27 Precision= 71.79 Recall=65.08 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 75.15 Recall=63.68 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.04 Precision= 70.39 Recall=67.75 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.55 Precision= 71.17 Recall=68.0 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.35 Precision= 71.86 Recall=68.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0047 - crf_viterbi_accuracy: 0.9746 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0014 - crf_viterbi_accuracy: 0.9748 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0052 - crf_viterbi_accuracy: 0.9774 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.27 Precision= 71.79 Recall=65.08 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 75.15 Recall=63.68 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.04 Precision= 70.39 Recall=67.75 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.55 Precision= 71.17 Recall=68.0 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.35 Precision= 71.86 Recall=68.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.72 Precision= 72.79 Recall=68.77 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0074 - crf_viterbi_accuracy: 0.9758 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.27 Precision= 71.79 Recall=65.08 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 75.15 Recall=63.68 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.04 Precision= 70.39 Recall=67.75 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.55 Precision= 71.17 Recall=68.0 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.35 Precision= 71.86 Recall=68.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.72 Precision= 72.79 Recall=68.77 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.76 Precision= 75.4 Recall=66.67 epochs= 24 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 62ms/step - loss: -0.0123 - crf_viterbi_accuracy: 0.9780 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.27 Precision= 71.79 Recall=65.08 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 75.15 Recall=63.68 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.04 Precision= 70.39 Recall=67.75 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.55 Precision= 71.17 Recall=68.0 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.35 Precision= 71.86 Recall=68.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.72 Precision= 72.79 Recall=68.77 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.76 Precision= 75.4 Recall=66.67 epochs= 24 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.78 Precision= 74.49 Recall=67.43 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0147 - crf_viterbi_accuracy: 0.9770 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0209 - crf_viterbi_accuracy: 0.9783 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0247 - crf_viterbi_accuracy: 0.9786 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0278 - crf_viterbi_accuracy: 0.9794 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0326 - crf_viterbi_accuracy: 0.9795 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.27 Precision= 71.79 Recall=65.08 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 75.15 Recall=63.68 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.04 Precision= 70.39 Recall=67.75 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.55 Precision= 71.17 Recall=68.0 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.35 Precision= 71.86 Recall=68.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.72 Precision= 72.79 Recall=68.77 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.76 Precision= 75.4 Recall=66.67 epochs= 24 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.78 Precision= 74.49 Recall=67.43 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.48 Precision= 74.57 Recall=68.64 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0351 - crf_viterbi_accuracy: 0.9800 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0408 - crf_viterbi_accuracy: 0.9811 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0437 - crf_viterbi_accuracy: 0.9819 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0460 - crf_viterbi_accuracy: 0.9813 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0505 - crf_viterbi_accuracy: 0.9825 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0549 - crf_viterbi_accuracy: 0.9820 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.27 Precision= 71.79 Recall=65.08 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 75.15 Recall=63.68 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.04 Precision= 70.39 Recall=67.75 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.55 Precision= 71.17 Recall=68.0 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.35 Precision= 71.86 Recall=68.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.72 Precision= 72.79 Recall=68.77 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.76 Precision= 75.4 Recall=66.67 epochs= 24 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.78 Precision= 74.49 Recall=67.43 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.48 Precision= 74.57 Recall=68.64 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.0 Precision= 73.65 Recall=70.42 epochs= 36 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0588 - crf_viterbi_accuracy: 0.9833 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0619 - crf_viterbi_accuracy: 0.9825 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0658 - crf_viterbi_accuracy: 0.9845 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0679 - crf_viterbi_accuracy: 0.9831 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 6ms/step\n",
            "F1-score= 29.41 Precision= 29.11 Recall=29.71 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.6 Precision= 51.65 Recall=47.71 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.68 Precision= 59.78 Recall=52.1 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.52 Precision= 64.06 Recall=50.57 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 58.9 Precision= 72.6 Recall=49.55 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.01 Precision= 67.71 Recall=60.69 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.73 Precision= 69.94 Recall=60.24 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.9 Precision= 72.69 Recall=61.96 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.89 Precision= 76.33 Recall=56.42 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 66.94 Precision= 71.1 Recall=63.23 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.17 Precision= 73.42 Recall=63.61 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.27 Precision= 71.79 Recall=65.08 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.94 Precision= 75.15 Recall=63.68 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.04 Precision= 70.39 Recall=67.75 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.55 Precision= 71.17 Recall=68.0 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.35 Precision= 71.86 Recall=68.89 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.72 Precision= 72.79 Recall=68.77 epochs= 23 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.76 Precision= 75.4 Recall=66.67 epochs= 24 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.78 Precision= 74.49 Recall=67.43 epochs= 25 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.48 Precision= 74.57 Recall=68.64 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.0 Precision= 73.65 Recall=70.42 epochs= 36 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.2 Precision= 75.57 Recall=67.3 epochs= 40 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzLQDP4RJImI",
        "outputId": "b97a3e1d-83d9-42dd-ba28-8c5428eec2ab"
      },
      "source": [
        "\n",
        "X_embeddings= X_fasttext \n",
        "embedding_name=X_fasttext_name\n",
        "\n",
        "random_split=False\n",
        "use_features=False \n",
        "character_embedding =Char_type(\"CNN\")\n",
        "\n",
        "\n",
        "if (use_features and character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (use_features):\n",
        "  X_train, X_test, Y_train, Y_test, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, emb_size=split(X_embeddings)\n",
        "\n",
        "else:\n",
        "  X_train, X_test, Y_train, Y_test, emb_size=split(X_embeddings)\n",
        "\n",
        "\n",
        "lstm_units=200 #500\n",
        "activation_function=\"hard_sigmoid\" # relu\n",
        "embedding_dropout=0.3\n",
        "lstm_dropout=0.5\n",
        "optimizer=\"nadam\"\n",
        "dense_dropout=0.3 \n",
        "second_layer=False\n",
        "dense_units=150\n",
        "val=0.0\n",
        "batch_size=5\n",
        "epochs=1\n",
        "variational_dropout= False\n",
        "\n",
        "for cc in range(2):\n",
        "    df1= experiment(40, False, \"FastText_Char\", epochs) ## experiment ( number of epochs, repeate runs or increase epochs , name of csv file)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_embedding  (909, 100, 300)\n",
            "Y_oneHot  (909, 100, 9)\n",
            "X_train  (681, 100, 300)\n",
            "X_test  (228, 100, 300)\n",
            "Y_train  (681, 100, 9)\n",
            "Y_test  (228, 100, 9)\n",
            "X_char_tr  (681, 100, 16)\n",
            "X_char_tr  (228, 100, 16)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_input (InputLayer)         (None, 100, 16, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_embedding (TimeDistributed (None, 100, 16, 1, 2 3450        char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 100, 16, 1, 2 5650        char_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 100, 16, 1, 2 0           time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 100, 400)     0           time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 100, 700)     0           word_input[0][0]                 \n",
            "                                                                 time_distributed_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 100, 700)     0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 100, 400)     1441600     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 100, 150)     60150       bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100, 150)     0           time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "crf_1 (CRF)                     (None, 100, 9)       1458        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,512,308\n",
            "Trainable params: 1,512,308\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 62s 90ms/step - loss: 0.3618 - crf_viterbi_accuracy: 0.9051 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 2s 7ms/step\n",
            "F1-score= 38.62 Precision= 42.8 Recall=35.18 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.2054 - crf_viterbi_accuracy: 0.9345 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.62 Precision= 42.8 Recall=35.18 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.04 Precision= 50.5 Recall=51.59 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.1545 - crf_viterbi_accuracy: 0.9448 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1277 - crf_viterbi_accuracy: 0.9515 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.62 Precision= 42.8 Recall=35.18 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.04 Precision= 50.5 Recall=51.59 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.77 Precision= 68.02 Recall=53.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1060 - crf_viterbi_accuracy: 0.9561 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.62 Precision= 42.8 Recall=35.18 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.04 Precision= 50.5 Recall=51.59 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.77 Precision= 68.02 Recall=53.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.59 Precision= 73.97 Recall=57.32 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0865 - crf_viterbi_accuracy: 0.9619 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.62 Precision= 42.8 Recall=35.18 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.04 Precision= 50.5 Recall=51.59 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.77 Precision= 68.02 Recall=53.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.59 Precision= 73.97 Recall=57.32 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.16 Precision= 74.5 Recall=61.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0717 - crf_viterbi_accuracy: 0.9658 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0644 - crf_viterbi_accuracy: 0.9668 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.62 Precision= 42.8 Recall=35.18 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.04 Precision= 50.5 Recall=51.59 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.77 Precision= 68.02 Recall=53.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.59 Precision= 73.97 Recall=57.32 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.16 Precision= 74.5 Recall=61.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.91 Precision= 72.36 Recall=65.78 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0529 - crf_viterbi_accuracy: 0.9699 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0449 - crf_viterbi_accuracy: 0.9720 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.62 Precision= 42.8 Recall=35.18 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.04 Precision= 50.5 Recall=51.59 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.77 Precision= 68.02 Recall=53.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.59 Precision= 73.97 Recall=57.32 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.16 Precision= 74.5 Recall=61.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.91 Precision= 72.36 Recall=65.78 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 76.0 Recall=60.62 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0371 - crf_viterbi_accuracy: 0.9735 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.62 Precision= 42.8 Recall=35.18 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.04 Precision= 50.5 Recall=51.59 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.77 Precision= 68.02 Recall=53.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.59 Precision= 73.97 Recall=57.32 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.16 Precision= 74.5 Recall=61.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.91 Precision= 72.36 Recall=65.78 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 76.0 Recall=60.62 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.57 Precision= 72.29 Recall=67.05 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0279 - crf_viterbi_accuracy: 0.9767 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0210 - crf_viterbi_accuracy: 0.9790 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0154 - crf_viterbi_accuracy: 0.9794 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.62 Precision= 42.8 Recall=35.18 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.04 Precision= 50.5 Recall=51.59 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.77 Precision= 68.02 Recall=53.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.59 Precision= 73.97 Recall=57.32 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.16 Precision= 74.5 Recall=61.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.91 Precision= 72.36 Recall=65.78 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 76.0 Recall=60.62 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.57 Precision= 72.29 Recall=67.05 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.89 Precision= 72.23 Recall=67.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0096 - crf_viterbi_accuracy: 0.9807 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0059 - crf_viterbi_accuracy: 0.9810 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.62 Precision= 42.8 Recall=35.18 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.04 Precision= 50.5 Recall=51.59 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.77 Precision= 68.02 Recall=53.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.59 Precision= 73.97 Recall=57.32 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.16 Precision= 74.5 Recall=61.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.91 Precision= 72.36 Recall=65.78 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 76.0 Recall=60.62 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.57 Precision= 72.29 Recall=67.05 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.89 Precision= 72.23 Recall=67.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.91 Precision= 76.4 Recall=64.44 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0010 - crf_viterbi_accuracy: 0.9818 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0045 - crf_viterbi_accuracy: 0.9834 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0083 - crf_viterbi_accuracy: 0.9834 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0152 - crf_viterbi_accuracy: 0.9843 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.62 Precision= 42.8 Recall=35.18 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.04 Precision= 50.5 Recall=51.59 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.77 Precision= 68.02 Recall=53.31 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.59 Precision= 73.97 Recall=57.32 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.16 Precision= 74.5 Recall=61.13 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.91 Precision= 72.36 Recall=65.78 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.45 Precision= 76.0 Recall=60.62 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.57 Precision= 72.29 Recall=67.05 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.89 Precision= 72.23 Recall=67.68 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.91 Precision= 76.4 Recall=64.44 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.2 Precision= 75.66 Recall=67.24 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0190 - crf_viterbi_accuracy: 0.9860 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0233 - crf_viterbi_accuracy: 0.9858 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0279 - crf_viterbi_accuracy: 0.9871 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0304 - crf_viterbi_accuracy: 0.9867 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0362 - crf_viterbi_accuracy: 0.9878 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0391 - crf_viterbi_accuracy: 0.9878 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0427 - crf_viterbi_accuracy: 0.9885 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0443 - crf_viterbi_accuracy: 0.9879 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0481 - crf_viterbi_accuracy: 0.9884 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_input (InputLayer)         (None, 100, 16, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_embedding (TimeDistributed (None, 100, 16, 1, 2 3450        char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 100, 16, 1, 2 5650        char_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 100, 16, 1, 2 0           time_distributed_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistrib (None, 100, 400)     0           time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 100, 700)     0           word_input[0][0]                 \n",
            "                                                                 time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 100, 700)     0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 100, 400)     1441600     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_8 (TimeDistrib (None, 100, 150)     60150       bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 100, 150)     0           time_distributed_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "crf_2 (CRF)                     (None, 100, 9)       1458        dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,512,308\n",
            "Trainable params: 1,512,308\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 64ms/step - loss: 0.4175 - crf_viterbi_accuracy: 0.8972 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 2s 7ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.2295 - crf_viterbi_accuracy: 0.9309 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1734 - crf_viterbi_accuracy: 0.9425 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1402 - crf_viterbi_accuracy: 0.9500 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1182 - crf_viterbi_accuracy: 0.9550 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0992 - crf_viterbi_accuracy: 0.9586 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0860 - crf_viterbi_accuracy: 0.9615 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.8 Precision= 76.29 Recall=61.01 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0725 - crf_viterbi_accuracy: 0.9658 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0627 - crf_viterbi_accuracy: 0.9681 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.8 Precision= 76.29 Recall=61.01 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.34 Precision= 73.71 Recall=65.46 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0545 - crf_viterbi_accuracy: 0.9700 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.8 Precision= 76.29 Recall=61.01 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.34 Precision= 73.71 Recall=65.46 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.72 Precision= 74.84 Recall=65.27 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0441 - crf_viterbi_accuracy: 0.9727 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0355 - crf_viterbi_accuracy: 0.9759 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.8 Precision= 76.29 Recall=61.01 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.34 Precision= 73.71 Recall=65.46 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.72 Precision= 74.84 Recall=65.27 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 74.86 Recall=66.09 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0290 - crf_viterbi_accuracy: 0.9767 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0226 - crf_viterbi_accuracy: 0.9789 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0181 - crf_viterbi_accuracy: 0.9788 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0126 - crf_viterbi_accuracy: 0.9794 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.8 Precision= 76.29 Recall=61.01 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.34 Precision= 73.71 Recall=65.46 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.72 Precision= 74.84 Recall=65.27 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 74.86 Recall=66.09 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.39 Precision= 72.3 Recall=68.58 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0066 - crf_viterbi_accuracy: 0.9809 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.8 Precision= 76.29 Recall=61.01 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.34 Precision= 73.71 Recall=65.46 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.72 Precision= 74.84 Recall=65.27 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 74.86 Recall=66.09 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.39 Precision= 72.3 Recall=68.58 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.4 Precision= 74.98 Recall=66.35 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0024 - crf_viterbi_accuracy: 0.9810 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0039 - crf_viterbi_accuracy: 0.9834 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0068 - crf_viterbi_accuracy: 0.9840 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.8 Precision= 76.29 Recall=61.01 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.34 Precision= 73.71 Recall=65.46 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.72 Precision= 74.84 Recall=65.27 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 74.86 Recall=66.09 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.39 Precision= 72.3 Recall=68.58 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.4 Precision= 74.98 Recall=66.35 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.42 Precision= 71.6 Recall=67.37 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 62ms/step - loss: -0.0117 - crf_viterbi_accuracy: 0.9844 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0163 - crf_viterbi_accuracy: 0.9849 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0197 - crf_viterbi_accuracy: 0.9849 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0250 - crf_viterbi_accuracy: 0.9866 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.8 Precision= 76.29 Recall=61.01 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.34 Precision= 73.71 Recall=65.46 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.72 Precision= 74.84 Recall=65.27 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 74.86 Recall=66.09 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.39 Precision= 72.3 Recall=68.58 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.4 Precision= 74.98 Recall=66.35 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.42 Precision= 71.6 Recall=67.37 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.16 Precision= 74.56 Recall=69.91 epochs= 24 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0285 - crf_viterbi_accuracy: 0.9867 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0329 - crf_viterbi_accuracy: 0.9880 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.8 Precision= 76.29 Recall=61.01 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.34 Precision= 73.71 Recall=65.46 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.72 Precision= 74.84 Recall=65.27 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 74.86 Recall=66.09 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.39 Precision= 72.3 Recall=68.58 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.4 Precision= 74.98 Recall=66.35 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.42 Precision= 71.6 Recall=67.37 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.16 Precision= 74.56 Recall=69.91 epochs= 24 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.58 Precision= 76.92 Recall=68.7 epochs= 26 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0369 - crf_viterbi_accuracy: 0.9887 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0391 - crf_viterbi_accuracy: 0.9877 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.8 Precision= 76.29 Recall=61.01 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.34 Precision= 73.71 Recall=65.46 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.72 Precision= 74.84 Recall=65.27 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 74.86 Recall=66.09 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.39 Precision= 72.3 Recall=68.58 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.4 Precision= 74.98 Recall=66.35 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.42 Precision= 71.6 Recall=67.37 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.16 Precision= 74.56 Recall=69.91 epochs= 24 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.58 Precision= 76.92 Recall=68.7 epochs= 26 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 73.07 Precision= 77.94 Recall=68.77 epochs= 28 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 62ms/step - loss: -0.0425 - crf_viterbi_accuracy: 0.9883 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0469 - crf_viterbi_accuracy: 0.9888 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 24.83 Precision= 29.48 Recall=21.44 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 42.91 Precision= 55.14 Recall=35.11 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 56.35 Precision= 63.53 Recall=50.64 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 59.92 Precision= 69.37 Recall=52.74 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.77 Precision= 66.47 Recall=55.98 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.76 Precision= 71.05 Recall=61.2 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.8 Precision= 76.29 Recall=61.01 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.34 Precision= 73.71 Recall=65.46 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.72 Precision= 74.84 Recall=65.27 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.2 Precision= 74.86 Recall=66.09 epochs= 12 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.39 Precision= 72.3 Recall=68.58 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.4 Precision= 74.98 Recall=66.35 epochs= 17 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.42 Precision= 71.6 Recall=67.37 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.16 Precision= 74.56 Recall=69.91 epochs= 24 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.58 Precision= 76.92 Recall=68.7 epochs= 26 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 73.07 Precision= 77.94 Recall=68.77 epochs= 28 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.69 Precision= 74.33 Recall=65.59 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0492 - crf_viterbi_accuracy: 0.9880 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0517 - crf_viterbi_accuracy: 0.9890 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0565 - crf_viterbi_accuracy: 0.9902 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0585 - crf_viterbi_accuracy: 0.9887 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0632 - crf_viterbi_accuracy: 0.9902 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0670 - crf_viterbi_accuracy: 0.9910 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0690 - crf_viterbi_accuracy: 0.9899 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcB7sAJyJIvo",
        "outputId": "40459cf9-f674-41e7-c08e-a1b74562a79d"
      },
      "source": [
        "\n",
        "X_embeddings= X_fasttext \n",
        "embedding_name=X_fasttext_name\n",
        "\n",
        "random_split=False\n",
        "use_features=True \n",
        "character_embedding =Char_type(\"CNN\")\n",
        "\n",
        "\n",
        "if (use_features and character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (use_features):\n",
        "  X_train, X_test, Y_train, Y_test, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, emb_size=split(X_embeddings)\n",
        "\n",
        "else:\n",
        "  X_train, X_test, Y_train, Y_test, emb_size=split(X_embeddings)\n",
        "\n",
        "\n",
        "lstm_units=200 #500\n",
        "activation_function=\"hard_sigmoid\" # relu\n",
        "embedding_dropout=0.3\n",
        "lstm_dropout=0.5\n",
        "optimizer=\"nadam\"\n",
        "dense_dropout=0.3 \n",
        "second_layer=False\n",
        "dense_units=150\n",
        "val=0.0\n",
        "batch_size=5\n",
        "epochs=1\n",
        "variational_dropout= False\n",
        "\n",
        "for cc in range(4):\n",
        "    df1= experiment(40, False, \"FastText_Fea_Char\", epochs) ## experiment ( number of epochs, repeate runs or increase epochs , name of csv file)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_embedding  (909, 100, 300)\n",
            "Y_oneHot  (909, 100, 9)\n",
            "X_train  (681, 100, 300)\n",
            "X_test  (228, 100, 300)\n",
            "Y_train  (681, 100, 9)\n",
            "Y_test  (228, 100, 9)\n",
            "X_char_tr  (681, 100, 16)\n",
            "X_char_tr  (228, 100, 16)\n",
            "X_fea_tr  (681, 100, 123)\n",
            "X_fea_te  (228, 100, 123)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_input (InputLayer)         (None, 100, 16, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_embedding (TimeDistributed (None, 100, 16, 1, 2 3450        char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_9 (TimeDistrib (None, 100, 16, 1, 2 5650        char_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_input (InputLayer)      (None, 100, 123)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_10 (TimeDistri (None, 100, 16, 1, 2 0           time_distributed_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 100, 423)     0           word_input[0][0]                 \n",
            "                                                                 feature_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_11 (TimeDistri (None, 100, 400)     0           time_distributed_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 100, 823)     0           concatenate_3[0][0]              \n",
            "                                                                 time_distributed_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 100, 823)     0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 100, 400)     1638400     dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_12 (TimeDistri (None, 100, 150)     60150       bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 100, 150)     0           time_distributed_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "crf_3 (CRF)                     (None, 100, 9)       1458        dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,709,108\n",
            "Trainable params: 1,709,108\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.4139 - crf_viterbi_accuracy: 0.8970 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 2s 8ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.2264 - crf_viterbi_accuracy: 0.9316 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.49 Precision= 51.84 Recall=51.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1692 - crf_viterbi_accuracy: 0.9434 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.49 Precision= 51.84 Recall=51.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.72 Precision= 69.47 Recall=49.36 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.1386 - crf_viterbi_accuracy: 0.9499 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.49 Precision= 51.84 Recall=51.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.72 Precision= 69.47 Recall=49.36 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.01 Precision= 66.74 Recall=54.52 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1148 - crf_viterbi_accuracy: 0.9545 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.49 Precision= 51.84 Recall=51.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.72 Precision= 69.47 Recall=49.36 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.01 Precision= 66.74 Recall=54.52 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 65.69 Recall=57.25 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0982 - crf_viterbi_accuracy: 0.9589 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0831 - crf_viterbi_accuracy: 0.9611 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.49 Precision= 51.84 Recall=51.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.72 Precision= 69.47 Recall=49.36 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.01 Precision= 66.74 Recall=54.52 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 65.69 Recall=57.25 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.28 Precision= 65.67 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0700 - crf_viterbi_accuracy: 0.9658 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.49 Precision= 51.84 Recall=51.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.72 Precision= 69.47 Recall=49.36 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.01 Precision= 66.74 Recall=54.52 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 65.69 Recall=57.25 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.28 Precision= 65.67 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.98 Precision= 72.91 Recall=63.68 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0609 - crf_viterbi_accuracy: 0.9671 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0509 - crf_viterbi_accuracy: 0.9701 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.49 Precision= 51.84 Recall=51.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.72 Precision= 69.47 Recall=49.36 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.01 Precision= 66.74 Recall=54.52 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 65.69 Recall=57.25 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.28 Precision= 65.67 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.98 Precision= 72.91 Recall=63.68 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.26 Precision= 71.47 Recall=65.33 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0424 - crf_viterbi_accuracy: 0.9720 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0352 - crf_viterbi_accuracy: 0.9733 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0291 - crf_viterbi_accuracy: 0.9741 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0196 - crf_viterbi_accuracy: 0.9770 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.49 Precision= 51.84 Recall=51.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.72 Precision= 69.47 Recall=49.36 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.01 Precision= 66.74 Recall=54.52 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 65.69 Recall=57.25 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.28 Precision= 65.67 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.98 Precision= 72.91 Recall=63.68 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.26 Precision= 71.47 Recall=65.33 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.92 Precision= 73.57 Recall=64.82 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0157 - crf_viterbi_accuracy: 0.9775 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.49 Precision= 51.84 Recall=51.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.72 Precision= 69.47 Recall=49.36 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.01 Precision= 66.74 Recall=54.52 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 65.69 Recall=57.25 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.28 Precision= 65.67 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.98 Precision= 72.91 Recall=63.68 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.26 Precision= 71.47 Recall=65.33 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.92 Precision= 73.57 Recall=64.82 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.65 Precision= 71.03 Recall=68.32 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0092 - crf_viterbi_accuracy: 0.9785 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.49 Precision= 51.84 Recall=51.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.72 Precision= 69.47 Recall=49.36 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.01 Precision= 66.74 Recall=54.52 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 65.69 Recall=57.25 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.28 Precision= 65.67 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.98 Precision= 72.91 Recall=63.68 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.26 Precision= 71.47 Recall=65.33 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.92 Precision= 73.57 Recall=64.82 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.65 Precision= 71.03 Recall=68.32 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.3 Precision= 75.07 Recall=66.09 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0053 - crf_viterbi_accuracy: 0.9794 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0031 - crf_viterbi_accuracy: 0.9823 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0057 - crf_viterbi_accuracy: 0.9818 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0112 - crf_viterbi_accuracy: 0.9835 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 21.58 Precision= 39.69 Recall=14.82 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 51.49 Precision= 51.84 Recall=51.15 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 57.72 Precision= 69.47 Recall=49.36 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.01 Precision= 66.74 Recall=54.52 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.18 Precision= 65.69 Recall=57.25 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 61.28 Precision= 65.67 Recall=57.44 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.98 Precision= 72.91 Recall=63.68 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.26 Precision= 71.47 Recall=65.33 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.92 Precision= 73.57 Recall=64.82 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.65 Precision= 71.03 Recall=68.32 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.3 Precision= 75.07 Recall=66.09 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.63 Precision= 72.52 Recall=65.14 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0167 - crf_viterbi_accuracy: 0.9834 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0196 - crf_viterbi_accuracy: 0.9838 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0252 - crf_viterbi_accuracy: 0.9853 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0283 - crf_viterbi_accuracy: 0.9849 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0314 - crf_viterbi_accuracy: 0.9853 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_input (InputLayer)         (None, 100, 16, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_embedding (TimeDistributed (None, 100, 16, 1, 2 3450        char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_13 (TimeDistri (None, 100, 16, 1, 2 5650        char_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_input (InputLayer)      (None, 100, 123)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_14 (TimeDistri (None, 100, 16, 1, 2 0           time_distributed_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 100, 423)     0           word_input[0][0]                 \n",
            "                                                                 feature_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_15 (TimeDistri (None, 100, 400)     0           time_distributed_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 100, 823)     0           concatenate_5[0][0]              \n",
            "                                                                 time_distributed_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 100, 823)     0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 100, 400)     1638400     dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_16 (TimeDistri (None, 100, 150)     60150       bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 100, 150)     0           time_distributed_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "crf_4 (CRF)                     (None, 100, 9)       1458        dropout_8[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,709,108\n",
            "Trainable params: 1,709,108\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: 0.3443 - crf_viterbi_accuracy: 0.9072 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 2s 9ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1924 - crf_viterbi_accuracy: 0.9364 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1427 - crf_viterbi_accuracy: 0.9476 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1172 - crf_viterbi_accuracy: 0.9542 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 62ms/step - loss: 0.0949 - crf_viterbi_accuracy: 0.9576 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0809 - crf_viterbi_accuracy: 0.9615 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0683 - crf_viterbi_accuracy: 0.9658 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0564 - crf_viterbi_accuracy: 0.9684 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0462 - crf_viterbi_accuracy: 0.9710 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0372 - crf_viterbi_accuracy: 0.9727 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.68 Precision= 73.78 Recall=64.25 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0296 - crf_viterbi_accuracy: 0.9750 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.68 Precision= 73.78 Recall=64.25 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.68 Precision= 74.82 Recall=65.2 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0224 - crf_viterbi_accuracy: 0.9760 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0168 - crf_viterbi_accuracy: 0.9769 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0099 - crf_viterbi_accuracy: 0.9788 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.68 Precision= 73.78 Recall=64.25 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.68 Precision= 74.82 Recall=65.2 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.25 Precision= 73.39 Recall=67.37 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0068 - crf_viterbi_accuracy: 0.9796 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0022 - crf_viterbi_accuracy: 0.9819 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.68 Precision= 73.78 Recall=64.25 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.68 Precision= 74.82 Recall=65.2 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.25 Precision= 73.39 Recall=67.37 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.0 Recall=68.26 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0081 - crf_viterbi_accuracy: 0.9827 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0116 - crf_viterbi_accuracy: 0.9822 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0154 - crf_viterbi_accuracy: 0.9839 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.68 Precision= 73.78 Recall=64.25 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.68 Precision= 74.82 Recall=65.2 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.25 Precision= 73.39 Recall=67.37 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.0 Recall=68.26 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.56 Precision= 75.28 Recall=68.19 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0190 - crf_viterbi_accuracy: 0.9841 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.68 Precision= 73.78 Recall=64.25 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.68 Precision= 74.82 Recall=65.2 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.25 Precision= 73.39 Recall=67.37 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.0 Recall=68.26 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.56 Precision= 75.28 Recall=68.19 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.42 Precision= 75.44 Recall=67.81 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0249 - crf_viterbi_accuracy: 0.9855 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.68 Precision= 73.78 Recall=64.25 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.68 Precision= 74.82 Recall=65.2 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.25 Precision= 73.39 Recall=67.37 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.0 Recall=68.26 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.56 Precision= 75.28 Recall=68.19 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.42 Precision= 75.44 Recall=67.81 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.06 Precision= 74.64 Recall=69.66 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0293 - crf_viterbi_accuracy: 0.9854 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0323 - crf_viterbi_accuracy: 0.9864 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0364 - crf_viterbi_accuracy: 0.9870 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0402 - crf_viterbi_accuracy: 0.9870 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0438 - crf_viterbi_accuracy: 0.9872 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0494 - crf_viterbi_accuracy: 0.9889 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0505 - crf_viterbi_accuracy: 0.9881 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.68 Precision= 73.78 Recall=64.25 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.68 Precision= 74.82 Recall=65.2 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.25 Precision= 73.39 Recall=67.37 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.0 Recall=68.26 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.56 Precision= 75.28 Recall=68.19 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.42 Precision= 75.44 Recall=67.81 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.06 Precision= 74.64 Recall=69.66 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.17 Precision= 75.31 Recall=69.27 epochs= 28 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0540 - crf_viterbi_accuracy: 0.9888 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0589 - crf_viterbi_accuracy: 0.9895 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.68 Precision= 73.78 Recall=64.25 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.68 Precision= 74.82 Recall=65.2 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.25 Precision= 73.39 Recall=67.37 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.0 Recall=68.26 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.56 Precision= 75.28 Recall=68.19 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.42 Precision= 75.44 Recall=67.81 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.06 Precision= 74.64 Recall=69.66 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.17 Precision= 75.31 Recall=69.27 epochs= 28 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.27 Precision= 74.84 Recall=66.22 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0630 - crf_viterbi_accuracy: 0.9903 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0656 - crf_viterbi_accuracy: 0.9903 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0693 - crf_viterbi_accuracy: 0.9906 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0716 - crf_viterbi_accuracy: 0.9906 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0747 - crf_viterbi_accuracy: 0.9909 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0800 - crf_viterbi_accuracy: 0.9918 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.68 Precision= 73.78 Recall=64.25 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.68 Precision= 74.82 Recall=65.2 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.25 Precision= 73.39 Recall=67.37 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.0 Recall=68.26 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.56 Precision= 75.28 Recall=68.19 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.42 Precision= 75.44 Recall=67.81 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.06 Precision= 74.64 Recall=69.66 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.17 Precision= 75.31 Recall=69.27 epochs= 28 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.27 Precision= 74.84 Recall=66.22 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 73.07 Precision= 75.42 Recall=70.87 epochs= 36 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0810 - crf_viterbi_accuracy: 0.9906 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0829 - crf_viterbi_accuracy: 0.9903 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0866 - crf_viterbi_accuracy: 0.9909 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0900 - crf_viterbi_accuracy: 0.9911 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 41.75 Precision= 43.28 Recall=40.33 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 52.12 Precision= 47.35 Recall=57.95 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 54.49 Precision= 69.11 Recall=44.97 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.23 Precision= 68.02 Recall=62.66 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.95 Precision= 75.85 Recall=58.33 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.24 Precision= 72.51 Recall=64.44 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.36 Precision= 74.42 Recall=64.95 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.68 Precision= 73.78 Recall=64.25 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.68 Precision= 74.82 Recall=65.2 epochs= 11 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.25 Precision= 73.39 Recall=67.37 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.01 Precision= 74.0 Recall=68.26 epochs= 16 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.56 Precision= 75.28 Recall=68.19 epochs= 19 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.42 Precision= 75.44 Recall=67.81 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.06 Precision= 74.64 Recall=69.66 epochs= 21 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.17 Precision= 75.31 Recall=69.27 epochs= 28 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.27 Precision= 74.84 Recall=66.22 epochs= 30 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 73.07 Precision= 75.42 Recall=70.87 epochs= 36 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.66 Precision= 76.86 Recall=68.89 epochs= 40 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_input (InputLayer)         (None, 100, 16, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_embedding (TimeDistributed (None, 100, 16, 1, 2 3450        char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_17 (TimeDistri (None, 100, 16, 1, 2 5650        char_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_input (InputLayer)      (None, 100, 123)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_18 (TimeDistri (None, 100, 16, 1, 2 0           time_distributed_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 100, 423)     0           word_input[0][0]                 \n",
            "                                                                 feature_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_19 (TimeDistri (None, 100, 400)     0           time_distributed_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 100, 823)     0           concatenate_7[0][0]              \n",
            "                                                                 time_distributed_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 100, 823)     0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 100, 400)     1638400     dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_20 (TimeDistri (None, 100, 150)     60150       bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 150)     0           time_distributed_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "crf_5 (CRF)                     (None, 100, 9)       1458        dropout_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,709,108\n",
            "Trainable params: 1,709,108\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 45s 65ms/step - loss: 0.3670 - crf_viterbi_accuracy: 0.9064 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 2s 10ms/step\n",
            "F1-score= 42.21 Precision= 49.66 Recall=36.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.2054 - crf_viterbi_accuracy: 0.9365 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 42.21 Precision= 49.66 Recall=36.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.45 Precision= 55.6 Recall=44.53 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1606 - crf_viterbi_accuracy: 0.9455 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 42.21 Precision= 49.66 Recall=36.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.45 Precision= 55.6 Recall=44.53 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.69 Precision= 63.71 Recall=57.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1302 - crf_viterbi_accuracy: 0.9533 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.1087 - crf_viterbi_accuracy: 0.9586 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 42.21 Precision= 49.66 Recall=36.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.45 Precision= 55.6 Recall=44.53 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.69 Precision= 63.71 Recall=57.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.89 Precision= 66.46 Recall=61.51 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0913 - crf_viterbi_accuracy: 0.9618 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 42.21 Precision= 49.66 Recall=36.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.45 Precision= 55.6 Recall=44.53 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.69 Precision= 63.71 Recall=57.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.89 Precision= 66.46 Recall=61.51 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.92 Precision= 72.11 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0813 - crf_viterbi_accuracy: 0.9644 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 42.21 Precision= 49.66 Recall=36.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.45 Precision= 55.6 Recall=44.53 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.69 Precision= 63.71 Recall=57.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.89 Precision= 66.46 Recall=61.51 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.92 Precision= 72.11 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.67 Precision= 73.25 Recall=64.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0686 - crf_viterbi_accuracy: 0.9668 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0588 - crf_viterbi_accuracy: 0.9693 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 42.21 Precision= 49.66 Recall=36.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.45 Precision= 55.6 Recall=44.53 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.69 Precision= 63.71 Recall=57.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.89 Precision= 66.46 Recall=61.51 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.92 Precision= 72.11 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.67 Precision= 73.25 Recall=64.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.87 Precision= 72.34 Recall=65.71 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0503 - crf_viterbi_accuracy: 0.9719 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 42.21 Precision= 49.66 Recall=36.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.45 Precision= 55.6 Recall=44.53 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.69 Precision= 63.71 Recall=57.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.89 Precision= 66.46 Recall=61.51 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.92 Precision= 72.11 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.67 Precision= 73.25 Recall=64.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.87 Precision= 72.34 Recall=65.71 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.86 Precision= 73.37 Recall=68.51 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0415 - crf_viterbi_accuracy: 0.9739 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0347 - crf_viterbi_accuracy: 0.9759 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.0285 - crf_viterbi_accuracy: 0.9769 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 42.21 Precision= 49.66 Recall=36.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.45 Precision= 55.6 Recall=44.53 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.69 Precision= 63.71 Recall=57.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.89 Precision= 66.46 Recall=61.51 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.92 Precision= 72.11 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.67 Precision= 73.25 Recall=64.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.87 Precision= 72.34 Recall=65.71 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.86 Precision= 73.37 Recall=68.51 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.9 Precision= 75.63 Recall=66.73 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0211 - crf_viterbi_accuracy: 0.9786 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 42.21 Precision= 49.66 Recall=36.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.45 Precision= 55.6 Recall=44.53 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.69 Precision= 63.71 Recall=57.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.89 Precision= 66.46 Recall=61.51 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.92 Precision= 72.11 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.67 Precision= 73.25 Recall=64.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.87 Precision= 72.34 Recall=65.71 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.86 Precision= 73.37 Recall=68.51 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.9 Precision= 75.63 Recall=66.73 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.87 Precision= 72.24 Recall=71.5 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0171 - crf_viterbi_accuracy: 0.9795 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0093 - crf_viterbi_accuracy: 0.9816 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0041 - crf_viterbi_accuracy: 0.9832 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 8.1478e-04 - crf_viterbi_accuracy: 0.9825 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0035 - crf_viterbi_accuracy: 0.9835 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 44s 64ms/step - loss: -0.0078 - crf_viterbi_accuracy: 0.9842 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 42.21 Precision= 49.66 Recall=36.7 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 49.45 Precision= 55.6 Recall=44.53 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.69 Precision= 63.71 Recall=57.95 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.89 Precision= 66.46 Recall=61.51 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 64.92 Precision= 72.11 Recall=59.03 epochs= 6 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.67 Precision= 73.25 Recall=64.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 68.87 Precision= 72.34 Recall=65.71 epochs= 9 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.86 Precision= 73.37 Recall=68.51 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.9 Precision= 75.63 Recall=66.73 epochs= 13 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.87 Precision= 72.24 Recall=71.5 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 72.43 Precision= 77.23 Recall=68.19 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0125 - crf_viterbi_accuracy: 0.9848 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: -0.0171 - crf_viterbi_accuracy: 0.9856 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0218 - crf_viterbi_accuracy: 0.9873 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0253 - crf_viterbi_accuracy: 0.9875 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0293 - crf_viterbi_accuracy: 0.9873 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0325 - crf_viterbi_accuracy: 0.9876 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0363 - crf_viterbi_accuracy: 0.9885 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0402 - crf_viterbi_accuracy: 0.9889 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0434 - crf_viterbi_accuracy: 0.9896 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_input (InputLayer)         (None, 100, 16, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_embedding (TimeDistributed (None, 100, 16, 1, 2 3450        char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_21 (TimeDistri (None, 100, 16, 1, 2 5650        char_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "word_input (InputLayer)         (None, 100, 300)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_input (InputLayer)      (None, 100, 123)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_22 (TimeDistri (None, 100, 16, 1, 2 0           time_distributed_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 100, 423)     0           word_input[0][0]                 \n",
            "                                                                 feature_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_23 (TimeDistri (None, 100, 400)     0           time_distributed_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 100, 823)     0           concatenate_9[0][0]              \n",
            "                                                                 time_distributed_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 100, 823)     0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 100, 400)     1638400     dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_24 (TimeDistri (None, 100, 150)     60150       bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 100, 150)     0           time_distributed_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "crf_6 (CRF)                     (None, 100, 9)       1458        dropout_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,709,108\n",
            "Trainable params: 1,709,108\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 63ms/step - loss: 0.3801 - crf_viterbi_accuracy: 0.9077 - accuracy: 0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,crf_viterbi_accuracy,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228/228 [==============================] - 2s 11ms/step\n",
            "F1-score= 38.26 Precision= 46.74 Recall=32.38 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.2115 - crf_viterbi_accuracy: 0.9366 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.26 Precision= 46.74 Recall=32.38 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.19 Precision= 41.28 Recall=52.42 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.1626 - crf_viterbi_accuracy: 0.9465 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.26 Precision= 46.74 Recall=32.38 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.19 Precision= 41.28 Recall=52.42 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.14 Precision= 67.59 Recall=46.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.1328 - crf_viterbi_accuracy: 0.9551 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.26 Precision= 46.74 Recall=32.38 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.19 Precision= 41.28 Recall=52.42 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.14 Precision= 67.59 Recall=46.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.68 Precision= 68.31 Recall=54.58 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 43s 62ms/step - loss: 0.1131 - crf_viterbi_accuracy: 0.9577 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.26 Precision= 46.74 Recall=32.38 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.19 Precision= 41.28 Recall=52.42 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.14 Precision= 67.59 Recall=46.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.68 Precision= 68.31 Recall=54.58 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.6 Precision= 71.04 Recall=57.57 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0950 - crf_viterbi_accuracy: 0.9611 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0790 - crf_viterbi_accuracy: 0.9642 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.26 Precision= 46.74 Recall=32.38 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.19 Precision= 41.28 Recall=52.42 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.14 Precision= 67.59 Recall=46.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.68 Precision= 68.31 Recall=54.58 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.6 Precision= 71.04 Recall=57.57 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.6 Precision= 76.13 Recall=57.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0678 - crf_viterbi_accuracy: 0.9688 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.26 Precision= 46.74 Recall=32.38 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.19 Precision= 41.28 Recall=52.42 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.14 Precision= 67.59 Recall=46.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.68 Precision= 68.31 Recall=54.58 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.6 Precision= 71.04 Recall=57.57 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.6 Precision= 76.13 Recall=57.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.49 Precision= 67.36 Recall=67.62 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0572 - crf_viterbi_accuracy: 0.9711 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0486 - crf_viterbi_accuracy: 0.9726 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.26 Precision= 46.74 Recall=32.38 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.19 Precision= 41.28 Recall=52.42 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.14 Precision= 67.59 Recall=46.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.68 Precision= 68.31 Recall=54.58 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.6 Precision= 71.04 Recall=57.57 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.6 Precision= 76.13 Recall=57.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.49 Precision= 67.36 Recall=67.62 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.46 Precision= 72.64 Recall=66.54 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0404 - crf_viterbi_accuracy: 0.9751 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0316 - crf_viterbi_accuracy: 0.9774 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0245 - crf_viterbi_accuracy: 0.9792 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0197 - crf_viterbi_accuracy: 0.9798 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.26 Precision= 46.74 Recall=32.38 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.19 Precision= 41.28 Recall=52.42 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.14 Precision= 67.59 Recall=46.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.68 Precision= 68.31 Recall=54.58 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.6 Precision= 71.04 Recall=57.57 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.6 Precision= 76.13 Recall=57.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.49 Precision= 67.36 Recall=67.62 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.46 Precision= 72.64 Recall=66.54 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.14 Precision= 73.75 Recall=66.86 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: 0.0139 - crf_viterbi_accuracy: 0.9804 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.26 Precision= 46.74 Recall=32.38 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.19 Precision= 41.28 Recall=52.42 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.14 Precision= 67.59 Recall=46.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.68 Precision= 68.31 Recall=54.58 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.6 Precision= 71.04 Recall=57.57 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.6 Precision= 76.13 Recall=57.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.49 Precision= 67.36 Recall=67.62 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.46 Precision= 72.64 Recall=66.54 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.14 Precision= 73.75 Recall=66.86 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.74 Precision= 75.14 Recall=68.64 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: 0.0082 - crf_viterbi_accuracy: 0.9807 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: 0.0033 - crf_viterbi_accuracy: 0.9825 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 62ms/step - loss: -0.0030 - crf_viterbi_accuracy: 0.9841 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 42s 61ms/step - loss: -0.0074 - crf_viterbi_accuracy: 0.9853 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: -0.0113 - crf_viterbi_accuracy: 0.9856 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "F1-score= 38.26 Precision= 46.74 Recall=32.38 epochs= 1 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 46.19 Precision= 41.28 Recall=52.42 epochs= 2 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 55.14 Precision= 67.59 Recall=46.56 epochs= 3 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 60.68 Precision= 68.31 Recall=54.58 epochs= 4 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 63.6 Precision= 71.04 Recall=57.57 epochs= 5 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 65.6 Precision= 76.13 Recall=57.63 epochs= 7 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 67.49 Precision= 67.36 Recall=67.62 epochs= 8 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.46 Precision= 72.64 Recall=66.54 epochs= 10 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 70.14 Precision= 73.75 Recall=66.86 epochs= 14 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 71.74 Precision= 75.14 Recall=68.64 epochs= 15 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "F1-score= 69.8 Precision= 75.69 Recall=64.76 epochs= 20 lstm_units= 200 embedding_dropout= 0.3 lstm_dropout= 0.5 activation_function= hard_sigmoid optimizer= nadam dense_dropout= 0.3 second_layer= False dense_units= 150 validation= 0.0 batch_size= 5 variational_dropout= False\n",
            "\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: -0.0146 - crf_viterbi_accuracy: 0.9856 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: -0.0213 - crf_viterbi_accuracy: 0.9871 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 61ms/step - loss: -0.0231 - crf_viterbi_accuracy: 0.9871 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n",
            "Epoch 1/1\n",
            "681/681 [==============================] - 41s 60ms/step - loss: -0.0273 - crf_viterbi_accuracy: 0.9877 - accuracy: 0.0066\n",
            "228/228 [==============================] - 1s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7TsYPa8Z_yv",
        "outputId": "c1a1fef9-4fd9-4c85-a04f-45685c978c14"
      },
      "source": [
        "## examine mispredictions\n",
        "\n",
        "#X_arabert, X_arabert_name= arabert(X_words, \"aubmindlab/bert-large-arabertv02\", \"all\", True,  \"mean\", False, False,1024 )\n",
        "\n",
        "X_embeddings= X_arabert \n",
        "embedding_name=X_arabert_name\n",
        "X_words_te=X_words[681:]  ## 681 is number of training sentences\n",
        "random_split=False\n",
        "use_features=False\n",
        "character_embedding =Char_type(\"NONE\")\n",
        "if (use_features and character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (use_features):\n",
        "  X_train, X_test, Y_train, Y_test, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, emb_size=split(X_embeddings)\n",
        "\n",
        "else:\n",
        "  X_train, X_test, Y_train, Y_test, emb_size=split(X_embeddings)\n",
        "\n",
        "\n",
        "\n",
        "model= load_model(\"/content/drive/MyDrive/Ali lotfy/saved models AQMAR/AraBert 79.48/weights.h5\", \"/content/drive/MyDrive/Ali lotfy/saved models AQMAR/AraBert 79.48/params.json\")\n",
        "#model= load_model(\"/content/drive/MyDrive/Ali lotfy/saved models/Arabert 10 88.06/weights.h5\", \"/content/drive/MyDrive/Ali lotfy/saved models/Arabert 10 88.06/params.json\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "test_pred = model.predict(([np.array(X_test), np.array(X_fea_te) ]), verbose=1)  \n",
        "#test_pred = model.predict(np(X_test), verbose=1)   \n",
        "\n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = pred2label(Y_test)\n",
        "\n",
        "print(classification_report(test_labels, pred_labels, digits=4))\n",
        "print(\"F1: \",f1_score(test_labels, pred_labels))\n",
        "print(\"precision: \",precision_score(test_labels, pred_labels))\n",
        "print(\"recall: \",recall_score(test_labels, pred_labels))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_embedding  (909, 100, 1024)\n",
            "Y_oneHot  (909, 100, 9)\n",
            "X_train  (681, 100, 1024)\n",
            "X_test  (228, 100, 1024)\n",
            "Y_train  (681, 100, 9)\n",
            "Y_test  (228, 100, 9)\n",
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "word_input (InputLayer)         (None, 100, 1024)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_input (InputLayer)      (None, 100, 123)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 100, 1147)    0           word_input[0][0]                 \n",
            "                                                                 feature_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 100, 1147)    0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_14 (Bidirectional (None, 100, 400)     2156800     dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_12 (TimeDistri (None, 100, 150)     60150       bidirectional_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 100, 150)     0           time_distributed_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "crf_12 (CRF)                    (None, 100, 9)       1458        dropout_26[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 2,218,408\n",
            "Trainable params: 2,218,408\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "228/228 [==============================] - 9s 38ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.8405    0.9049    0.8715       326\n",
            "        MISC     0.7263    0.6690    0.6965       722\n",
            "         ORG     0.7170    0.7525    0.7343       101\n",
            "        PERS     0.8963    0.9196    0.9078       423\n",
            "\n",
            "   micro avg     0.7988    0.7907    0.7948      1572\n",
            "   macro avg     0.7950    0.8115    0.8025      1572\n",
            "weighted avg     0.7951    0.7907    0.7921      1572\n",
            "\n",
            "F1:  0.7947570332480819\n",
            "precision:  0.7988431876606684\n",
            "recall:  0.7907124681933843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDU21nOH1ClF",
        "outputId": "6c1f9eb6-61b7-4818-e67c-74e26d649fc5"
      },
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "print(classification_report( test_labels, pred_labels, digits=4))\n",
        "print(\"F1: \",f1_score( test_labels, pred_labels))\n",
        "print(\"precision: \",precision_score( test_labels,  pred_labels))\n",
        "print(\"recall: \",recall_score( test_labels,  pred_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.8857    0.8558    0.8705       326\n",
            "        MISC     0.6710    0.6413    0.6558       722\n",
            "         ORG     0.6942    0.8235    0.7534       102\n",
            "        PERS     0.9221    0.8939    0.9078       424\n",
            "\n",
            "   micro avg     0.7840    0.7656    0.7747      1574\n",
            "   macro avg     0.7933    0.8036    0.7969      1574\n",
            "weighted avg     0.7846    0.7656    0.7745      1574\n",
            "\n",
            "F1:  0.7746705239472838\n",
            "precision:  0.7839947950553026\n",
            "recall:  0.7655654383735705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S8UxgHW0G94"
      },
      "source": [
        "y_true = np.array(test_labels).reshape([-1])\n",
        "y_pred = np.array(pred_labels).reshape([-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viYpt2Zh0VAA",
        "outputId": "78f62eb4-92ff-4c3c-f58f-d3a0ea8b0d60"
      },
      "source": [
        "len(y_true)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19456"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uyw8m5v0ogD"
      },
      "source": [
        "from sklearn.metrics import f1_score , classification_report , recall_score, precision_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVSqTu8i4JiT"
      },
      "source": [
        "labels = ['I-LOC', 'I-MISC', 'B-MISC','B-ORG', 'B-PERS', 'B-LOC', 'I-ORG', 'I-PERS', 'O']\n",
        "labels.remove('O') # remove 'O' label from evaluation\n",
        "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
        "#print(sklearn_crfsuite.metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqdQhMrL4XqH",
        "outputId": "492d5249-8f29-4f6d-d7a6-e8476bd541c5"
      },
      "source": [
        "sorted_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-ORG', 'I-ORG', 'B-PERS', 'I-PERS']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvQlJioZy8-i",
        "outputId": "8d892778-31cb-4448-c06b-742d6f3f8f44"
      },
      "source": [
        "target_names = ['I-LOC', 'I-MISC', 'B-MISC','B-ORG', 'B-PERS', 'B-LOC', 'I-ORG', 'I-PERS', 'O']\n",
        "#print(classification_report(pred_labels, test_labels, target_names=target_names))\n",
        "print(classification_report(y_true, y_pred, labels=sorted_labels, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC     0.8952    0.8677    0.8812       325\n",
            "       I-LOC     0.8903    0.8846    0.8875       156\n",
            "      B-MISC     0.7865    0.7462    0.7658       721\n",
            "      I-MISC     0.7506    0.5996    0.6667       517\n",
            "       B-ORG     0.7672    0.8725    0.8165       102\n",
            "       I-ORG     0.8512    0.8306    0.8408       124\n",
            "      B-PERS     0.9364    0.9033    0.9196       424\n",
            "      I-PERS     0.9755    0.9636    0.9695       330\n",
            "\n",
            "   micro avg     0.8511    0.8007    0.8251      2699\n",
            "   macro avg     0.8566    0.8335    0.8435      2699\n",
            "weighted avg     0.8476    0.8007    0.8222      2699\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxQ7zwcCRLBt"
      },
      "source": [
        "###================ evaluation method ===============\n",
        "#this method evaluate all NEs, hocwver results are different by a small margin\n",
        "\n",
        "def evaluate(test_labels, pred_labels, entity_class, X_words_te):\n",
        "  i=0 # loop on sentences\n",
        "  TP=[0,0,0,0]\n",
        "  FN=[0,0,0,0]\n",
        "  FP=[0,0,0,0]\n",
        "  FPC=[0,0,0,0] # FPC is entities that are not FP, they should equal TP but they are not as there is a condition that is not handeled\n",
        "               #to do : add the difference between FPC and TP to FP.\n",
        "\n",
        "  classes = ['PERS', 'LOC', 'ORG', 'MISC']\n",
        "  i=0\n",
        "  count= 0\n",
        "  print(\"{:20} {:10} {:10} {:10}\".format(\"Word\", \"True\", \"Pred\",  \"sentence\"))\n",
        " \n",
        "  while i < len(test_labels):\n",
        "    j=0 # loop on tokens\n",
        "    while j < len (test_labels[i]):\n",
        "      \n",
        "      if(entity_class in test_labels[i][j]):\n",
        "        entity_start=j\n",
        "        class_name= test_labels[i][j] [2:]\n",
        "        while (True):\n",
        "          if (test_labels[i][j] != pred_labels[i][j]):\n",
        "            j+=1\n",
        "            FN[classes.index(class_name)]+=1\n",
        "            show=\"allTrue\"\n",
        "            count+=1\n",
        "            break;\n",
        "          elif class_name not in test_labels[i][j+1] or 'B-' in test_labels[i][j+1] :\n",
        "            if class_name in pred_labels[i][j+1] and 'B-' not in pred_labels[i][j+1]: \n",
        "              FN[classes.index(class_name)]+=1\n",
        "              show=\"allTrue+\"\n",
        "              count+=1\n",
        "            else:\n",
        "              TP[classes.index(class_name)]+=1\n",
        "              show=\"\"\n",
        "            j+=1\n",
        "            break;\n",
        "          else:\n",
        "            j+=1\n",
        "        show_mispredictions(entity_start, show, entity_class, i, test_labels, pred_labels, X_words_te) # show mispredictions\n",
        "      else:\n",
        "        j+=1\n",
        "    i+=1\n",
        "  print(count)\n",
        "\n",
        "  i=0\n",
        "  count=0\n",
        "  print(\"{:20} {:10} {:10} {:10}\".format(\"Word\", \"True\", \"Pred\",  \"sentence\"))\n",
        "\n",
        "  while i < len(pred_labels):\n",
        "    j=0 # loop on tokens\n",
        "    while j < len (pred_labels[i]):\n",
        "      if(entity_class in pred_labels[i][j]):\n",
        "        entity_start=j\n",
        "        class_name= pred_labels[i][j] [2:]\n",
        "        while (True):\n",
        "          if (pred_labels[i][j] != test_labels[i][j]):\n",
        "            j+=1\n",
        "            FP[classes.index(class_name)]+=1\n",
        "            show=\"allPred\"\n",
        "            count+=1\n",
        "            break;\n",
        "          elif class_name not in pred_labels[i][j+1] or 'B-' in pred_labels[i][j+1]:\n",
        "            if class_name in test_labels[i][j+1] and 'B-' not in test_labels[i][j+1]: \n",
        "              FP[classes.index(class_name)]+=1\n",
        "              show=\"allPred+\"\n",
        "              count+=1\n",
        "            else:\n",
        "              FPC[classes.index(class_name)]+=1\n",
        "              show=\"\"\n",
        "            j+=1\n",
        "\n",
        "            break;\n",
        "          else:\n",
        "            j+=1\n",
        "        show_mispredictions(entity_start, show, entity_class, i, test_labels, pred_labels, X_words_te) # show mispredictions\n",
        "      else:\n",
        "        j+=1\n",
        "    i+=1\n",
        "  print(count)\n",
        "  print('TP: ',TP)\n",
        "  print('FN: ',FN)\n",
        "  print('FP: ',FP)\n",
        "  print('FPC: ',FPC)\n",
        "\n",
        "\n",
        "\n",
        "def show_mispredictions( entity_start, show, entity_class, i, test_labels, pred_labels, X_words_te):\n",
        "  if show !=\"\":\n",
        "    if \"True\" in show:\n",
        "      series = test_labels\n",
        "    else:\n",
        "      series = pred_labels\n",
        "    print(\"{:20} {:10} {:10} [{}]\".format(X_words_te[i][entity_start],test_labels[i][entity_start],pred_labels[i][entity_start], i))\n",
        "    entity_start+=1\n",
        "    try:\n",
        "      while(\"I-\" in series[i][entity_start]):\n",
        "        print(\"{:20} {:10} {:10} [{}]\".format(X_words_te[i][entity_start],test_labels[i][entity_start],pred_labels[i][entity_start], i))\n",
        "        entity_start+=1\n",
        "      if \"+\" in show:\n",
        "        print(\"{:20} {:10} {:10} [{}]\".format(X_words_te[i][entity_start],test_labels[i][entity_start],pred_labels[i][entity_start], i))\n",
        "    except:\n",
        "      filler=0\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL8fQA0ZjCbA",
        "outputId": "73778f60-6756-454a-bed2-53c9d088e4f8"
      },
      "source": [
        "evaluate(test_labels, pred_labels, \"B-\", X_words_te)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word                 True       Pred       sentence  \n",
            "ونايفة               B-LOC      O          [0]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-LOC      B-LOC      [1]\n",
            "المتحدة              B-ORG      I-LOC      [1]\n",
            "-------------------------------------------------------------------------\n",
            "المتحدة              B-ORG      I-LOC      [1]\n",
            "-------------------------------------------------------------------------\n",
            "تراب                 B-PERS     O          [1]\n",
            "-------------------------------------------------------------------------\n",
            "الأمن                B-ORG      O          [1]\n",
            "-------------------------------------------------------------------------\n",
            "دار                  B-ORG      O          [2]\n",
            "الهيئة               I-ORG      O          [2]\n",
            "المصرية              I-ORG      O          [2]\n",
            "العامة               I-ORG      O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "التأسلم              B-MISC     O          [2]\n",
            "السياسي              I-MISC     O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "حزب                  B-ORG      O          [2]\n",
            "التجمع               I-ORG      O          [2]\n",
            "المصري               I-ORG      O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "قناة                 B-ORG      O          [2]\n",
            "السويس               I-ORG      I-ORG      [2]\n",
            "الاستعمارية          I-ORG      O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "الشرق                B-ORG      B-LOC      [2]\n",
            "الأوسط               I-ORG      I-LOC      [2]\n",
            "-------------------------------------------------------------------------\n",
            "الخلفاء              B-MISC     O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "الراشدين             B-MISC     O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "الدولة               B-MISC     B-ORG      [2]\n",
            "الأموية              I-MISC     I-ORG      [2]\n",
            "-------------------------------------------------------------------------\n",
            "العباسية             B-MISC     O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "الجماعة              B-ORG      O          [3]\n",
            "المسلمة              I-ORG      O          [3]\n",
            "-------------------------------------------------------------------------\n",
            "بجماعة               B-ORG      O          [3]\n",
            "التكفير              I-ORG      O          [3]\n",
            "والهجرة              I-ORG      O          [3]\n",
            "-------------------------------------------------------------------------\n",
            "جماعة                B-ORG      O          [3]\n",
            "الجهاد               I-ORG      O          [3]\n",
            "-------------------------------------------------------------------------\n",
            "والجماعة             B-ORG      O          [3]\n",
            "الإسلامية            I-ORG      O          [3]\n",
            "-------------------------------------------------------------------------\n",
            "حظر                  B-PERS     O          [3]\n",
            "مسعود                I-PERS     B-PERS     [3]\n",
            "البارزاني            I-PERS     I-PERS     [3]\n",
            "-------------------------------------------------------------------------\n",
            "كردستان              B-LOC      B-LOC      [3]\n",
            "العراق               I-LOC      B-LOC      [3]\n",
            "-------------------------------------------------------------------------\n",
            "السنة                B-ORG      B-ORG      [3]\n",
            "والشيعة              I-ORG      B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "الأمم                B-ORG      B-ORG      [5]\n",
            "المتحدة              I-ORG      I-ORG      [5]\n",
            "للتربية              O          I-ORG      [5]\n",
            "-------------------------------------------------------------------------\n",
            "بوصوله               B-MISC     O          [5]\n",
            "-------------------------------------------------------------------------\n",
            "بحر                  B-LOC      O          [5]\n",
            "الصين                I-LOC      B-LOC      [5]\n",
            "-------------------------------------------------------------------------\n",
            "لاريجاني             B-PERS     I-PERS     [5]\n",
            "-------------------------------------------------------------------------\n",
            "البابا               B-PERS     O          [5]\n",
            "بنديكت               I-PERS     B-PERS     [5]\n",
            "ال                   I-PERS     O          [5]\n",
            "-------------------------------------------------------------------------\n",
            "جماعة                B-ORG      O          [6]\n",
            "قاعدة                I-ORG      O          [6]\n",
            "-------------------------------------------------------------------------\n",
            "الجهاد               B-ORG      O          [6]\n",
            "-------------------------------------------------------------------------\n",
            "لخالد                B-LOC      B-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "الظواهري             B-PERS     B-PERS     [6]\n",
            "البابا               I-PERS     O          [6]\n",
            "بنديكت               I-PERS     B-PERS     [6]\n",
            "ال                   I-PERS     O          [6]\n",
            "-------------------------------------------------------------------------\n",
            "المسيحية             B-MISC     O          [6]\n",
            "-------------------------------------------------------------------------\n",
            "عمر                  B-PERS     B-PERS     [6]\n",
            "حسن                  I-PERS     I-PERS     [6]\n",
            "البشير               B-PERS     I-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "البشير               B-PERS     I-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "حركة                 B-ORG      O          [7]\n",
            "المقاومة             I-ORG      B-ORG      [7]\n",
            "الإسلامية            I-ORG      I-ORG      [7]\n",
            "-------------------------------------------------------------------------\n",
            "قطرية                B-LOC      O          [7]\n",
            "-------------------------------------------------------------------------\n",
            "هوائيتين             B-ORG      O          [7]\n",
            "-------------------------------------------------------------------------\n",
            "البوينغ              B-ORG      B-MISC     [8]\n",
            "-------------------------------------------------------------------------\n",
            "مانوس                B-MISC     B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "مانوس                B-MISC     B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "GOL                  B-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "سيرا                 B-LOC      B-LOC      [8]\n",
            "دو                   I-LOC      I-LOC      [8]\n",
            "كاشيمبو              I-LOC      B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "البوينغ              B-ORG      B-MISC     [8]\n",
            "-------------------------------------------------------------------------\n",
            "الليرة               B-MISC     O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "رابطة                B-ORG      O          [8]\n",
            "البنوك               I-ORG      O          [8]\n",
            "الايطالية            I-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "البنك                B-ORG      B-ORG      [8]\n",
            "المركزي              I-ORG      I-ORG      [8]\n",
            "الايطالي             I-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "بالليرة              B-MISC     O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "بنك                  B-ORG      B-ORG      [8]\n",
            "ايطاليا              I-ORG      I-ORG      [8]\n",
            "المركزي              I-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "بنك                  B-ORG      O          [9]\n",
            "فرنسا                I-ORG      B-LOC      [9]\n",
            "المركزي              I-ORG      O          [9]\n",
            "-------------------------------------------------------------------------\n",
            "مدريد                B-ORG      B-LOC      [9]\n",
            "-------------------------------------------------------------------------\n",
            "ماراثون              B-MISC     O          [9]\n",
            "باريس                I-MISC     B-LOC      [9]\n",
            "-------------------------------------------------------------------------\n",
            "بيك                  B-MISC     B-MISC     [10]\n",
            "آب                   I-MISC     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-ORG      [10]\n",
            "باجيرو               B-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "الرالي               B-MISC     O          [10]\n",
            "القطري               I-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "قطر                  B-ORG      B-ORG      [10]\n",
            "للراليات             O          I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "ال                   B-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "رالي                 B-MISC     B-MISC     [10]\n",
            "باريس                I-MISC     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "خوان                 B-PERS     B-PERS     [10]\n",
            "روما                 B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "روما                 B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "حماس                 B-ORG      O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "سيريل                B-PERS     B-PERS     [10]\n",
            "ديسبري               B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "ديسبري               B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     B-MISC     [10]\n",
            "تي                   I-MISC     I-MISC     [10]\n",
            "إم                   I-MISC     I-MISC     [10]\n",
            "إل                   I-MISC     I-MISC     [10]\n",
            "سي4                  I-MISC     I-MISC     [10]\n",
            "660                  I-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "للرالي               B-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "نيسان                B-ORG      B-ORG      [10]\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "آب                   I-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "نيسان                B-ORG      B-ORG      [10]\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "آب                   I-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "ال                   B-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-PERS     [10]\n",
            "باجيرو               I-ORG      I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "شينوزوكا             B-PERS     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "شليسير               B-ORG      B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "الهاجري              B-PERS     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "ال                   B-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "200                  B-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "روما                 B-PERS     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [10]\n",
            "تي                   I-MISC     I-MISC     [10]\n",
            "إم                   I-MISC     I-MISC     [10]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [10]\n",
            "تي                   I-MISC     O          [10]\n",
            "إم                   I-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [10]\n",
            "تي                   I-MISC     O          [10]\n",
            "إم                   I-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "سينكت                B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تي                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تي                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "كوما                 B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "سالا                 B-PERS     B-MISC     [11]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تي                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "كوكس                 B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "جنوب                 B-LOC      O          [11]\n",
            "افريقيا              I-LOC      B-LOC      [11]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تم                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تم                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "ميوني                B-PERS     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تم                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "راديك                B-PERS     B-PERS     [11]\n",
            "وفريدل               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وفريدل               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "دونالد               B-PERS     B-PERS     [11]\n",
            "وبالمر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وبالمر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "فيسنت                B-PERS     B-PERS     [11]\n",
            "وبورتاس              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وبورتاس              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "بالا                 B-PERS     B-PERS     [11]\n",
            "وفيزنر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وفيزنر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "روبي                 B-PERS     B-PERS     [11]\n",
            "وجون                 B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وجون                 B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "نوفاك                B-PERS     B-PERS     [11]\n",
            "وريكل                B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وريكل                B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "اسبيلين              B-PERS     B-PERS     [11]\n",
            "ونيبورج              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "ونيبورج              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "دام                  B-PERS     B-PERS     [12]\n",
            "وقاسيك               B-PERS     I-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "وقاسيك               B-PERS     I-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "ارثر                 B-ORG      B-ORG      [12]\n",
            "اندرسون              I-ORG      I-ORG      [12]\n",
            "للمحاسبة             I-ORG      O          [12]\n",
            "-------------------------------------------------------------------------\n",
            "اندرسون              B-ORG      B-LOC      [12]\n",
            "-------------------------------------------------------------------------\n",
            "اندرسون              B-ORG      B-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "انرون                B-ORG      B-MISC     [12]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-PERS     B-LOC      [12]\n",
            "المتحدة              I-PERS     I-LOC      [12]\n",
            "-------------------------------------------------------------------------\n",
            "بلعاوي               B-PERS     I-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "الاناضول             B-ORG      B-LOC      [14]\n",
            "-------------------------------------------------------------------------\n",
            "الحزب                B-ORG      O          [14]\n",
            "الكردي               I-ORG      O          [14]\n",
            "الانفصالي            I-ORG      O          [14]\n",
            "-------------------------------------------------------------------------\n",
            "الاناضول             B-ORG      B-LOC      [14]\n",
            "-------------------------------------------------------------------------\n",
            "ياسوكوني             B-MISC     B-LOC      [15]\n",
            "-------------------------------------------------------------------------\n",
            "الرياض               B-LOC      B-ORG      [15]\n",
            "-------------------------------------------------------------------------\n",
            "تبليسي               B-PERS     B-LOC      [15]\n",
            "-------------------------------------------------------------------------\n",
            "تبليسي               B-PERS     B-LOC      [16]\n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 B-PERS     B-ORG      [16]\n",
            "الامن                I-PERS     I-ORG      [16]\n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 B-PERS     B-ORG      [16]\n",
            "الامن                I-PERS     I-ORG      [16]\n",
            "-------------------------------------------------------------------------\n",
            "ادامنتوس             B-ORG      B-PERS     [17]\n",
            "فاسيلاكيس            I-ORG      I-PERS     [17]\n",
            "-------------------------------------------------------------------------\n",
            "للجماعة              B-ORG      O          [17]\n",
            "السلفية              I-ORG      O          [17]\n",
            "للتبشير              I-ORG      O          [17]\n",
            "والجهاد              I-ORG      O          [17]\n",
            "-------------------------------------------------------------------------\n",
            "ادكار                B-LOC      B-LOC      [17]\n",
            "والقصور              I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "شابت                 B-LOC      B-LOC      [17]\n",
            "الأمير               I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "مجموعة               B-ORG      O          [17]\n",
            "السلفية              I-ORG      O          [17]\n",
            "للتبشير              I-ORG      O          [17]\n",
            "والجهاد              I-ORG      O          [17]\n",
            "-------------------------------------------------------------------------\n",
            "الجماعة              B-ORG      O          [17]\n",
            "السلفية              I-ORG      O          [17]\n",
            "للتبشير              I-ORG      O          [17]\n",
            "والجهاد              I-ORG      O          [17]\n",
            "-------------------------------------------------------------------------\n",
            "للمعهد               B-ORG      O          [17]\n",
            "الملكي               I-ORG      O          [17]\n",
            "البريطاني            I-ORG      O          [17]\n",
            "للدراسات             I-ORG      O          [17]\n",
            "الدولية              I-ORG      O          [17]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-LOC      B-LOC      [17]\n",
            "المتحدة              B-ORG      I-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "المتحدة              B-ORG      I-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "سان                  B-ORG      I-ORG      [17]\n",
            "اندرو                I-ORG      I-ORG      [17]\n",
            "-------------------------------------------------------------------------\n",
            "لاريجاني             B-PERS     I-PERS     [18]\n",
            "-------------------------------------------------------------------------\n",
            "الجامعة              B-ORG      O          [19]\n",
            "المغربية             I-ORG      O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "اتحاد                B-ORG      O          [19]\n",
            "المجامع              I-ORG      O          [19]\n",
            "اللغوية              I-ORG      O          [19]\n",
            "العربية              I-ORG      O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "معجم                 B-MISC     O          [19]\n",
            "تاريخي               I-MISC     O          [19]\n",
            "للغة                 I-MISC     O          [19]\n",
            "العربية              I-MISC     O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "بكينغهام             B-LOC      B-ORG      [19]\n",
            "-------------------------------------------------------------------------\n",
            "وDell                B-ORG      O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "وDell                B-ORG      O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "IBM                  B-ORG      B-ORG      [19]\n",
            "وLenovo              B-ORG      I-ORG      [19]\n",
            "-------------------------------------------------------------------------\n",
            "وLenovo              B-ORG      I-ORG      [19]\n",
            "-------------------------------------------------------------------------\n",
            "وLenovo              B-ORG      O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "وDell                B-ORG      O          [20]\n",
            "-------------------------------------------------------------------------\n",
            "باناسونيك            B-ORG      B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "لتس                  B-MISC     B-MISC     [20]\n",
            "نوت                  I-MISC     I-MISC     [20]\n",
            "CF                   I-MISC     B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "الحركة               B-ORG      O          [20]\n",
            "الطلابية             I-ORG      O          [20]\n",
            "الإسلامية            I-ORG      O          [20]\n",
            "-------------------------------------------------------------------------\n",
            "لوكالة               B-ORG      O          [21]\n",
            "الأنباء              I-ORG      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "الحركة               B-ORG      O          [21]\n",
            "الطلابية             I-ORG      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "الحركة               B-ORG      O          [21]\n",
            "الطلابية             I-ORG      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "للاتهامات            B-ORG      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "ناسا                 B-ORG      I-ORG      [21]\n",
            "-------------------------------------------------------------------------\n",
            "المريخ               B-LOC      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "المريخ               B-LOC      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "المريخ               B-LOC      B-ORG      [22]\n",
            "-------------------------------------------------------------------------\n",
            "بيكنور               B-MISC     B-ORG      [22]\n",
            "-------------------------------------------------------------------------\n",
            "فينوجرادوف           B-PERS     B-PERS     [22]\n",
            "ووليامز              B-PERS     I-PERS     [22]\n",
            "-------------------------------------------------------------------------\n",
            "ووليامز              B-PERS     I-PERS     [22]\n",
            "-------------------------------------------------------------------------\n",
            "فولكسفاجن            B-PERS     B-ORG      [23]\n",
            "-------------------------------------------------------------------------\n",
            "المقدسي              B-PERS     O          [23]\n",
            "-------------------------------------------------------------------------\n",
            "عبد                  B-PERS     B-PERS     [23]\n",
            "المجيد               I-PERS     I-PERS     [23]\n",
            "الذنيبات             O          I-PERS     [23]\n",
            "-------------------------------------------------------------------------\n",
            "للحركة               B-ORG      O          [24]\n",
            "الإسلامية            I-ORG      O          [24]\n",
            "-------------------------------------------------------------------------\n",
            "المجلس               B-ORG      O          [24]\n",
            "العالي               I-ORG      O          [24]\n",
            "للدستور              I-ORG      O          [24]\n",
            "-------------------------------------------------------------------------\n",
            "الحسين               B-PERS     B-LOC      [24]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [25]\n",
            "التنس                I-MISC     I-MISC     [25]\n",
            "الفردي               I-MISC     I-MISC     [25]\n",
            "الدولية              I-MISC     I-MISC     [25]\n",
            "المفتوحة             I-MISC     O          [25]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     O          [25]\n",
            "ويمبلدون             I-MISC     B-MISC     [25]\n",
            "الدولية              I-MISC     O          [25]\n",
            "للتنس                I-MISC     O          [25]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [25]\n",
            "فرنسا                I-MISC     I-MISC     [25]\n",
            "المفتوحة             I-MISC     I-MISC     [25]\n",
            "للتنس                O          I-MISC     [25]\n",
            "-------------------------------------------------------------------------\n",
            "ويمبلدون             B-MISC     B-ORG      [25]\n",
            "-------------------------------------------------------------------------\n",
            "السمبا               B-MISC     B-ORG      [26]\n",
            "-------------------------------------------------------------------------\n",
            "الترجي               B-ORG      B-ORG      [26]\n",
            "الرياضي              O          I-ORG      [26]\n",
            "-------------------------------------------------------------------------\n",
            "والملعب              B-ORG      O          [26]\n",
            "التونسي              I-ORG      O          [26]\n",
            "-------------------------------------------------------------------------\n",
            "كأس                  B-MISC     O          [26]\n",
            "الاتحاد              I-MISC     I-MISC     [26]\n",
            "الأفريقي             I-MISC     I-MISC     [26]\n",
            "لكرة                 I-MISC     O          [26]\n",
            "القدم                I-MISC     O          [26]\n",
            "-------------------------------------------------------------------------\n",
            "شاه                  B-PERS     I-PERS     [28]\n",
            "باكتيوال             I-PERS     I-PERS     [28]\n",
            "-------------------------------------------------------------------------\n",
            "داود                 B-PERS     B-MISC     [28]\n",
            "-------------------------------------------------------------------------\n",
            "حزب                  B-ORG      O          [29]\n",
            "الاتحاد              I-ORG      O          [29]\n",
            "الديمقراطي           I-ORG      O          [29]\n",
            "-------------------------------------------------------------------------\n",
            "مركز                 B-ORG      O          [29]\n",
            "إينتسر               I-ORG      B-ORG      [29]\n",
            "-------------------------------------------------------------------------\n",
            "الساعدي              B-PERS     B-PERS     [29]\n",
            "نجل                  I-PERS     O          [29]\n",
            "-------------------------------------------------------------------------\n",
            "الساعدي              B-PERS     B-PERS     [30]\n",
            "القذافي              B-PERS     I-PERS     [30]\n",
            "-------------------------------------------------------------------------\n",
            "القذافي              B-PERS     I-PERS     [30]\n",
            "-------------------------------------------------------------------------\n",
            "غاتويك               B-MISC     B-LOC      [30]\n",
            "-------------------------------------------------------------------------\n",
            "هرنانديز             B-LOC      I-PERS     [30]\n",
            "-------------------------------------------------------------------------\n",
            "دوري                 B-MISC     O          [30]\n",
            "أبطال                I-MISC     O          [30]\n",
            "أوروبا               I-MISC     B-LOC      [30]\n",
            "-------------------------------------------------------------------------\n",
            "بطولة                B-MISC     B-MISC     [31]\n",
            "تايلند               I-MISC     I-MISC     [31]\n",
            "الدولية              I-MISC     O          [31]\n",
            "للتنس                I-MISC     O          [31]\n",
            "-------------------------------------------------------------------------\n",
            "إديلاييد             B-MISC     B-MISC     [31]\n",
            "ولاس                 I-MISC     B-MISC     [31]\n",
            "فيغاس                I-MISC     I-MISC     [31]\n",
            "-------------------------------------------------------------------------\n",
            "وإنديانابوليس        B-PERS     B-LOC      [31]\n",
            "-------------------------------------------------------------------------\n",
            "الإيغور              B-MISC     O          [31]\n",
            "-------------------------------------------------------------------------\n",
            "أستوكهولوم           B-LOC      B-LOC      [32]\n",
            "وأوسلو               I-LOC      B-LOC      [32]\n",
            "-------------------------------------------------------------------------\n",
            "بمركز                B-ORG      O          [32]\n",
            "الغوري               I-ORG      O          [32]\n",
            "للتراث               I-ORG      O          [32]\n",
            "الموسيقي             I-ORG      O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "ومعهد                B-ORG      O          [32]\n",
            "الموسيقى             I-ORG      O          [32]\n",
            "العربية              I-ORG      O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "لدار                 B-MISC     O          [32]\n",
            "الأوبرا              I-MISC     O          [32]\n",
            "المصرية              I-MISC     O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "ومسرح                B-MISC     O          [32]\n",
            "الجنينة              I-MISC     O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "الأزهر               B-ORG      O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "النيل                B-LOC      O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "منظر                 B-MISC     O          [32]\n",
            "للنيل                I-MISC     O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "الأولاد              B-MISC     O          [32]\n",
            "في                   I-MISC     O          [32]\n",
            "النيل                I-MISC     O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "تمثال                B-MISC     O          [32]\n",
            "سيزيف                I-MISC     B-MISC     [32]\n",
            "-------------------------------------------------------------------------\n",
            "الأطفال              B-MISC     O          [32]\n",
            "والفنانون            I-MISC     O          [32]\n",
            "وحدهم                I-MISC     O          [32]\n",
            "قادرون               I-MISC     O          [32]\n",
            "على                  I-MISC     O          [32]\n",
            "إنقاذ                I-MISC     O          [32]\n",
            "العالم               I-MISC     O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "الجائزة              B-MISC     O          [33]\n",
            "الدولية              I-MISC     O          [33]\n",
            "الإيطالية            I-MISC     O          [33]\n",
            "لحوض                 I-MISC     O          [33]\n",
            "البحر                I-MISC     B-LOC      [33]\n",
            "الأبيض               I-MISC     I-LOC      [33]\n",
            "المتوسط              I-MISC     I-LOC      [33]\n",
            "-------------------------------------------------------------------------\n",
            "دولي                 B-MISC     O          [33]\n",
            "-------------------------------------------------------------------------\n",
            "معهد                 B-ORG      B-ORG      [33]\n",
            "رويان                I-ORG      I-ORG      [33]\n",
            "للبحوث               I-ORG      O          [33]\n",
            "العلمية              I-ORG      O          [33]\n",
            "حميد                 I-ORG      B-PERS     [33]\n",
            "كورابى               I-ORG      I-PERS     [33]\n",
            "-------------------------------------------------------------------------\n",
            "معهد                 B-ORG      O          [33]\n",
            "رويان                I-ORG      B-ORG      [33]\n",
            "-------------------------------------------------------------------------\n",
            "دولي                 B-MISC     O          [33]\n",
            "-------------------------------------------------------------------------\n",
            "المؤتمر              B-MISC     O          [33]\n",
            "الدولي               I-MISC     O          [33]\n",
            "السادس               I-MISC     O          [33]\n",
            "عشر                  I-MISC     O          [33]\n",
            "-------------------------------------------------------------------------\n",
            "لفيروس               B-MISC     O          [33]\n",
            "اتش                  I-MISC     B-MISC     [33]\n",
            "آي                   I-MISC     I-MISC     [33]\n",
            "في                   I-MISC     I-MISC     [33]\n",
            "-------------------------------------------------------------------------\n",
            "بفيروس               B-MISC     O          [33]\n",
            "اتش                  I-MISC     B-MISC     [33]\n",
            "آي                   I-MISC     I-MISC     [33]\n",
            "في                   I-MISC     I-MISC     [33]\n",
            "-------------------------------------------------------------------------\n",
            "موفق                 B-PERS     B-PERS     [34]\n",
            "الربيعي              B-PERS     I-PERS     [34]\n",
            "-------------------------------------------------------------------------\n",
            "الربيعي              B-PERS     I-PERS     [34]\n",
            "-------------------------------------------------------------------------\n",
            "البابا               B-PERS     O          [35]\n",
            "-------------------------------------------------------------------------\n",
            "كاستل                B-LOC      B-LOC      [35]\n",
            "جاندولفو             B-LOC      I-LOC      [35]\n",
            "-------------------------------------------------------------------------\n",
            "جاندولفو             B-LOC      I-LOC      [35]\n",
            "-------------------------------------------------------------------------\n",
            "سيلفا                B-PERS     I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "تارسو                B-ORG      B-PERS     [35]\n",
            "جينرو                I-ORG      I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "سيلفا                B-PERS     I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "ريال                 B-ORG      B-ORG      [35]\n",
            "مدريد                B-LOC      I-ORG      [35]\n",
            "-------------------------------------------------------------------------\n",
            "مدريد                B-LOC      I-ORG      [35]\n",
            "-------------------------------------------------------------------------\n",
            "ريال                 B-ORG      B-ORG      [36]\n",
            "مدريد                B-LOC      I-ORG      [36]\n",
            "-------------------------------------------------------------------------\n",
            "مدريد                B-LOC      I-ORG      [36]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [36]\n",
            "العالم               I-MISC     I-MISC     [36]\n",
            "للإسكواش             I-MISC     I-MISC     [36]\n",
            "للسيدات              O          I-MISC     [36]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [36]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [36]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "فرنسا                B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "وإسبانيا             B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "وكندا                B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "جنوب                 B-ORG      B-LOC      [37]\n",
            "أفريقيا              I-ORG      I-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "ماليزيا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "إنجلترا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "هولندا               B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "إنجلترا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "المؤسسة              B-ORG      B-ORG      [37]\n",
            "العربية              I-ORG      I-ORG      [37]\n",
            "لضمان                I-ORG      O          [37]\n",
            "الاستثمار            I-ORG      O          [37]\n",
            "-------------------------------------------------------------------------\n",
            "جابر                 B-PERS     B-PERS     [37]\n",
            "الأحمد               I-PERS     I-PERS     [37]\n",
            "الجابر               I-PERS     I-PERS     [37]\n",
            "الصباح               B-PERS     I-PERS     [37]\n",
            "-------------------------------------------------------------------------\n",
            "الصباح               B-PERS     I-PERS     [37]\n",
            "-------------------------------------------------------------------------\n",
            "جامعة                B-ORG      B-ORG      [38]\n",
            "جورجتاون             B-ORG      I-ORG      [38]\n",
            "-------------------------------------------------------------------------\n",
            "جورجتاون             B-ORG      I-ORG      [38]\n",
            "-------------------------------------------------------------------------\n",
            "الخليج               B-LOC      I-MISC     [39]\n",
            "-------------------------------------------------------------------------\n",
            "ألفريد               B-PERS     B-PERS     [39]\n",
            "نوبل                 B-PERS     I-PERS     [39]\n",
            "-------------------------------------------------------------------------\n",
            "نوبل                 B-PERS     I-PERS     [39]\n",
            "-------------------------------------------------------------------------\n",
            "البنك                B-ORG      O          [39]\n",
            "المركزي              I-ORG      O          [39]\n",
            "السويدي              I-ORG      O          [39]\n",
            "-------------------------------------------------------------------------\n",
            "القاعدة              B-ORG      O          [40]\n",
            "-------------------------------------------------------------------------\n",
            "والجراح              B-PERS     O          [40]\n",
            "-------------------------------------------------------------------------\n",
            "نيويورك              B-LOC      B-LOC      [40]\n",
            "وواشنطن              B-LOC      I-LOC      [40]\n",
            "-------------------------------------------------------------------------\n",
            "وواشنطن              B-LOC      I-LOC      [40]\n",
            "-------------------------------------------------------------------------\n",
            "والجراح              B-PERS     O          [40]\n",
            "-------------------------------------------------------------------------\n",
            "الجراح               B-PERS     O          [40]\n",
            "-------------------------------------------------------------------------\n",
            "القاعدة              B-ORG      O          [41]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-ORG      B-LOC      [41]\n",
            "المتحدة              I-ORG      I-LOC      [41]\n",
            "-------------------------------------------------------------------------\n",
            "جولي                 B-PERS     B-PERS     [41]\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "جولي                 B-PERS     B-PERS     [41]\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "نيويورك              B-ORG      B-LOC      [42]\n",
            "-------------------------------------------------------------------------\n",
            "سنتا                 B-MISC     O          [42]\n",
            "-------------------------------------------------------------------------\n",
            "دولارا               B-ORG      B-MISC     [42]\n",
            "-------------------------------------------------------------------------\n",
            "مدمر                 B-ORG      O          [42]\n",
            "-------------------------------------------------------------------------\n",
            "المكسيك              B-MISC     I-LOC      [42]\n",
            "-------------------------------------------------------------------------\n",
            "Salvador             B-PERS     B-PERS     [42]\n",
            "Dalí                 I-PERS     O          [42]\n",
            "-------------------------------------------------------------------------\n",
            "الكلب                B-MISC     O          [43]\n",
            "الأندلسي             I-MISC     O          [43]\n",
            "-------------------------------------------------------------------------\n",
            "L                    B-MISC     O          [43]\n",
            "'                    I-MISC     O          [43]\n",
            "Age                  I-MISC     O          [43]\n",
            "d                    I-MISC     O          [43]\n",
            "'                    I-MISC     O          [43]\n",
            "or                   I-MISC     O          [43]\n",
            "-------------------------------------------------------------------------\n",
            "الحياة               B-MISC     B-MISC     [43]\n",
            "السرية               I-MISC     I-MISC     [43]\n",
            "لسلفادور             I-MISC     B-PERS     [43]\n",
            "دالي                 I-MISC     I-PERS     [43]\n",
            "-------------------------------------------------------------------------\n",
            "ستاد                 B-MISC     O          [44]\n",
            "الحسن                I-MISC     B-LOC      [44]\n",
            "-------------------------------------------------------------------------\n",
            "ستاد                 B-MISC     O          [45]\n",
            "عمان                 I-MISC     B-LOC      [45]\n",
            "-------------------------------------------------------------------------\n",
            "ستاد                 B-MISC     O          [45]\n",
            "-------------------------------------------------------------------------\n",
            "عبده                 B-PERS     O          [45]\n",
            "الحسين               I-PERS     B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "لؤي                  B-ORG      B-PERS     [45]\n",
            "العبادي              I-ORG      I-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "فالحسين              B-ORG      B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "فالحسين              B-ORG      O          [45]\n",
            "-------------------------------------------------------------------------\n",
            "والزبون              B-PERS     O          [45]\n",
            "-------------------------------------------------------------------------\n",
            "وخير                 B-PERS     O          [45]\n",
            "-------------------------------------------------------------------------\n",
            "الحسين               B-ORG      B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "الشرمان              B-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "للحفناوي             B-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الدينمو              B-PERS     O          [46]\n",
            "الحسنات              I-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الرياحنة             B-ORG      O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "ورامي                B-PERS     B-PERS     [46]\n",
            "الذين                I-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "والمصري              B-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الحسنات              B-PERS     O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "ومقابلة              B-PERS     O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "المصري               B-PERS     O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "التحرير              B-ORG      O          [47]\n",
            "الوطني               I-ORG      O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "والمقاومة            B-ORG      O          [47]\n",
            "الإسلامية            I-ORG      O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "فتح                  B-ORG      O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "رام                  B-LOC      B-LOC      [48]\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "رام                  B-LOC      B-LOC      [48]\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "لمهرجان              B-MISC     O          [48]\n",
            "البندقية             I-MISC     B-MISC     [48]\n",
            "-------------------------------------------------------------------------\n",
            "أنا                  B-MISC     B-MISC     [48]\n",
            "وترانه               I-MISC     B-MISC     [48]\n",
            "و15                  I-MISC     I-MISC     [48]\n",
            "سنة                  I-MISC     I-MISC     [48]\n",
            "-------------------------------------------------------------------------\n",
            "البوب                B-MISC     O          [48]\n",
            "-------------------------------------------------------------------------\n",
            "البوب                B-MISC     O          [48]\n",
            "-------------------------------------------------------------------------\n",
            "البوب                B-MISC     O          [48]\n",
            "-------------------------------------------------------------------------\n",
            "طهران                B-ORG      B-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "لاريجاني             B-PERS     I-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "هيئة                 B-ORG      O          [49]\n",
            "الطاقة               I-ORG      O          [49]\n",
            "الذرية               I-ORG      O          [49]\n",
            "الإيرانية            I-ORG      O          [49]\n",
            "-------------------------------------------------------------------------\n",
            "غلام                 B-PERS     B-PERS     [49]\n",
            "رضا                  B-PERS     I-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "رضا                  B-PERS     I-PERS     [49]\n",
            "آغا                  I-PERS     I-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "هوي                  B-MISC     B-LOC      [49]\n",
            "-------------------------------------------------------------------------\n",
            "ومكة                 B-LOC      B-LOC      [49]\n",
            "المكرمة              I-LOC      O          [49]\n",
            "-------------------------------------------------------------------------\n",
            "الوليد               B-PERS     B-PERS     [50]\n",
            "بن                   I-PERS     I-PERS     [50]\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "كوبلي                B-ORG      B-MISC     [50]\n",
            "بلازا                I-ORG      I-MISC     [50]\n",
            "-------------------------------------------------------------------------\n",
            "الشركة               B-ORG      O          [50]\n",
            "العربية              I-ORG      O          [50]\n",
            "للإنتاج              I-ORG      O          [50]\n",
            "الإعلامي             I-ORG      O          [50]\n",
            "-------------------------------------------------------------------------\n",
            "الوليد               B-PERS     B-PERS     [50]\n",
            "بن                   I-PERS     I-PERS     [50]\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "شركة                 B-ORG      O          [50]\n",
            "المملكة              I-ORG      B-ORG      [50]\n",
            "القابضة              I-ORG      I-ORG      [50]\n",
            "-------------------------------------------------------------------------\n",
            "وللوليد              B-PERS     O          [50]\n",
            "-------------------------------------------------------------------------\n",
            "314\n",
            "Word                 True       Pred       sentence  \n",
            "الصالحية             O          B-LOC      [0]\n",
            "-------------------------------------------------------------------------\n",
            "ونايفة               O          B-ORG      [0]\n",
            "-------------------------------------------------------------------------\n",
            "الأغوار              O          B-LOC      [0]\n",
            "-------------------------------------------------------------------------\n",
            "الصالحية             O          B-LOC      [0]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-LOC      B-LOC      [1]\n",
            "المتحدة              B-ORG      I-LOC      [1]\n",
            "-------------------------------------------------------------------------\n",
            "الإخوان              I-MISC     B-ORG      [2]\n",
            "المسلمين             I-MISC     I-ORG      [2]\n",
            "-------------------------------------------------------------------------\n",
            "الشرق                B-ORG      B-LOC      [2]\n",
            "الأوسط               I-ORG      I-LOC      [2]\n",
            "-------------------------------------------------------------------------\n",
            "الدولة               B-MISC     B-ORG      [2]\n",
            "الأموية              I-MISC     I-ORG      [2]\n",
            "-------------------------------------------------------------------------\n",
            "الإخوان              O          B-ORG      [2]\n",
            "المسلمين             O          I-ORG      [2]\n",
            "-------------------------------------------------------------------------\n",
            "الإسلام              O          B-MISC     [2]\n",
            "-------------------------------------------------------------------------\n",
            "الأكراد              O          B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "الجولان              O          B-LOC      [3]\n",
            "-------------------------------------------------------------------------\n",
            "مسعود                I-PERS     B-PERS     [3]\n",
            "البارزاني            I-PERS     I-PERS     [3]\n",
            "-------------------------------------------------------------------------\n",
            "كردستان              B-LOC      B-LOC      [3]\n",
            "العراق               I-LOC      B-LOC      [3]\n",
            "-------------------------------------------------------------------------\n",
            "العراق               I-LOC      B-LOC      [3]\n",
            "-------------------------------------------------------------------------\n",
            "حرب                  O          B-MISC     [3]\n",
            "الخليج               O          I-MISC     [3]\n",
            "-------------------------------------------------------------------------\n",
            "وسنة                 O          B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "السنة                B-ORG      B-ORG      [3]\n",
            "والشيعة              I-ORG      B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "والشيعة              I-ORG      B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "والأكراد             O          B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "حالة                 O          B-MISC     [3]\n",
            "النكران              O          I-MISC     [3]\n",
            "-------------------------------------------------------------------------\n",
            "بمنظمة               O          B-ORG      [5]\n",
            "-------------------------------------------------------------------------\n",
            "الأمم                B-ORG      B-ORG      [5]\n",
            "المتحدة              I-ORG      I-ORG      [5]\n",
            "للتربية              O          I-ORG      [5]\n",
            "والعلوم              O          I-ORG      [5]\n",
            "والثقافة             O          I-ORG      [5]\n",
            "-------------------------------------------------------------------------\n",
            "الصين                I-LOC      B-LOC      [5]\n",
            "-------------------------------------------------------------------------\n",
            "وعلي                 O          B-PERS     [5]\n",
            "لاريجاني             B-PERS     I-PERS     [5]\n",
            "-------------------------------------------------------------------------\n",
            "بنديكت               I-PERS     B-PERS     [5]\n",
            "-------------------------------------------------------------------------\n",
            "بالإسلام             O          B-MISC     [5]\n",
            "-------------------------------------------------------------------------\n",
            "لخالد                B-LOC      B-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "الإسلام              O          B-MISC     [6]\n",
            "-------------------------------------------------------------------------\n",
            "الظواهري             B-PERS     B-PERS     [6]\n",
            "البابا               I-PERS     O          [6]\n",
            "-------------------------------------------------------------------------\n",
            "بنديكت               I-PERS     B-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "عمر                  B-PERS     B-PERS     [6]\n",
            "حسن                  I-PERS     I-PERS     [6]\n",
            "البشير               B-PERS     I-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "المقاومة             I-ORG      B-ORG      [7]\n",
            "الإسلامية            I-ORG      I-ORG      [7]\n",
            "-------------------------------------------------------------------------\n",
            "حماس                 O          B-ORG      [7]\n",
            "-------------------------------------------------------------------------\n",
            "قطر                  O          B-LOC      [7]\n",
            "-------------------------------------------------------------------------\n",
            "بحماس                O          B-ORG      [7]\n",
            "-------------------------------------------------------------------------\n",
            "الضفة                O          B-LOC      [8]\n",
            "الغربية              O          I-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "البوينغ              B-ORG      B-MISC     [8]\n",
            "-------------------------------------------------------------------------\n",
            "مانوس                B-MISC     B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "مانوس                B-MISC     B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "سيرا                 B-LOC      B-LOC      [8]\n",
            "دو                   I-LOC      I-LOC      [8]\n",
            "كاشيمبو              I-LOC      B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "كاشيمبو              I-LOC      B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "البوينغ              B-ORG      B-MISC     [8]\n",
            "-------------------------------------------------------------------------\n",
            "البنك                B-ORG      B-ORG      [8]\n",
            "المركزي              I-ORG      I-ORG      [8]\n",
            "الايطالي             I-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "بنك                  B-ORG      B-ORG      [8]\n",
            "ايطاليا              I-ORG      I-ORG      [8]\n",
            "المركزي              I-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "فرنسا                I-ORG      B-LOC      [9]\n",
            "-------------------------------------------------------------------------\n",
            "مدريد                B-ORG      B-LOC      [9]\n",
            "-------------------------------------------------------------------------\n",
            "باريس                I-MISC     B-LOC      [9]\n",
            "-------------------------------------------------------------------------\n",
            "داكار                I-MISC     B-MISC     [9]\n",
            "-------------------------------------------------------------------------\n",
            "بيك                  B-MISC     B-MISC     [10]\n",
            "آب                   I-MISC     I-PERS     [10]\n",
            "نيسان                B-ORG      B-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-ORG      [10]\n",
            "باجيرو               B-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "قطر                  B-ORG      B-ORG      [10]\n",
            "للراليات             O          I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "رالي                 B-MISC     B-MISC     [10]\n",
            "باريس                I-MISC     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "باريس                I-MISC     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "داكار                I-MISC     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "الهاجري              O          B-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "خوان                 B-PERS     B-PERS     [10]\n",
            "روما                 B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "سيريل                B-PERS     B-PERS     [10]\n",
            "ديسبري               B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     B-MISC     [10]\n",
            "تي                   I-MISC     I-MISC     [10]\n",
            "إم                   I-MISC     I-MISC     [10]\n",
            "إل                   I-MISC     I-MISC     [10]\n",
            "سي4                  I-MISC     I-MISC     [10]\n",
            "660                  I-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "الرشيدة              O          B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "نيسان                B-ORG      B-ORG      [10]\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "آب                   I-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "نيسان                B-ORG      B-ORG      [10]\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "آب                   I-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-PERS     [10]\n",
            "باجيرو               I-ORG      I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-PERS     [10]\n",
            "باجيرو               B-MISC     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "شليسير               B-ORG      B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "روما                 B-PERS     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "سينكت                B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "كوما                 B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "سالا                 B-PERS     B-MISC     [11]\n",
            "-------------------------------------------------------------------------\n",
            "كوكس                 B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "افريقيا              I-LOC      B-LOC      [11]\n",
            "-------------------------------------------------------------------------\n",
            "راديك                B-PERS     B-PERS     [11]\n",
            "وفريدل               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "دونالد               B-PERS     B-PERS     [11]\n",
            "وبالمر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "فيسنت                B-PERS     B-PERS     [11]\n",
            "وبورتاس              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "بالا                 B-PERS     B-PERS     [11]\n",
            "وفيزنر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "روبي                 B-PERS     B-PERS     [11]\n",
            "وجون                 B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "نوفاك                B-PERS     B-PERS     [11]\n",
            "وريكل                B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "اسبيلين              B-PERS     B-PERS     [11]\n",
            "ونيبورج              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "دام                  B-PERS     B-PERS     [12]\n",
            "وقاسيك               B-PERS     I-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "ارثر                 B-ORG      B-ORG      [12]\n",
            "اندرسون              I-ORG      I-ORG      [12]\n",
            "للمحاسبة             I-ORG      O          [12]\n",
            "-------------------------------------------------------------------------\n",
            "دولار                O          B-MISC     [12]\n",
            "-------------------------------------------------------------------------\n",
            "اندرسون              B-ORG      B-LOC      [12]\n",
            "-------------------------------------------------------------------------\n",
            "اندرسون              B-ORG      B-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "انرون                B-ORG      B-MISC     [12]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-PERS     B-LOC      [12]\n",
            "المتحدة              I-PERS     I-LOC      [12]\n",
            "الأميركية            O          I-LOC      [12]\n",
            "-------------------------------------------------------------------------\n",
            "بالمانيا             O          B-LOC      [13]\n",
            "-------------------------------------------------------------------------\n",
            "لالمانيا             O          B-LOC      [13]\n",
            "-------------------------------------------------------------------------\n",
            "الاناضول             B-ORG      B-LOC      [14]\n",
            "-------------------------------------------------------------------------\n",
            "من                   O          B-ORG      [14]\n",
            "اجل                  O          I-ORG      [14]\n",
            "مجتمع                O          I-ORG      [14]\n",
            "ديمقراطي             O          I-ORG      [14]\n",
            "-------------------------------------------------------------------------\n",
            "الاكراد              O          B-ORG      [14]\n",
            "-------------------------------------------------------------------------\n",
            "الاناضول             B-ORG      B-LOC      [14]\n",
            "-------------------------------------------------------------------------\n",
            "الحرب                O          B-MISC     [14]\n",
            "العالمية             O          I-MISC     [14]\n",
            "الثانية              O          I-MISC     [14]\n",
            "-------------------------------------------------------------------------\n",
            "ياسوكوني             B-MISC     B-LOC      [15]\n",
            "-------------------------------------------------------------------------\n",
            "الرياض               B-LOC      B-ORG      [15]\n",
            "-------------------------------------------------------------------------\n",
            "تبليسي               B-PERS     B-LOC      [15]\n",
            "-------------------------------------------------------------------------\n",
            "تبليسي               B-PERS     B-LOC      [16]\n",
            "-------------------------------------------------------------------------\n",
            "بان                  O          B-PERS     [16]\n",
            "-------------------------------------------------------------------------\n",
            "بان                  O          B-PERS     [16]\n",
            "-------------------------------------------------------------------------\n",
            "بان                  O          B-PERS     [16]\n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 B-PERS     B-ORG      [16]\n",
            "الامن                I-PERS     I-ORG      [16]\n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 B-PERS     B-ORG      [16]\n",
            "الامن                I-PERS     I-ORG      [16]\n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 O          B-ORG      [16]\n",
            "الامن                O          I-ORG      [16]\n",
            "-------------------------------------------------------------------------\n",
            "ادامنتوس             B-ORG      B-PERS     [17]\n",
            "فاسيلاكيس            I-ORG      I-PERS     [17]\n",
            "-------------------------------------------------------------------------\n",
            "ادكار                B-LOC      B-LOC      [17]\n",
            "والقصور              I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "والقصور              I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "شابت                 B-LOC      B-LOC      [17]\n",
            "الأمير               I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "الأمير               I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-LOC      B-LOC      [17]\n",
            "المتحدة              B-ORG      I-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "جامعة                O          B-ORG      [17]\n",
            "سان                  B-ORG      I-ORG      [17]\n",
            "اندرو                I-ORG      I-ORG      [17]\n",
            "-------------------------------------------------------------------------\n",
            "الوكالة              O          B-ORG      [18]\n",
            "الدولية              O          I-ORG      [18]\n",
            "للطاقة               O          I-ORG      [18]\n",
            "الذرية               O          I-ORG      [18]\n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [18]\n",
            "لاريجاني             B-PERS     I-PERS     [18]\n",
            "-------------------------------------------------------------------------\n",
            "الأورو               O          B-MISC     [18]\n",
            "-------------------------------------------------------------------------\n",
            "بكينغهام             B-LOC      B-ORG      [19]\n",
            "-------------------------------------------------------------------------\n",
            "IBM                  B-ORG      B-ORG      [19]\n",
            "وLenovo              B-ORG      I-ORG      [19]\n",
            "-------------------------------------------------------------------------\n",
            "ليثيوم               O          B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "باناسونيك            B-ORG      B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "لتس                  B-MISC     B-MISC     [20]\n",
            "نوت                  I-MISC     I-MISC     [20]\n",
            "CF                   I-MISC     B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "CF                   I-MISC     B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "العسكر               O          B-ORG      [21]\n",
            "الطيبة               O          I-ORG      [21]\n",
            "-------------------------------------------------------------------------\n",
            "لوكالة               O          B-ORG      [21]\n",
            "الفضاء               O          I-ORG      [21]\n",
            "الأمريكية            O          I-ORG      [21]\n",
            "ناسا                 B-ORG      I-ORG      [21]\n",
            "-------------------------------------------------------------------------\n",
            "المريخ               B-LOC      B-ORG      [22]\n",
            "-------------------------------------------------------------------------\n",
            "بيكنور               B-MISC     B-ORG      [22]\n",
            "-------------------------------------------------------------------------\n",
            "فينوجرادوف           B-PERS     B-PERS     [22]\n",
            "ووليامز              B-PERS     I-PERS     [22]\n",
            "-------------------------------------------------------------------------\n",
            "لألمانيا             O          B-LOC      [23]\n",
            "-------------------------------------------------------------------------\n",
            "فولكسفاجن            B-PERS     B-ORG      [23]\n",
            "-------------------------------------------------------------------------\n",
            "سنتا                 O          B-MISC     [23]\n",
            "-------------------------------------------------------------------------\n",
            "دولار                O          B-MISC     [23]\n",
            "-------------------------------------------------------------------------\n",
            "دولار                O          B-MISC     [23]\n",
            "-------------------------------------------------------------------------\n",
            "عبد                  B-PERS     B-PERS     [23]\n",
            "المجيد               I-PERS     I-PERS     [23]\n",
            "الذنيبات             O          I-PERS     [23]\n",
            "-------------------------------------------------------------------------\n",
            "الذنيبات             O          B-PERS     [24]\n",
            "-------------------------------------------------------------------------\n",
            "الحسين               B-PERS     B-LOC      [24]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [25]\n",
            "التنس                I-MISC     I-MISC     [25]\n",
            "الفردي               I-MISC     I-MISC     [25]\n",
            "الدولية              I-MISC     I-MISC     [25]\n",
            "المفتوحة             I-MISC     O          [25]\n",
            "-------------------------------------------------------------------------\n",
            "ويمبلدون             I-MISC     B-MISC     [25]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [25]\n",
            "فرنسا                I-MISC     I-MISC     [25]\n",
            "المفتوحة             I-MISC     I-MISC     [25]\n",
            "للتنس                O          I-MISC     [25]\n",
            "-------------------------------------------------------------------------\n",
            "ويمبلدون             B-MISC     B-ORG      [25]\n",
            "-------------------------------------------------------------------------\n",
            "بطولات               O          B-MISC     [25]\n",
            "كأس                  O          I-MISC     [25]\n",
            "العالم               O          I-MISC     [25]\n",
            "-------------------------------------------------------------------------\n",
            "تشيكوسلوفاكيا        I-LOC      B-LOC      [26]\n",
            "-------------------------------------------------------------------------\n",
            "السمبا               B-MISC     B-ORG      [26]\n",
            "-------------------------------------------------------------------------\n",
            "الترجي               B-ORG      B-ORG      [26]\n",
            "الرياضي              O          I-ORG      [26]\n",
            "-------------------------------------------------------------------------\n",
            "النجم                O          B-ORG      [26]\n",
            "الساحلي              O          I-ORG      [26]\n",
            "-------------------------------------------------------------------------\n",
            "البطولة              O          B-MISC     [26]\n",
            "والكأس               O          I-MISC     [26]\n",
            "-------------------------------------------------------------------------\n",
            "الزواوي              O          B-PERS     [27]\n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [28]\n",
            "شاه                  B-PERS     I-PERS     [28]\n",
            "باكتيوال             I-PERS     I-PERS     [28]\n",
            "-------------------------------------------------------------------------\n",
            "داود                 B-PERS     B-MISC     [28]\n",
            "-------------------------------------------------------------------------\n",
            "إينتسر               I-ORG      B-ORG      [29]\n",
            "-------------------------------------------------------------------------\n",
            "بازل                 O          B-LOC      [29]\n",
            "-------------------------------------------------------------------------\n",
            "الساعدي              B-PERS     B-PERS     [29]\n",
            "نجل                  I-PERS     O          [29]\n",
            "-------------------------------------------------------------------------\n",
            "الساعدي              B-PERS     B-PERS     [30]\n",
            "القذافي              B-PERS     I-PERS     [30]\n",
            "-------------------------------------------------------------------------\n",
            "غاتويك               B-MISC     B-LOC      [30]\n",
            "-------------------------------------------------------------------------\n",
            "زافي                 O          B-PERS     [30]\n",
            "هرنانديز             B-LOC      I-PERS     [30]\n",
            "-------------------------------------------------------------------------\n",
            "أوروبا               I-MISC     B-LOC      [30]\n",
            "-------------------------------------------------------------------------\n",
            "بطولة                B-MISC     B-MISC     [31]\n",
            "تايلند               I-MISC     I-MISC     [31]\n",
            "الدولية              I-MISC     O          [31]\n",
            "-------------------------------------------------------------------------\n",
            "إديلاييد             B-MISC     B-MISC     [31]\n",
            "ولاس                 I-MISC     B-MISC     [31]\n",
            "-------------------------------------------------------------------------\n",
            "ولاس                 I-MISC     B-MISC     [31]\n",
            "فيغاس                I-MISC     I-MISC     [31]\n",
            "-------------------------------------------------------------------------\n",
            "وإنديانابوليس        B-PERS     B-LOC      [31]\n",
            "-------------------------------------------------------------------------\n",
            "بطولة                O          B-MISC     [31]\n",
            "بلاده                O          I-MISC     [31]\n",
            "-------------------------------------------------------------------------\n",
            "أستوكهولوم           B-LOC      B-LOC      [32]\n",
            "وأوسلو               I-LOC      B-LOC      [32]\n",
            "-------------------------------------------------------------------------\n",
            "وأوسلو               I-LOC      B-LOC      [32]\n",
            "-------------------------------------------------------------------------\n",
            "سيزيف                I-MISC     B-MISC     [32]\n",
            "-------------------------------------------------------------------------\n",
            "البحر                I-MISC     B-LOC      [33]\n",
            "الأبيض               I-MISC     I-LOC      [33]\n",
            "المتوسط              I-MISC     I-LOC      [33]\n",
            "-------------------------------------------------------------------------\n",
            "معهد                 B-ORG      B-ORG      [33]\n",
            "رويان                I-ORG      I-ORG      [33]\n",
            "للبحوث               I-ORG      O          [33]\n",
            "-------------------------------------------------------------------------\n",
            "حميد                 I-ORG      B-PERS     [33]\n",
            "كورابى               I-ORG      I-PERS     [33]\n",
            "-------------------------------------------------------------------------\n",
            "رويان                I-ORG      B-ORG      [33]\n",
            "-------------------------------------------------------------------------\n",
            "اتش                  I-MISC     B-MISC     [33]\n",
            "آي                   I-MISC     I-MISC     [33]\n",
            "في                   I-MISC     I-MISC     [33]\n",
            "-------------------------------------------------------------------------\n",
            "اتش                  I-MISC     B-MISC     [33]\n",
            "آي                   I-MISC     I-MISC     [33]\n",
            "في                   I-MISC     I-MISC     [33]\n",
            "-------------------------------------------------------------------------\n",
            "موفق                 B-PERS     B-PERS     [34]\n",
            "الربيعي              B-PERS     I-PERS     [34]\n",
            "-------------------------------------------------------------------------\n",
            "الانبار              O          B-LOC      [34]\n",
            "-------------------------------------------------------------------------\n",
            "سني                  O          B-ORG      [34]\n",
            "-------------------------------------------------------------------------\n",
            "كاستل                B-LOC      B-LOC      [35]\n",
            "جاندولفو             B-LOC      I-LOC      [35]\n",
            "-------------------------------------------------------------------------\n",
            "دا                   O          B-PERS     [35]\n",
            "سيلفا                B-PERS     I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "لولا                 O          B-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "تارسو                B-ORG      B-PERS     [35]\n",
            "جينرو                I-ORG      I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "دا                   O          B-PERS     [35]\n",
            "سيلفا                B-PERS     I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "ريال                 B-ORG      B-ORG      [35]\n",
            "مدريد                B-LOC      I-ORG      [35]\n",
            "-------------------------------------------------------------------------\n",
            "ريال                 B-ORG      B-ORG      [36]\n",
            "مدريد                B-LOC      I-ORG      [36]\n",
            "-------------------------------------------------------------------------\n",
            "الريال               O          B-ORG      [36]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [36]\n",
            "العالم               I-MISC     I-MISC     [36]\n",
            "للإسكواش             I-MISC     I-MISC     [36]\n",
            "للسيدات              O          I-MISC     [36]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [36]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [36]\n",
            "-------------------------------------------------------------------------\n",
            "البطولة              O          B-MISC     [36]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "فرنسا                B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "وإسبانيا             B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "وكندا                B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "جنوب                 B-ORG      B-LOC      [37]\n",
            "أفريقيا              I-ORG      I-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "ماليزيا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "إنجلترا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "هولندا               B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "بطولة                O          B-MISC     [37]\n",
            "العالم               O          I-MISC     [37]\n",
            "لفرق                 O          I-MISC     [37]\n",
            "الرجال               O          I-MISC     [37]\n",
            "-------------------------------------------------------------------------\n",
            "إنجلترا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "المؤسسة              B-ORG      B-ORG      [37]\n",
            "العربية              I-ORG      I-ORG      [37]\n",
            "لضمان                I-ORG      O          [37]\n",
            "-------------------------------------------------------------------------\n",
            "جابر                 B-PERS     B-PERS     [37]\n",
            "الأحمد               I-PERS     I-PERS     [37]\n",
            "الجابر               I-PERS     I-PERS     [37]\n",
            "الصباح               B-PERS     I-PERS     [37]\n",
            "-------------------------------------------------------------------------\n",
            "جامعة                B-ORG      B-ORG      [38]\n",
            "جورجتاون             B-ORG      I-ORG      [38]\n",
            "-------------------------------------------------------------------------\n",
            "جور                  O          B-PERS     [38]\n",
            "-------------------------------------------------------------------------\n",
            "الحرب                O          B-MISC     [38]\n",
            "الباردة              O          I-MISC     [38]\n",
            "-------------------------------------------------------------------------\n",
            "حرب                  O          B-MISC     [39]\n",
            "الخليج               B-LOC      I-MISC     [39]\n",
            "-------------------------------------------------------------------------\n",
            "ألفريد               B-PERS     B-PERS     [39]\n",
            "نوبل                 B-PERS     I-PERS     [39]\n",
            "-------------------------------------------------------------------------\n",
            "نيويورك              B-LOC      B-LOC      [40]\n",
            "وواشنطن              B-LOC      I-LOC      [40]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-ORG      B-LOC      [41]\n",
            "المتحدة              I-ORG      I-LOC      [41]\n",
            "-------------------------------------------------------------------------\n",
            "جولي                 B-PERS     B-PERS     [41]\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "جولي                 B-PERS     B-PERS     [41]\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "harrass              O          B-MISC     [42]\n",
            "-------------------------------------------------------------------------\n",
            "نيويورك              B-ORG      B-LOC      [42]\n",
            "-------------------------------------------------------------------------\n",
            "دولارا               B-ORG      B-MISC     [42]\n",
            "-------------------------------------------------------------------------\n",
            "خليج                 O          B-LOC      [42]\n",
            "المكسيك              B-MISC     I-LOC      [42]\n",
            "-------------------------------------------------------------------------\n",
            "Salvador             B-PERS     B-PERS     [42]\n",
            "Dalí                 I-PERS     O          [42]\n",
            "-------------------------------------------------------------------------\n",
            "إسبانيا              O          B-LOC      [42]\n",
            "-------------------------------------------------------------------------\n",
            "دالي                 O          B-PERS     [43]\n",
            "-------------------------------------------------------------------------\n",
            "دالي                 O          B-PERS     [43]\n",
            "-------------------------------------------------------------------------\n",
            "إصرار                O          B-MISC     [43]\n",
            "الذاكرة              O          I-MISC     [43]\n",
            "-------------------------------------------------------------------------\n",
            "الحياة               B-MISC     B-MISC     [43]\n",
            "السرية               I-MISC     I-MISC     [43]\n",
            "لسلفادور             I-MISC     B-PERS     [43]\n",
            "-------------------------------------------------------------------------\n",
            "لسلفادور             I-MISC     B-PERS     [43]\n",
            "دالي                 I-MISC     I-PERS     [43]\n",
            "-------------------------------------------------------------------------\n",
            "الحسن                I-MISC     B-LOC      [44]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [44]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [44]\n",
            "-------------------------------------------------------------------------\n",
            "عمان                 I-MISC     B-LOC      [45]\n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [45]\n",
            "-------------------------------------------------------------------------\n",
            "الدرع                O          B-MISC     [45]\n",
            "والكأس               O          I-MISC     [45]\n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [45]\n",
            "-------------------------------------------------------------------------\n",
            "الحسين               I-PERS     B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "لؤي                  B-ORG      B-PERS     [45]\n",
            "العبادي              I-ORG      I-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "فالحسين              B-ORG      B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [45]\n",
            "عقاب                 O          I-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "الحسين               B-ORG      B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "الشباب               O          B-ORG      [45]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "قتيبة                O          B-PERS     [46]\n",
            "عرسان                O          I-PERS     [46]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "شهابات               O          B-PERS     [46]\n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "ورامي                B-PERS     B-PERS     [46]\n",
            "الذين                I-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "الزريقي              O          B-PERS     [47]\n",
            "-------------------------------------------------------------------------\n",
            "ذيابات               O          B-PERS     [47]\n",
            "-------------------------------------------------------------------------\n",
            "ورامي                O          B-PERS     [47]\n",
            "-------------------------------------------------------------------------\n",
            "ذيابات               O          B-MISC     [47]\n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [47]\n",
            "-------------------------------------------------------------------------\n",
            "رامي                 O          B-PERS     [47]\n",
            "-------------------------------------------------------------------------\n",
            "برفح                 O          B-LOC      [47]\n",
            "-------------------------------------------------------------------------\n",
            "فتح                  O          B-ORG      [47]\n",
            "-------------------------------------------------------------------------\n",
            "رام                  B-LOC      B-LOC      [48]\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "رام                  B-LOC      B-LOC      [48]\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "البندقية             I-MISC     B-MISC     [48]\n",
            "-------------------------------------------------------------------------\n",
            "أنا                  B-MISC     B-MISC     [48]\n",
            "وترانه               I-MISC     B-MISC     [48]\n",
            "-------------------------------------------------------------------------\n",
            "وترانه               I-MISC     B-MISC     [48]\n",
            "و15                  I-MISC     I-MISC     [48]\n",
            "سنة                  I-MISC     I-MISC     [48]\n",
            "-------------------------------------------------------------------------\n",
            "هوليود               O          B-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "طهران                B-ORG      B-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [49]\n",
            "لاريجاني             B-PERS     I-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "لمجلس                O          B-ORG      [49]\n",
            "الأمن                O          I-ORG      [49]\n",
            "-------------------------------------------------------------------------\n",
            "غلام                 B-PERS     B-PERS     [49]\n",
            "رضا                  B-PERS     I-PERS     [49]\n",
            "آغا                  I-PERS     I-PERS     [49]\n",
            "زاده                 O          I-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "بوشهر                O          B-LOC      [49]\n",
            "-------------------------------------------------------------------------\n",
            "ما                   O          B-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "هوي                  B-MISC     B-LOC      [49]\n",
            "-------------------------------------------------------------------------\n",
            "ومكة                 B-LOC      B-LOC      [49]\n",
            "المكرمة              I-LOC      O          [49]\n",
            "-------------------------------------------------------------------------\n",
            "الوليد               B-PERS     B-PERS     [50]\n",
            "بن                   I-PERS     I-PERS     [50]\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "كوبلي                B-ORG      B-MISC     [50]\n",
            "بلازا                I-ORG      I-MISC     [50]\n",
            "-------------------------------------------------------------------------\n",
            "الوليد               B-PERS     B-PERS     [50]\n",
            "بن                   I-PERS     I-PERS     [50]\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "المملكة              I-ORG      B-ORG      [50]\n",
            "القابضة              I-ORG      I-ORG      [50]\n",
            "-------------------------------------------------------------------------\n",
            "262\n",
            "TP:  [792, 627, 333, 151]\n",
            "FN:  [90, 29, 117, 78]\n",
            "FP:  [66, 78, 67, 51]\n",
            "FPC:  [792, 627, 333, 151]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDwZSl7tTpE0",
        "outputId": "0d14254a-56da-41f9-cafb-c89b9a26e0e7"
      },
      "source": [
        "#X_words_te=X_words[257:]  ## 257 is number of training sentences\n",
        "evaluate(test_labels, pred_labels, \"B-PERS\", X_words_te)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word                 True       Pred       sentence  \n",
            "تراب                 B-PERS     O          [1]\n",
            "-------------------------------------------------------------------------\n",
            "حظر                  B-PERS     O          [3]\n",
            "مسعود                I-PERS     B-PERS     [3]\n",
            "البارزاني            I-PERS     I-PERS     [3]\n",
            "-------------------------------------------------------------------------\n",
            "لاريجاني             B-PERS     I-PERS     [5]\n",
            "-------------------------------------------------------------------------\n",
            "البابا               B-PERS     O          [5]\n",
            "بنديكت               I-PERS     B-PERS     [5]\n",
            "ال                   I-PERS     O          [5]\n",
            "-------------------------------------------------------------------------\n",
            "الظواهري             B-PERS     B-PERS     [6]\n",
            "البابا               I-PERS     O          [6]\n",
            "بنديكت               I-PERS     B-PERS     [6]\n",
            "ال                   I-PERS     O          [6]\n",
            "-------------------------------------------------------------------------\n",
            "عمر                  B-PERS     B-PERS     [6]\n",
            "حسن                  I-PERS     I-PERS     [6]\n",
            "البشير               B-PERS     I-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "البشير               B-PERS     I-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "خوان                 B-PERS     B-PERS     [10]\n",
            "روما                 B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "روما                 B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "سيريل                B-PERS     B-PERS     [10]\n",
            "ديسبري               B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "ديسبري               B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "شينوزوكا             B-PERS     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "الهاجري              B-PERS     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "روما                 B-PERS     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "سينكت                B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "كوما                 B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "سالا                 B-PERS     B-MISC     [11]\n",
            "-------------------------------------------------------------------------\n",
            "كوكس                 B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "ميوني                B-PERS     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "راديك                B-PERS     B-PERS     [11]\n",
            "وفريدل               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وفريدل               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "دونالد               B-PERS     B-PERS     [11]\n",
            "وبالمر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وبالمر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "فيسنت                B-PERS     B-PERS     [11]\n",
            "وبورتاس              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وبورتاس              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "بالا                 B-PERS     B-PERS     [11]\n",
            "وفيزنر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وفيزنر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "روبي                 B-PERS     B-PERS     [11]\n",
            "وجون                 B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وجون                 B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "نوفاك                B-PERS     B-PERS     [11]\n",
            "وريكل                B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "وريكل                B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "اسبيلين              B-PERS     B-PERS     [11]\n",
            "ونيبورج              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "ونيبورج              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "دام                  B-PERS     B-PERS     [12]\n",
            "وقاسيك               B-PERS     I-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "وقاسيك               B-PERS     I-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-PERS     B-LOC      [12]\n",
            "المتحدة              I-PERS     I-LOC      [12]\n",
            "-------------------------------------------------------------------------\n",
            "بلعاوي               B-PERS     I-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "تبليسي               B-PERS     B-LOC      [15]\n",
            "-------------------------------------------------------------------------\n",
            "تبليسي               B-PERS     B-LOC      [16]\n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 B-PERS     B-ORG      [16]\n",
            "الامن                I-PERS     I-ORG      [16]\n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 B-PERS     B-ORG      [16]\n",
            "الامن                I-PERS     I-ORG      [16]\n",
            "-------------------------------------------------------------------------\n",
            "لاريجاني             B-PERS     I-PERS     [18]\n",
            "-------------------------------------------------------------------------\n",
            "فينوجرادوف           B-PERS     B-PERS     [22]\n",
            "ووليامز              B-PERS     I-PERS     [22]\n",
            "-------------------------------------------------------------------------\n",
            "ووليامز              B-PERS     I-PERS     [22]\n",
            "-------------------------------------------------------------------------\n",
            "فولكسفاجن            B-PERS     B-ORG      [23]\n",
            "-------------------------------------------------------------------------\n",
            "المقدسي              B-PERS     O          [23]\n",
            "-------------------------------------------------------------------------\n",
            "عبد                  B-PERS     B-PERS     [23]\n",
            "المجيد               I-PERS     I-PERS     [23]\n",
            "الذنيبات             O          I-PERS     [23]\n",
            "-------------------------------------------------------------------------\n",
            "الحسين               B-PERS     B-LOC      [24]\n",
            "-------------------------------------------------------------------------\n",
            "شاه                  B-PERS     I-PERS     [28]\n",
            "باكتيوال             I-PERS     I-PERS     [28]\n",
            "-------------------------------------------------------------------------\n",
            "داود                 B-PERS     B-MISC     [28]\n",
            "-------------------------------------------------------------------------\n",
            "الساعدي              B-PERS     B-PERS     [29]\n",
            "نجل                  I-PERS     O          [29]\n",
            "-------------------------------------------------------------------------\n",
            "الساعدي              B-PERS     B-PERS     [30]\n",
            "القذافي              B-PERS     I-PERS     [30]\n",
            "-------------------------------------------------------------------------\n",
            "القذافي              B-PERS     I-PERS     [30]\n",
            "-------------------------------------------------------------------------\n",
            "وإنديانابوليس        B-PERS     B-LOC      [31]\n",
            "-------------------------------------------------------------------------\n",
            "موفق                 B-PERS     B-PERS     [34]\n",
            "الربيعي              B-PERS     I-PERS     [34]\n",
            "-------------------------------------------------------------------------\n",
            "الربيعي              B-PERS     I-PERS     [34]\n",
            "-------------------------------------------------------------------------\n",
            "البابا               B-PERS     O          [35]\n",
            "-------------------------------------------------------------------------\n",
            "سيلفا                B-PERS     I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "سيلفا                B-PERS     I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "جابر                 B-PERS     B-PERS     [37]\n",
            "الأحمد               I-PERS     I-PERS     [37]\n",
            "الجابر               I-PERS     I-PERS     [37]\n",
            "الصباح               B-PERS     I-PERS     [37]\n",
            "-------------------------------------------------------------------------\n",
            "الصباح               B-PERS     I-PERS     [37]\n",
            "-------------------------------------------------------------------------\n",
            "ألفريد               B-PERS     B-PERS     [39]\n",
            "نوبل                 B-PERS     I-PERS     [39]\n",
            "-------------------------------------------------------------------------\n",
            "نوبل                 B-PERS     I-PERS     [39]\n",
            "-------------------------------------------------------------------------\n",
            "والجراح              B-PERS     O          [40]\n",
            "-------------------------------------------------------------------------\n",
            "والجراح              B-PERS     O          [40]\n",
            "-------------------------------------------------------------------------\n",
            "الجراح               B-PERS     O          [40]\n",
            "-------------------------------------------------------------------------\n",
            "جولي                 B-PERS     B-PERS     [41]\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "جولي                 B-PERS     B-PERS     [41]\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "Salvador             B-PERS     B-PERS     [42]\n",
            "Dalí                 I-PERS     O          [42]\n",
            "-------------------------------------------------------------------------\n",
            "عبده                 B-PERS     O          [45]\n",
            "الحسين               I-PERS     B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "والزبون              B-PERS     O          [45]\n",
            "-------------------------------------------------------------------------\n",
            "وخير                 B-PERS     O          [45]\n",
            "-------------------------------------------------------------------------\n",
            "الشرمان              B-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "للحفناوي             B-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الدينمو              B-PERS     O          [46]\n",
            "الحسنات              I-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "ورامي                B-PERS     B-PERS     [46]\n",
            "الذين                I-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "والمصري              B-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الحسنات              B-PERS     O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "ومقابلة              B-PERS     O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "المصري               B-PERS     O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "لاريجاني             B-PERS     I-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "غلام                 B-PERS     B-PERS     [49]\n",
            "رضا                  B-PERS     I-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "رضا                  B-PERS     I-PERS     [49]\n",
            "آغا                  I-PERS     I-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "الوليد               B-PERS     B-PERS     [50]\n",
            "بن                   I-PERS     I-PERS     [50]\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "الوليد               B-PERS     B-PERS     [50]\n",
            "بن                   I-PERS     I-PERS     [50]\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "وللوليد              B-PERS     O          [50]\n",
            "-------------------------------------------------------------------------\n",
            "90\n",
            "Word                 True       Pred       sentence  \n",
            "مسعود                I-PERS     B-PERS     [3]\n",
            "البارزاني            I-PERS     I-PERS     [3]\n",
            "-------------------------------------------------------------------------\n",
            "وعلي                 O          B-PERS     [5]\n",
            "لاريجاني             B-PERS     I-PERS     [5]\n",
            "-------------------------------------------------------------------------\n",
            "بنديكت               I-PERS     B-PERS     [5]\n",
            "-------------------------------------------------------------------------\n",
            "لخالد                B-LOC      B-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "الظواهري             B-PERS     B-PERS     [6]\n",
            "البابا               I-PERS     O          [6]\n",
            "-------------------------------------------------------------------------\n",
            "بنديكت               I-PERS     B-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "عمر                  B-PERS     B-PERS     [6]\n",
            "حسن                  I-PERS     I-PERS     [6]\n",
            "البشير               B-PERS     I-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "الهاجري              O          B-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "خوان                 B-PERS     B-PERS     [10]\n",
            "روما                 B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "سيريل                B-PERS     B-PERS     [10]\n",
            "ديسبري               B-PERS     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-PERS     [10]\n",
            "باجيرو               I-ORG      I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-PERS     [10]\n",
            "باجيرو               B-MISC     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "راديك                B-PERS     B-PERS     [11]\n",
            "وفريدل               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "دونالد               B-PERS     B-PERS     [11]\n",
            "وبالمر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "فيسنت                B-PERS     B-PERS     [11]\n",
            "وبورتاس              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "بالا                 B-PERS     B-PERS     [11]\n",
            "وفيزنر               B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "روبي                 B-PERS     B-PERS     [11]\n",
            "وجون                 B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "نوفاك                B-PERS     B-PERS     [11]\n",
            "وريكل                B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "اسبيلين              B-PERS     B-PERS     [11]\n",
            "ونيبورج              B-PERS     I-PERS     [11]\n",
            "-------------------------------------------------------------------------\n",
            "دام                  B-PERS     B-PERS     [12]\n",
            "وقاسيك               B-PERS     I-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "اندرسون              B-ORG      B-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "بان                  O          B-PERS     [16]\n",
            "-------------------------------------------------------------------------\n",
            "بان                  O          B-PERS     [16]\n",
            "-------------------------------------------------------------------------\n",
            "بان                  O          B-PERS     [16]\n",
            "-------------------------------------------------------------------------\n",
            "ادامنتوس             B-ORG      B-PERS     [17]\n",
            "فاسيلاكيس            I-ORG      I-PERS     [17]\n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [18]\n",
            "لاريجاني             B-PERS     I-PERS     [18]\n",
            "-------------------------------------------------------------------------\n",
            "فينوجرادوف           B-PERS     B-PERS     [22]\n",
            "ووليامز              B-PERS     I-PERS     [22]\n",
            "-------------------------------------------------------------------------\n",
            "عبد                  B-PERS     B-PERS     [23]\n",
            "المجيد               I-PERS     I-PERS     [23]\n",
            "الذنيبات             O          I-PERS     [23]\n",
            "-------------------------------------------------------------------------\n",
            "الذنيبات             O          B-PERS     [24]\n",
            "-------------------------------------------------------------------------\n",
            "الزواوي              O          B-PERS     [27]\n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [28]\n",
            "شاه                  B-PERS     I-PERS     [28]\n",
            "باكتيوال             I-PERS     I-PERS     [28]\n",
            "-------------------------------------------------------------------------\n",
            "الساعدي              B-PERS     B-PERS     [29]\n",
            "نجل                  I-PERS     O          [29]\n",
            "-------------------------------------------------------------------------\n",
            "الساعدي              B-PERS     B-PERS     [30]\n",
            "القذافي              B-PERS     I-PERS     [30]\n",
            "-------------------------------------------------------------------------\n",
            "زافي                 O          B-PERS     [30]\n",
            "هرنانديز             B-LOC      I-PERS     [30]\n",
            "-------------------------------------------------------------------------\n",
            "حميد                 I-ORG      B-PERS     [33]\n",
            "كورابى               I-ORG      I-PERS     [33]\n",
            "-------------------------------------------------------------------------\n",
            "موفق                 B-PERS     B-PERS     [34]\n",
            "الربيعي              B-PERS     I-PERS     [34]\n",
            "-------------------------------------------------------------------------\n",
            "دا                   O          B-PERS     [35]\n",
            "سيلفا                B-PERS     I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "لولا                 O          B-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "تارسو                B-ORG      B-PERS     [35]\n",
            "جينرو                I-ORG      I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "دا                   O          B-PERS     [35]\n",
            "سيلفا                B-PERS     I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "جابر                 B-PERS     B-PERS     [37]\n",
            "الأحمد               I-PERS     I-PERS     [37]\n",
            "الجابر               I-PERS     I-PERS     [37]\n",
            "الصباح               B-PERS     I-PERS     [37]\n",
            "-------------------------------------------------------------------------\n",
            "جور                  O          B-PERS     [38]\n",
            "-------------------------------------------------------------------------\n",
            "ألفريد               B-PERS     B-PERS     [39]\n",
            "نوبل                 B-PERS     I-PERS     [39]\n",
            "-------------------------------------------------------------------------\n",
            "جولي                 B-PERS     B-PERS     [41]\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "جولي                 B-PERS     B-PERS     [41]\n",
            "وايزنغر              B-PERS     I-PERS     [41]\n",
            "-------------------------------------------------------------------------\n",
            "Salvador             B-PERS     B-PERS     [42]\n",
            "Dalí                 I-PERS     O          [42]\n",
            "-------------------------------------------------------------------------\n",
            "دالي                 O          B-PERS     [43]\n",
            "-------------------------------------------------------------------------\n",
            "دالي                 O          B-PERS     [43]\n",
            "-------------------------------------------------------------------------\n",
            "لسلفادور             I-MISC     B-PERS     [43]\n",
            "دالي                 I-MISC     I-PERS     [43]\n",
            "-------------------------------------------------------------------------\n",
            "الحسين               I-PERS     B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "لؤي                  B-ORG      B-PERS     [45]\n",
            "العبادي              I-ORG      I-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "فالحسين              B-ORG      B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [45]\n",
            "عقاب                 O          I-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "الحسين               B-ORG      B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "قتيبة                O          B-PERS     [46]\n",
            "عرسان                O          I-PERS     [46]\n",
            "-------------------------------------------------------------------------\n",
            "شهابات               O          B-PERS     [46]\n",
            "-------------------------------------------------------------------------\n",
            "ورامي                B-PERS     B-PERS     [46]\n",
            "الذين                I-PERS     O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الزريقي              O          B-PERS     [47]\n",
            "-------------------------------------------------------------------------\n",
            "ذيابات               O          B-PERS     [47]\n",
            "-------------------------------------------------------------------------\n",
            "ورامي                O          B-PERS     [47]\n",
            "-------------------------------------------------------------------------\n",
            "رامي                 O          B-PERS     [47]\n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [49]\n",
            "لاريجاني             B-PERS     I-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "غلام                 B-PERS     B-PERS     [49]\n",
            "رضا                  B-PERS     I-PERS     [49]\n",
            "آغا                  I-PERS     I-PERS     [49]\n",
            "زاده                 O          I-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "ما                   O          B-PERS     [49]\n",
            "-------------------------------------------------------------------------\n",
            "الوليد               B-PERS     B-PERS     [50]\n",
            "بن                   I-PERS     I-PERS     [50]\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "الوليد               B-PERS     B-PERS     [50]\n",
            "بن                   I-PERS     I-PERS     [50]\n",
            "طلال                 B-PERS     I-PERS     [50]\n",
            "-------------------------------------------------------------------------\n",
            "66\n",
            "TP:  [792, 0, 0, 0]\n",
            "FN:  [90, 0, 0, 0]\n",
            "FP:  [66, 0, 0, 0]\n",
            "FPC:  [792, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06gXKXngf_jP",
        "outputId": "9f05e880-f2a3-4fc8-867b-2aeadda61c0c"
      },
      "source": [
        "#X_words_te=X_words[257:]  ## 257 is number of training sentences\n",
        "evaluate(test_labels, pred_labels, \"B-LOC\", X_words_te)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word                 True       Pred       sentence  \n",
            "ونايفة               B-LOC      O          [0]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-LOC      B-LOC      [1]\n",
            "المتحدة              B-ORG      I-LOC      [1]\n",
            "-------------------------------------------------------------------------\n",
            "كردستان              B-LOC      B-LOC      [3]\n",
            "العراق               I-LOC      B-LOC      [3]\n",
            "-------------------------------------------------------------------------\n",
            "بحر                  B-LOC      O          [5]\n",
            "الصين                I-LOC      B-LOC      [5]\n",
            "-------------------------------------------------------------------------\n",
            "لخالد                B-LOC      B-PERS     [6]\n",
            "-------------------------------------------------------------------------\n",
            "قطرية                B-LOC      O          [7]\n",
            "-------------------------------------------------------------------------\n",
            "سيرا                 B-LOC      B-LOC      [8]\n",
            "دو                   I-LOC      I-LOC      [8]\n",
            "كاشيمبو              I-LOC      B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "جنوب                 B-LOC      O          [11]\n",
            "افريقيا              I-LOC      B-LOC      [11]\n",
            "-------------------------------------------------------------------------\n",
            "الرياض               B-LOC      B-ORG      [15]\n",
            "-------------------------------------------------------------------------\n",
            "ادكار                B-LOC      B-LOC      [17]\n",
            "والقصور              I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "شابت                 B-LOC      B-LOC      [17]\n",
            "الأمير               I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-LOC      B-LOC      [17]\n",
            "المتحدة              B-ORG      I-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "بكينغهام             B-LOC      B-ORG      [19]\n",
            "-------------------------------------------------------------------------\n",
            "المريخ               B-LOC      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "المريخ               B-LOC      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "المريخ               B-LOC      B-ORG      [22]\n",
            "-------------------------------------------------------------------------\n",
            "هرنانديز             B-LOC      I-PERS     [30]\n",
            "-------------------------------------------------------------------------\n",
            "أستوكهولوم           B-LOC      B-LOC      [32]\n",
            "وأوسلو               I-LOC      B-LOC      [32]\n",
            "-------------------------------------------------------------------------\n",
            "النيل                B-LOC      O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "كاستل                B-LOC      B-LOC      [35]\n",
            "جاندولفو             B-LOC      I-LOC      [35]\n",
            "-------------------------------------------------------------------------\n",
            "جاندولفو             B-LOC      I-LOC      [35]\n",
            "-------------------------------------------------------------------------\n",
            "مدريد                B-LOC      I-ORG      [35]\n",
            "-------------------------------------------------------------------------\n",
            "مدريد                B-LOC      I-ORG      [36]\n",
            "-------------------------------------------------------------------------\n",
            "الخليج               B-LOC      I-MISC     [39]\n",
            "-------------------------------------------------------------------------\n",
            "نيويورك              B-LOC      B-LOC      [40]\n",
            "وواشنطن              B-LOC      I-LOC      [40]\n",
            "-------------------------------------------------------------------------\n",
            "وواشنطن              B-LOC      I-LOC      [40]\n",
            "-------------------------------------------------------------------------\n",
            "رام                  B-LOC      B-LOC      [48]\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "رام                  B-LOC      B-LOC      [48]\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "ومكة                 B-LOC      B-LOC      [49]\n",
            "المكرمة              I-LOC      O          [49]\n",
            "-------------------------------------------------------------------------\n",
            "29\n",
            "Word                 True       Pred       sentence  \n",
            "الصالحية             O          B-LOC      [0]\n",
            "-------------------------------------------------------------------------\n",
            "الأغوار              O          B-LOC      [0]\n",
            "-------------------------------------------------------------------------\n",
            "الصالحية             O          B-LOC      [0]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-LOC      B-LOC      [1]\n",
            "المتحدة              B-ORG      I-LOC      [1]\n",
            "-------------------------------------------------------------------------\n",
            "الشرق                B-ORG      B-LOC      [2]\n",
            "الأوسط               I-ORG      I-LOC      [2]\n",
            "-------------------------------------------------------------------------\n",
            "الجولان              O          B-LOC      [3]\n",
            "-------------------------------------------------------------------------\n",
            "كردستان              B-LOC      B-LOC      [3]\n",
            "العراق               I-LOC      B-LOC      [3]\n",
            "-------------------------------------------------------------------------\n",
            "العراق               I-LOC      B-LOC      [3]\n",
            "-------------------------------------------------------------------------\n",
            "الصين                I-LOC      B-LOC      [5]\n",
            "-------------------------------------------------------------------------\n",
            "قطر                  O          B-LOC      [7]\n",
            "-------------------------------------------------------------------------\n",
            "الضفة                O          B-LOC      [8]\n",
            "الغربية              O          I-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "مانوس                B-MISC     B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "مانوس                B-MISC     B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "سيرا                 B-LOC      B-LOC      [8]\n",
            "دو                   I-LOC      I-LOC      [8]\n",
            "كاشيمبو              I-LOC      B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "كاشيمبو              I-LOC      B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "فرنسا                I-ORG      B-LOC      [9]\n",
            "-------------------------------------------------------------------------\n",
            "مدريد                B-ORG      B-LOC      [9]\n",
            "-------------------------------------------------------------------------\n",
            "باريس                I-MISC     B-LOC      [9]\n",
            "-------------------------------------------------------------------------\n",
            "باريس                I-MISC     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "داكار                I-MISC     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "الرشيدة              O          B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "شليسير               B-ORG      B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "روما                 B-PERS     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "افريقيا              I-LOC      B-LOC      [11]\n",
            "-------------------------------------------------------------------------\n",
            "اندرسون              B-ORG      B-LOC      [12]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-PERS     B-LOC      [12]\n",
            "المتحدة              I-PERS     I-LOC      [12]\n",
            "الأميركية            O          I-LOC      [12]\n",
            "-------------------------------------------------------------------------\n",
            "بالمانيا             O          B-LOC      [13]\n",
            "-------------------------------------------------------------------------\n",
            "لالمانيا             O          B-LOC      [13]\n",
            "-------------------------------------------------------------------------\n",
            "الاناضول             B-ORG      B-LOC      [14]\n",
            "-------------------------------------------------------------------------\n",
            "الاناضول             B-ORG      B-LOC      [14]\n",
            "-------------------------------------------------------------------------\n",
            "ياسوكوني             B-MISC     B-LOC      [15]\n",
            "-------------------------------------------------------------------------\n",
            "تبليسي               B-PERS     B-LOC      [15]\n",
            "-------------------------------------------------------------------------\n",
            "تبليسي               B-PERS     B-LOC      [16]\n",
            "-------------------------------------------------------------------------\n",
            "ادكار                B-LOC      B-LOC      [17]\n",
            "والقصور              I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "والقصور              I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "شابت                 B-LOC      B-LOC      [17]\n",
            "الأمير               I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "الأمير               I-LOC      B-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-LOC      B-LOC      [17]\n",
            "المتحدة              B-ORG      I-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "لألمانيا             O          B-LOC      [23]\n",
            "-------------------------------------------------------------------------\n",
            "الحسين               B-PERS     B-LOC      [24]\n",
            "-------------------------------------------------------------------------\n",
            "تشيكوسلوفاكيا        I-LOC      B-LOC      [26]\n",
            "-------------------------------------------------------------------------\n",
            "بازل                 O          B-LOC      [29]\n",
            "-------------------------------------------------------------------------\n",
            "غاتويك               B-MISC     B-LOC      [30]\n",
            "-------------------------------------------------------------------------\n",
            "أوروبا               I-MISC     B-LOC      [30]\n",
            "-------------------------------------------------------------------------\n",
            "وإنديانابوليس        B-PERS     B-LOC      [31]\n",
            "-------------------------------------------------------------------------\n",
            "أستوكهولوم           B-LOC      B-LOC      [32]\n",
            "وأوسلو               I-LOC      B-LOC      [32]\n",
            "-------------------------------------------------------------------------\n",
            "وأوسلو               I-LOC      B-LOC      [32]\n",
            "-------------------------------------------------------------------------\n",
            "البحر                I-MISC     B-LOC      [33]\n",
            "الأبيض               I-MISC     I-LOC      [33]\n",
            "المتوسط              I-MISC     I-LOC      [33]\n",
            "-------------------------------------------------------------------------\n",
            "الانبار              O          B-LOC      [34]\n",
            "-------------------------------------------------------------------------\n",
            "كاستل                B-LOC      B-LOC      [35]\n",
            "جاندولفو             B-LOC      I-LOC      [35]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [36]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [36]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "فرنسا                B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "وإسبانيا             B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "وكندا                B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "جنوب                 B-ORG      B-LOC      [37]\n",
            "أفريقيا              I-ORG      I-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "ماليزيا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "إنجلترا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "هولندا               B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "إنجلترا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "نيويورك              B-LOC      B-LOC      [40]\n",
            "وواشنطن              B-LOC      I-LOC      [40]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-ORG      B-LOC      [41]\n",
            "المتحدة              I-ORG      I-LOC      [41]\n",
            "-------------------------------------------------------------------------\n",
            "نيويورك              B-ORG      B-LOC      [42]\n",
            "-------------------------------------------------------------------------\n",
            "خليج                 O          B-LOC      [42]\n",
            "المكسيك              B-MISC     I-LOC      [42]\n",
            "-------------------------------------------------------------------------\n",
            "إسبانيا              O          B-LOC      [42]\n",
            "-------------------------------------------------------------------------\n",
            "الحسن                I-MISC     B-LOC      [44]\n",
            "-------------------------------------------------------------------------\n",
            "عمان                 I-MISC     B-LOC      [45]\n",
            "-------------------------------------------------------------------------\n",
            "برفح                 O          B-LOC      [47]\n",
            "-------------------------------------------------------------------------\n",
            "رام                  B-LOC      B-LOC      [48]\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "رام                  B-LOC      B-LOC      [48]\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "هوليود               O          B-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "طهران                B-ORG      B-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "بوشهر                O          B-LOC      [49]\n",
            "-------------------------------------------------------------------------\n",
            "هوي                  B-MISC     B-LOC      [49]\n",
            "-------------------------------------------------------------------------\n",
            "ومكة                 B-LOC      B-LOC      [49]\n",
            "المكرمة              I-LOC      O          [49]\n",
            "-------------------------------------------------------------------------\n",
            "78\n",
            "TP:  [0, 627, 0, 0]\n",
            "FN:  [0, 29, 0, 0]\n",
            "FP:  [0, 78, 0, 0]\n",
            "FPC:  [0, 627, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tUVs9FVf_n2",
        "outputId": "86537c8f-ecc4-4411-8532-95123c5effa5"
      },
      "source": [
        "#X_words_te=X_words[257:]  ## 257 is number of training sentences\n",
        "evaluate(test_labels, pred_labels, \"B-ORG\", X_words_te)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word                 True       Pred       sentence  \n",
            "المتحدة              B-ORG      I-LOC      [1]\n",
            "-------------------------------------------------------------------------\n",
            "الأمن                B-ORG      O          [1]\n",
            "-------------------------------------------------------------------------\n",
            "دار                  B-ORG      O          [2]\n",
            "الهيئة               I-ORG      O          [2]\n",
            "المصرية              I-ORG      O          [2]\n",
            "العامة               I-ORG      O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "حزب                  B-ORG      O          [2]\n",
            "التجمع               I-ORG      O          [2]\n",
            "المصري               I-ORG      O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "قناة                 B-ORG      O          [2]\n",
            "السويس               I-ORG      I-ORG      [2]\n",
            "الاستعمارية          I-ORG      O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "الشرق                B-ORG      B-LOC      [2]\n",
            "الأوسط               I-ORG      I-LOC      [2]\n",
            "-------------------------------------------------------------------------\n",
            "الجماعة              B-ORG      O          [3]\n",
            "المسلمة              I-ORG      O          [3]\n",
            "-------------------------------------------------------------------------\n",
            "بجماعة               B-ORG      O          [3]\n",
            "التكفير              I-ORG      O          [3]\n",
            "والهجرة              I-ORG      O          [3]\n",
            "-------------------------------------------------------------------------\n",
            "جماعة                B-ORG      O          [3]\n",
            "الجهاد               I-ORG      O          [3]\n",
            "-------------------------------------------------------------------------\n",
            "والجماعة             B-ORG      O          [3]\n",
            "الإسلامية            I-ORG      O          [3]\n",
            "-------------------------------------------------------------------------\n",
            "السنة                B-ORG      B-ORG      [3]\n",
            "والشيعة              I-ORG      B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "الأمم                B-ORG      B-ORG      [5]\n",
            "المتحدة              I-ORG      I-ORG      [5]\n",
            "للتربية              O          I-ORG      [5]\n",
            "-------------------------------------------------------------------------\n",
            "جماعة                B-ORG      O          [6]\n",
            "قاعدة                I-ORG      O          [6]\n",
            "-------------------------------------------------------------------------\n",
            "الجهاد               B-ORG      O          [6]\n",
            "-------------------------------------------------------------------------\n",
            "حركة                 B-ORG      O          [7]\n",
            "المقاومة             I-ORG      B-ORG      [7]\n",
            "الإسلامية            I-ORG      I-ORG      [7]\n",
            "-------------------------------------------------------------------------\n",
            "هوائيتين             B-ORG      O          [7]\n",
            "-------------------------------------------------------------------------\n",
            "البوينغ              B-ORG      B-MISC     [8]\n",
            "-------------------------------------------------------------------------\n",
            "GOL                  B-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "البوينغ              B-ORG      B-MISC     [8]\n",
            "-------------------------------------------------------------------------\n",
            "رابطة                B-ORG      O          [8]\n",
            "البنوك               I-ORG      O          [8]\n",
            "الايطالية            I-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "البنك                B-ORG      B-ORG      [8]\n",
            "المركزي              I-ORG      I-ORG      [8]\n",
            "الايطالي             I-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "بنك                  B-ORG      B-ORG      [8]\n",
            "ايطاليا              I-ORG      I-ORG      [8]\n",
            "المركزي              I-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "بنك                  B-ORG      O          [9]\n",
            "فرنسا                I-ORG      B-LOC      [9]\n",
            "المركزي              I-ORG      O          [9]\n",
            "-------------------------------------------------------------------------\n",
            "مدريد                B-ORG      B-LOC      [9]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-ORG      [10]\n",
            "باجيرو               B-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "قطر                  B-ORG      B-ORG      [10]\n",
            "للراليات             O          I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "حماس                 B-ORG      O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "نيسان                B-ORG      B-ORG      [10]\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "نيسان                B-ORG      B-ORG      [10]\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-PERS     [10]\n",
            "باجيرو               I-ORG      I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "شليسير               B-ORG      B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "ارثر                 B-ORG      B-ORG      [12]\n",
            "اندرسون              I-ORG      I-ORG      [12]\n",
            "للمحاسبة             I-ORG      O          [12]\n",
            "-------------------------------------------------------------------------\n",
            "اندرسون              B-ORG      B-LOC      [12]\n",
            "-------------------------------------------------------------------------\n",
            "اندرسون              B-ORG      B-PERS     [12]\n",
            "-------------------------------------------------------------------------\n",
            "انرون                B-ORG      B-MISC     [12]\n",
            "-------------------------------------------------------------------------\n",
            "الاناضول             B-ORG      B-LOC      [14]\n",
            "-------------------------------------------------------------------------\n",
            "الحزب                B-ORG      O          [14]\n",
            "الكردي               I-ORG      O          [14]\n",
            "الانفصالي            I-ORG      O          [14]\n",
            "-------------------------------------------------------------------------\n",
            "الاناضول             B-ORG      B-LOC      [14]\n",
            "-------------------------------------------------------------------------\n",
            "ادامنتوس             B-ORG      B-PERS     [17]\n",
            "فاسيلاكيس            I-ORG      I-PERS     [17]\n",
            "-------------------------------------------------------------------------\n",
            "للجماعة              B-ORG      O          [17]\n",
            "السلفية              I-ORG      O          [17]\n",
            "للتبشير              I-ORG      O          [17]\n",
            "والجهاد              I-ORG      O          [17]\n",
            "-------------------------------------------------------------------------\n",
            "مجموعة               B-ORG      O          [17]\n",
            "السلفية              I-ORG      O          [17]\n",
            "للتبشير              I-ORG      O          [17]\n",
            "والجهاد              I-ORG      O          [17]\n",
            "-------------------------------------------------------------------------\n",
            "الجماعة              B-ORG      O          [17]\n",
            "السلفية              I-ORG      O          [17]\n",
            "للتبشير              I-ORG      O          [17]\n",
            "والجهاد              I-ORG      O          [17]\n",
            "-------------------------------------------------------------------------\n",
            "للمعهد               B-ORG      O          [17]\n",
            "الملكي               I-ORG      O          [17]\n",
            "البريطاني            I-ORG      O          [17]\n",
            "للدراسات             I-ORG      O          [17]\n",
            "الدولية              I-ORG      O          [17]\n",
            "-------------------------------------------------------------------------\n",
            "المتحدة              B-ORG      I-LOC      [17]\n",
            "-------------------------------------------------------------------------\n",
            "سان                  B-ORG      I-ORG      [17]\n",
            "اندرو                I-ORG      I-ORG      [17]\n",
            "-------------------------------------------------------------------------\n",
            "الجامعة              B-ORG      O          [19]\n",
            "المغربية             I-ORG      O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "اتحاد                B-ORG      O          [19]\n",
            "المجامع              I-ORG      O          [19]\n",
            "اللغوية              I-ORG      O          [19]\n",
            "العربية              I-ORG      O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "وDell                B-ORG      O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "وDell                B-ORG      O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "IBM                  B-ORG      B-ORG      [19]\n",
            "وLenovo              B-ORG      I-ORG      [19]\n",
            "-------------------------------------------------------------------------\n",
            "وLenovo              B-ORG      I-ORG      [19]\n",
            "-------------------------------------------------------------------------\n",
            "وLenovo              B-ORG      O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "وDell                B-ORG      O          [20]\n",
            "-------------------------------------------------------------------------\n",
            "باناسونيك            B-ORG      B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "الحركة               B-ORG      O          [20]\n",
            "الطلابية             I-ORG      O          [20]\n",
            "الإسلامية            I-ORG      O          [20]\n",
            "-------------------------------------------------------------------------\n",
            "لوكالة               B-ORG      O          [21]\n",
            "الأنباء              I-ORG      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "الحركة               B-ORG      O          [21]\n",
            "الطلابية             I-ORG      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "الحركة               B-ORG      O          [21]\n",
            "الطلابية             I-ORG      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "للاتهامات            B-ORG      O          [21]\n",
            "-------------------------------------------------------------------------\n",
            "ناسا                 B-ORG      I-ORG      [21]\n",
            "-------------------------------------------------------------------------\n",
            "للحركة               B-ORG      O          [24]\n",
            "الإسلامية            I-ORG      O          [24]\n",
            "-------------------------------------------------------------------------\n",
            "المجلس               B-ORG      O          [24]\n",
            "العالي               I-ORG      O          [24]\n",
            "للدستور              I-ORG      O          [24]\n",
            "-------------------------------------------------------------------------\n",
            "الترجي               B-ORG      B-ORG      [26]\n",
            "الرياضي              O          I-ORG      [26]\n",
            "-------------------------------------------------------------------------\n",
            "والملعب              B-ORG      O          [26]\n",
            "التونسي              I-ORG      O          [26]\n",
            "-------------------------------------------------------------------------\n",
            "حزب                  B-ORG      O          [29]\n",
            "الاتحاد              I-ORG      O          [29]\n",
            "الديمقراطي           I-ORG      O          [29]\n",
            "-------------------------------------------------------------------------\n",
            "مركز                 B-ORG      O          [29]\n",
            "إينتسر               I-ORG      B-ORG      [29]\n",
            "-------------------------------------------------------------------------\n",
            "بمركز                B-ORG      O          [32]\n",
            "الغوري               I-ORG      O          [32]\n",
            "للتراث               I-ORG      O          [32]\n",
            "الموسيقي             I-ORG      O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "ومعهد                B-ORG      O          [32]\n",
            "الموسيقى             I-ORG      O          [32]\n",
            "العربية              I-ORG      O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "الأزهر               B-ORG      O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "معهد                 B-ORG      B-ORG      [33]\n",
            "رويان                I-ORG      I-ORG      [33]\n",
            "للبحوث               I-ORG      O          [33]\n",
            "العلمية              I-ORG      O          [33]\n",
            "حميد                 I-ORG      B-PERS     [33]\n",
            "كورابى               I-ORG      I-PERS     [33]\n",
            "-------------------------------------------------------------------------\n",
            "معهد                 B-ORG      O          [33]\n",
            "رويان                I-ORG      B-ORG      [33]\n",
            "-------------------------------------------------------------------------\n",
            "تارسو                B-ORG      B-PERS     [35]\n",
            "جينرو                I-ORG      I-PERS     [35]\n",
            "-------------------------------------------------------------------------\n",
            "ريال                 B-ORG      B-ORG      [35]\n",
            "مدريد                B-LOC      I-ORG      [35]\n",
            "-------------------------------------------------------------------------\n",
            "ريال                 B-ORG      B-ORG      [36]\n",
            "مدريد                B-LOC      I-ORG      [36]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [36]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [36]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "فرنسا                B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "وإسبانيا             B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "وكندا                B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "جنوب                 B-ORG      B-LOC      [37]\n",
            "أفريقيا              I-ORG      I-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "ماليزيا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "إنجلترا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "هولندا               B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "إنجلترا              B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]\n",
            "-------------------------------------------------------------------------\n",
            "المؤسسة              B-ORG      B-ORG      [37]\n",
            "العربية              I-ORG      I-ORG      [37]\n",
            "لضمان                I-ORG      O          [37]\n",
            "الاستثمار            I-ORG      O          [37]\n",
            "-------------------------------------------------------------------------\n",
            "جامعة                B-ORG      B-ORG      [38]\n",
            "جورجتاون             B-ORG      I-ORG      [38]\n",
            "-------------------------------------------------------------------------\n",
            "جورجتاون             B-ORG      I-ORG      [38]\n",
            "-------------------------------------------------------------------------\n",
            "البنك                B-ORG      O          [39]\n",
            "المركزي              I-ORG      O          [39]\n",
            "السويدي              I-ORG      O          [39]\n",
            "-------------------------------------------------------------------------\n",
            "القاعدة              B-ORG      O          [40]\n",
            "-------------------------------------------------------------------------\n",
            "القاعدة              B-ORG      O          [41]\n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-ORG      B-LOC      [41]\n",
            "المتحدة              I-ORG      I-LOC      [41]\n",
            "-------------------------------------------------------------------------\n",
            "نيويورك              B-ORG      B-LOC      [42]\n",
            "-------------------------------------------------------------------------\n",
            "دولارا               B-ORG      B-MISC     [42]\n",
            "-------------------------------------------------------------------------\n",
            "مدمر                 B-ORG      O          [42]\n",
            "-------------------------------------------------------------------------\n",
            "لؤي                  B-ORG      B-PERS     [45]\n",
            "العبادي              I-ORG      I-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "فالحسين              B-ORG      B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "فالحسين              B-ORG      O          [45]\n",
            "-------------------------------------------------------------------------\n",
            "الحسين               B-ORG      B-PERS     [45]\n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "الرياحنة             B-ORG      O          [46]\n",
            "-------------------------------------------------------------------------\n",
            "التحرير              B-ORG      O          [47]\n",
            "الوطني               I-ORG      O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "والمقاومة            B-ORG      O          [47]\n",
            "الإسلامية            I-ORG      O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "فتح                  B-ORG      O          [47]\n",
            "-------------------------------------------------------------------------\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "الله                 B-ORG      I-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "طهران                B-ORG      B-LOC      [48]\n",
            "-------------------------------------------------------------------------\n",
            "هيئة                 B-ORG      O          [49]\n",
            "الطاقة               I-ORG      O          [49]\n",
            "الذرية               I-ORG      O          [49]\n",
            "الإيرانية            I-ORG      O          [49]\n",
            "-------------------------------------------------------------------------\n",
            "كوبلي                B-ORG      B-MISC     [50]\n",
            "بلازا                I-ORG      I-MISC     [50]\n",
            "-------------------------------------------------------------------------\n",
            "الشركة               B-ORG      O          [50]\n",
            "العربية              I-ORG      O          [50]\n",
            "للإنتاج              I-ORG      O          [50]\n",
            "الإعلامي             I-ORG      O          [50]\n",
            "-------------------------------------------------------------------------\n",
            "شركة                 B-ORG      O          [50]\n",
            "المملكة              I-ORG      B-ORG      [50]\n",
            "القابضة              I-ORG      I-ORG      [50]\n",
            "-------------------------------------------------------------------------\n",
            "117\n",
            "Word                 True       Pred       sentence  \n",
            "ونايفة               O          B-ORG      [0]\n",
            "-------------------------------------------------------------------------\n",
            "الإخوان              I-MISC     B-ORG      [2]\n",
            "المسلمين             I-MISC     I-ORG      [2]\n",
            "-------------------------------------------------------------------------\n",
            "الدولة               B-MISC     B-ORG      [2]\n",
            "الأموية              I-MISC     I-ORG      [2]\n",
            "-------------------------------------------------------------------------\n",
            "الإخوان              O          B-ORG      [2]\n",
            "المسلمين             O          I-ORG      [2]\n",
            "-------------------------------------------------------------------------\n",
            "الأكراد              O          B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "وسنة                 O          B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "السنة                B-ORG      B-ORG      [3]\n",
            "والشيعة              I-ORG      B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "والشيعة              I-ORG      B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "والأكراد             O          B-ORG      [3]\n",
            "-------------------------------------------------------------------------\n",
            "بمنظمة               O          B-ORG      [5]\n",
            "-------------------------------------------------------------------------\n",
            "الأمم                B-ORG      B-ORG      [5]\n",
            "المتحدة              I-ORG      I-ORG      [5]\n",
            "للتربية              O          I-ORG      [5]\n",
            "والعلوم              O          I-ORG      [5]\n",
            "والثقافة             O          I-ORG      [5]\n",
            "-------------------------------------------------------------------------\n",
            "المقاومة             I-ORG      B-ORG      [7]\n",
            "الإسلامية            I-ORG      I-ORG      [7]\n",
            "-------------------------------------------------------------------------\n",
            "حماس                 O          B-ORG      [7]\n",
            "-------------------------------------------------------------------------\n",
            "بحماس                O          B-ORG      [7]\n",
            "-------------------------------------------------------------------------\n",
            "البنك                B-ORG      B-ORG      [8]\n",
            "المركزي              I-ORG      I-ORG      [8]\n",
            "الايطالي             I-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "بنك                  B-ORG      B-ORG      [8]\n",
            "ايطاليا              I-ORG      I-ORG      [8]\n",
            "المركزي              I-ORG      O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-ORG      [10]\n",
            "باجيرو               B-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "قطر                  B-ORG      B-ORG      [10]\n",
            "للراليات             O          I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "نيسان                B-ORG      B-ORG      [10]\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "آب                   I-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "نيسان                B-ORG      B-ORG      [10]\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "آب                   I-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "سينكت                B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "كوما                 B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "كوكس                 B-PERS     B-ORG      [11]\n",
            "-------------------------------------------------------------------------\n",
            "ارثر                 B-ORG      B-ORG      [12]\n",
            "اندرسون              I-ORG      I-ORG      [12]\n",
            "للمحاسبة             I-ORG      O          [12]\n",
            "-------------------------------------------------------------------------\n",
            "من                   O          B-ORG      [14]\n",
            "اجل                  O          I-ORG      [14]\n",
            "مجتمع                O          I-ORG      [14]\n",
            "ديمقراطي             O          I-ORG      [14]\n",
            "-------------------------------------------------------------------------\n",
            "الاكراد              O          B-ORG      [14]\n",
            "-------------------------------------------------------------------------\n",
            "الرياض               B-LOC      B-ORG      [15]\n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 B-PERS     B-ORG      [16]\n",
            "الامن                I-PERS     I-ORG      [16]\n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 B-PERS     B-ORG      [16]\n",
            "الامن                I-PERS     I-ORG      [16]\n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 O          B-ORG      [16]\n",
            "الامن                O          I-ORG      [16]\n",
            "-------------------------------------------------------------------------\n",
            "جامعة                O          B-ORG      [17]\n",
            "سان                  B-ORG      I-ORG      [17]\n",
            "اندرو                I-ORG      I-ORG      [17]\n",
            "-------------------------------------------------------------------------\n",
            "الوكالة              O          B-ORG      [18]\n",
            "الدولية              O          I-ORG      [18]\n",
            "للطاقة               O          I-ORG      [18]\n",
            "الذرية               O          I-ORG      [18]\n",
            "-------------------------------------------------------------------------\n",
            "بكينغهام             B-LOC      B-ORG      [19]\n",
            "-------------------------------------------------------------------------\n",
            "IBM                  B-ORG      B-ORG      [19]\n",
            "وLenovo              B-ORG      I-ORG      [19]\n",
            "-------------------------------------------------------------------------\n",
            "العسكر               O          B-ORG      [21]\n",
            "الطيبة               O          I-ORG      [21]\n",
            "-------------------------------------------------------------------------\n",
            "لوكالة               O          B-ORG      [21]\n",
            "الفضاء               O          I-ORG      [21]\n",
            "الأمريكية            O          I-ORG      [21]\n",
            "ناسا                 B-ORG      I-ORG      [21]\n",
            "-------------------------------------------------------------------------\n",
            "المريخ               B-LOC      B-ORG      [22]\n",
            "-------------------------------------------------------------------------\n",
            "بيكنور               B-MISC     B-ORG      [22]\n",
            "-------------------------------------------------------------------------\n",
            "فولكسفاجن            B-PERS     B-ORG      [23]\n",
            "-------------------------------------------------------------------------\n",
            "ويمبلدون             B-MISC     B-ORG      [25]\n",
            "-------------------------------------------------------------------------\n",
            "السمبا               B-MISC     B-ORG      [26]\n",
            "-------------------------------------------------------------------------\n",
            "الترجي               B-ORG      B-ORG      [26]\n",
            "الرياضي              O          I-ORG      [26]\n",
            "-------------------------------------------------------------------------\n",
            "النجم                O          B-ORG      [26]\n",
            "الساحلي              O          I-ORG      [26]\n",
            "-------------------------------------------------------------------------\n",
            "إينتسر               I-ORG      B-ORG      [29]\n",
            "-------------------------------------------------------------------------\n",
            "معهد                 B-ORG      B-ORG      [33]\n",
            "رويان                I-ORG      I-ORG      [33]\n",
            "للبحوث               I-ORG      O          [33]\n",
            "-------------------------------------------------------------------------\n",
            "رويان                I-ORG      B-ORG      [33]\n",
            "-------------------------------------------------------------------------\n",
            "سني                  O          B-ORG      [34]\n",
            "-------------------------------------------------------------------------\n",
            "ريال                 B-ORG      B-ORG      [35]\n",
            "مدريد                B-LOC      I-ORG      [35]\n",
            "-------------------------------------------------------------------------\n",
            "ريال                 B-ORG      B-ORG      [36]\n",
            "مدريد                B-LOC      I-ORG      [36]\n",
            "-------------------------------------------------------------------------\n",
            "الريال               O          B-ORG      [36]\n",
            "-------------------------------------------------------------------------\n",
            "المؤسسة              B-ORG      B-ORG      [37]\n",
            "العربية              I-ORG      I-ORG      [37]\n",
            "لضمان                I-ORG      O          [37]\n",
            "-------------------------------------------------------------------------\n",
            "جامعة                B-ORG      B-ORG      [38]\n",
            "جورجتاون             B-ORG      I-ORG      [38]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [44]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [44]\n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [45]\n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [45]\n",
            "-------------------------------------------------------------------------\n",
            "الشباب               O          B-ORG      [45]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [46]\n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [47]\n",
            "-------------------------------------------------------------------------\n",
            "فتح                  O          B-ORG      [47]\n",
            "-------------------------------------------------------------------------\n",
            "لمجلس                O          B-ORG      [49]\n",
            "الأمن                O          I-ORG      [49]\n",
            "-------------------------------------------------------------------------\n",
            "المملكة              I-ORG      B-ORG      [50]\n",
            "القابضة              I-ORG      I-ORG      [50]\n",
            "-------------------------------------------------------------------------\n",
            "67\n",
            "TP:  [0, 0, 333, 0]\n",
            "FN:  [0, 0, 117, 0]\n",
            "FP:  [0, 0, 67, 0]\n",
            "FPC:  [0, 0, 333, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYsIUKOkf_rC",
        "outputId": "94db2212-421d-4f81-ba5c-e87711914cd7"
      },
      "source": [
        "#X_words_te=X_words[257:]  ## 257 is number of training sentences\n",
        "evaluate(test_labels, pred_labels, \"B-MISC\", X_words_te)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word                 True       Pred       sentence  \n",
            "التأسلم              B-MISC     O          [2]\n",
            "السياسي              I-MISC     O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "الخلفاء              B-MISC     O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "الراشدين             B-MISC     O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "الدولة               B-MISC     B-ORG      [2]\n",
            "الأموية              I-MISC     I-ORG      [2]\n",
            "-------------------------------------------------------------------------\n",
            "العباسية             B-MISC     O          [2]\n",
            "-------------------------------------------------------------------------\n",
            "بوصوله               B-MISC     O          [5]\n",
            "-------------------------------------------------------------------------\n",
            "المسيحية             B-MISC     O          [6]\n",
            "-------------------------------------------------------------------------\n",
            "مانوس                B-MISC     B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "مانوس                B-MISC     B-LOC      [8]\n",
            "-------------------------------------------------------------------------\n",
            "الليرة               B-MISC     O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "بالليرة              B-MISC     O          [8]\n",
            "-------------------------------------------------------------------------\n",
            "ماراثون              B-MISC     O          [9]\n",
            "باريس                I-MISC     B-LOC      [9]\n",
            "-------------------------------------------------------------------------\n",
            "بيك                  B-MISC     B-MISC     [10]\n",
            "آب                   I-MISC     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "الرالي               B-MISC     O          [10]\n",
            "القطري               I-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "ال                   B-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "رالي                 B-MISC     B-MISC     [10]\n",
            "باريس                I-MISC     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     B-MISC     [10]\n",
            "تي                   I-MISC     I-MISC     [10]\n",
            "إم                   I-MISC     I-MISC     [10]\n",
            "إل                   I-MISC     I-MISC     [10]\n",
            "سي4                  I-MISC     I-MISC     [10]\n",
            "660                  I-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "للرالي               B-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "آب                   I-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "بيك                  B-MISC     I-ORG      [10]\n",
            "آب                   I-MISC     I-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "ال                   B-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-PERS     [10]\n",
            "-------------------------------------------------------------------------\n",
            "ال                   B-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "200                  B-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [10]\n",
            "تي                   I-MISC     I-MISC     [10]\n",
            "إم                   I-MISC     I-MISC     [10]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [10]\n",
            "تي                   I-MISC     O          [10]\n",
            "إم                   I-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [10]\n",
            "تي                   I-MISC     O          [10]\n",
            "إم                   I-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تي                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تي                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تي                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تم                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تم                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]\n",
            "تم                   I-MISC     O          [11]\n",
            "إم                   I-MISC     O          [11]\n",
            "-------------------------------------------------------------------------\n",
            "ياسوكوني             B-MISC     B-LOC      [15]\n",
            "-------------------------------------------------------------------------\n",
            "معجم                 B-MISC     O          [19]\n",
            "تاريخي               I-MISC     O          [19]\n",
            "للغة                 I-MISC     O          [19]\n",
            "العربية              I-MISC     O          [19]\n",
            "-------------------------------------------------------------------------\n",
            "لتس                  B-MISC     B-MISC     [20]\n",
            "نوت                  I-MISC     I-MISC     [20]\n",
            "CF                   I-MISC     B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "بيكنور               B-MISC     B-ORG      [22]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [25]\n",
            "التنس                I-MISC     I-MISC     [25]\n",
            "الفردي               I-MISC     I-MISC     [25]\n",
            "الدولية              I-MISC     I-MISC     [25]\n",
            "المفتوحة             I-MISC     O          [25]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     O          [25]\n",
            "ويمبلدون             I-MISC     B-MISC     [25]\n",
            "الدولية              I-MISC     O          [25]\n",
            "للتنس                I-MISC     O          [25]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [25]\n",
            "فرنسا                I-MISC     I-MISC     [25]\n",
            "المفتوحة             I-MISC     I-MISC     [25]\n",
            "للتنس                O          I-MISC     [25]\n",
            "-------------------------------------------------------------------------\n",
            "ويمبلدون             B-MISC     B-ORG      [25]\n",
            "-------------------------------------------------------------------------\n",
            "السمبا               B-MISC     B-ORG      [26]\n",
            "-------------------------------------------------------------------------\n",
            "كأس                  B-MISC     O          [26]\n",
            "الاتحاد              I-MISC     I-MISC     [26]\n",
            "الأفريقي             I-MISC     I-MISC     [26]\n",
            "لكرة                 I-MISC     O          [26]\n",
            "القدم                I-MISC     O          [26]\n",
            "-------------------------------------------------------------------------\n",
            "غاتويك               B-MISC     B-LOC      [30]\n",
            "-------------------------------------------------------------------------\n",
            "دوري                 B-MISC     O          [30]\n",
            "أبطال                I-MISC     O          [30]\n",
            "أوروبا               I-MISC     B-LOC      [30]\n",
            "-------------------------------------------------------------------------\n",
            "بطولة                B-MISC     B-MISC     [31]\n",
            "تايلند               I-MISC     I-MISC     [31]\n",
            "الدولية              I-MISC     O          [31]\n",
            "للتنس                I-MISC     O          [31]\n",
            "-------------------------------------------------------------------------\n",
            "إديلاييد             B-MISC     B-MISC     [31]\n",
            "ولاس                 I-MISC     B-MISC     [31]\n",
            "فيغاس                I-MISC     I-MISC     [31]\n",
            "-------------------------------------------------------------------------\n",
            "الإيغور              B-MISC     O          [31]\n",
            "-------------------------------------------------------------------------\n",
            "لدار                 B-MISC     O          [32]\n",
            "الأوبرا              I-MISC     O          [32]\n",
            "المصرية              I-MISC     O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "ومسرح                B-MISC     O          [32]\n",
            "الجنينة              I-MISC     O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "منظر                 B-MISC     O          [32]\n",
            "للنيل                I-MISC     O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "الأولاد              B-MISC     O          [32]\n",
            "في                   I-MISC     O          [32]\n",
            "النيل                I-MISC     O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "تمثال                B-MISC     O          [32]\n",
            "سيزيف                I-MISC     B-MISC     [32]\n",
            "-------------------------------------------------------------------------\n",
            "الأطفال              B-MISC     O          [32]\n",
            "والفنانون            I-MISC     O          [32]\n",
            "وحدهم                I-MISC     O          [32]\n",
            "قادرون               I-MISC     O          [32]\n",
            "على                  I-MISC     O          [32]\n",
            "إنقاذ                I-MISC     O          [32]\n",
            "العالم               I-MISC     O          [32]\n",
            "-------------------------------------------------------------------------\n",
            "الجائزة              B-MISC     O          [33]\n",
            "الدولية              I-MISC     O          [33]\n",
            "الإيطالية            I-MISC     O          [33]\n",
            "لحوض                 I-MISC     O          [33]\n",
            "البحر                I-MISC     B-LOC      [33]\n",
            "الأبيض               I-MISC     I-LOC      [33]\n",
            "المتوسط              I-MISC     I-LOC      [33]\n",
            "-------------------------------------------------------------------------\n",
            "دولي                 B-MISC     O          [33]\n",
            "-------------------------------------------------------------------------\n",
            "دولي                 B-MISC     O          [33]\n",
            "-------------------------------------------------------------------------\n",
            "المؤتمر              B-MISC     O          [33]\n",
            "الدولي               I-MISC     O          [33]\n",
            "السادس               I-MISC     O          [33]\n",
            "عشر                  I-MISC     O          [33]\n",
            "-------------------------------------------------------------------------\n",
            "لفيروس               B-MISC     O          [33]\n",
            "اتش                  I-MISC     B-MISC     [33]\n",
            "آي                   I-MISC     I-MISC     [33]\n",
            "في                   I-MISC     I-MISC     [33]\n",
            "-------------------------------------------------------------------------\n",
            "بفيروس               B-MISC     O          [33]\n",
            "اتش                  I-MISC     B-MISC     [33]\n",
            "آي                   I-MISC     I-MISC     [33]\n",
            "في                   I-MISC     I-MISC     [33]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [36]\n",
            "العالم               I-MISC     I-MISC     [36]\n",
            "للإسكواش             I-MISC     I-MISC     [36]\n",
            "للسيدات              O          I-MISC     [36]\n",
            "-------------------------------------------------------------------------\n",
            "سنتا                 B-MISC     O          [42]\n",
            "-------------------------------------------------------------------------\n",
            "المكسيك              B-MISC     I-LOC      [42]\n",
            "-------------------------------------------------------------------------\n",
            "الكلب                B-MISC     O          [43]\n",
            "الأندلسي             I-MISC     O          [43]\n",
            "-------------------------------------------------------------------------\n",
            "L                    B-MISC     O          [43]\n",
            "'                    I-MISC     O          [43]\n",
            "Age                  I-MISC     O          [43]\n",
            "d                    I-MISC     O          [43]\n",
            "'                    I-MISC     O          [43]\n",
            "or                   I-MISC     O          [43]\n",
            "-------------------------------------------------------------------------\n",
            "الحياة               B-MISC     B-MISC     [43]\n",
            "السرية               I-MISC     I-MISC     [43]\n",
            "لسلفادور             I-MISC     B-PERS     [43]\n",
            "دالي                 I-MISC     I-PERS     [43]\n",
            "-------------------------------------------------------------------------\n",
            "ستاد                 B-MISC     O          [44]\n",
            "الحسن                I-MISC     B-LOC      [44]\n",
            "-------------------------------------------------------------------------\n",
            "ستاد                 B-MISC     O          [45]\n",
            "عمان                 I-MISC     B-LOC      [45]\n",
            "-------------------------------------------------------------------------\n",
            "ستاد                 B-MISC     O          [45]\n",
            "-------------------------------------------------------------------------\n",
            "لمهرجان              B-MISC     O          [48]\n",
            "البندقية             I-MISC     B-MISC     [48]\n",
            "-------------------------------------------------------------------------\n",
            "أنا                  B-MISC     B-MISC     [48]\n",
            "وترانه               I-MISC     B-MISC     [48]\n",
            "و15                  I-MISC     I-MISC     [48]\n",
            "سنة                  I-MISC     I-MISC     [48]\n",
            "-------------------------------------------------------------------------\n",
            "البوب                B-MISC     O          [48]\n",
            "-------------------------------------------------------------------------\n",
            "البوب                B-MISC     O          [48]\n",
            "-------------------------------------------------------------------------\n",
            "البوب                B-MISC     O          [48]\n",
            "-------------------------------------------------------------------------\n",
            "هوي                  B-MISC     B-LOC      [49]\n",
            "-------------------------------------------------------------------------\n",
            "78\n",
            "Word                 True       Pred       sentence  \n",
            "الإسلام              O          B-MISC     [2]\n",
            "-------------------------------------------------------------------------\n",
            "حرب                  O          B-MISC     [3]\n",
            "الخليج               O          I-MISC     [3]\n",
            "-------------------------------------------------------------------------\n",
            "حالة                 O          B-MISC     [3]\n",
            "النكران              O          I-MISC     [3]\n",
            "-------------------------------------------------------------------------\n",
            "بالإسلام             O          B-MISC     [5]\n",
            "-------------------------------------------------------------------------\n",
            "الإسلام              O          B-MISC     [6]\n",
            "-------------------------------------------------------------------------\n",
            "البوينغ              B-ORG      B-MISC     [8]\n",
            "-------------------------------------------------------------------------\n",
            "البوينغ              B-ORG      B-MISC     [8]\n",
            "-------------------------------------------------------------------------\n",
            "داكار                I-MISC     B-MISC     [9]\n",
            "-------------------------------------------------------------------------\n",
            "بيك                  B-MISC     B-MISC     [10]\n",
            "آب                   I-MISC     I-PERS     [10]\n",
            "نيسان                B-ORG      B-ORG      [10]\n",
            "-------------------------------------------------------------------------\n",
            "رالي                 B-MISC     B-MISC     [10]\n",
            "باريس                I-MISC     B-LOC      [10]\n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     B-MISC     [10]\n",
            "تي                   I-MISC     I-MISC     [10]\n",
            "إم                   I-MISC     I-MISC     [10]\n",
            "إل                   I-MISC     I-MISC     [10]\n",
            "سي4                  I-MISC     I-MISC     [10]\n",
            "660                  I-MISC     O          [10]\n",
            "-------------------------------------------------------------------------\n",
            "سالا                 B-PERS     B-MISC     [11]\n",
            "-------------------------------------------------------------------------\n",
            "دولار                O          B-MISC     [12]\n",
            "-------------------------------------------------------------------------\n",
            "انرون                B-ORG      B-MISC     [12]\n",
            "-------------------------------------------------------------------------\n",
            "الحرب                O          B-MISC     [14]\n",
            "العالمية             O          I-MISC     [14]\n",
            "الثانية              O          I-MISC     [14]\n",
            "-------------------------------------------------------------------------\n",
            "الأورو               O          B-MISC     [18]\n",
            "-------------------------------------------------------------------------\n",
            "ليثيوم               O          B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "باناسونيك            B-ORG      B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "لتس                  B-MISC     B-MISC     [20]\n",
            "نوت                  I-MISC     I-MISC     [20]\n",
            "CF                   I-MISC     B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "CF                   I-MISC     B-MISC     [20]\n",
            "-------------------------------------------------------------------------\n",
            "سنتا                 O          B-MISC     [23]\n",
            "-------------------------------------------------------------------------\n",
            "دولار                O          B-MISC     [23]\n",
            "-------------------------------------------------------------------------\n",
            "دولار                O          B-MISC     [23]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [25]\n",
            "التنس                I-MISC     I-MISC     [25]\n",
            "الفردي               I-MISC     I-MISC     [25]\n",
            "الدولية              I-MISC     I-MISC     [25]\n",
            "المفتوحة             I-MISC     O          [25]\n",
            "-------------------------------------------------------------------------\n",
            "ويمبلدون             I-MISC     B-MISC     [25]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [25]\n",
            "فرنسا                I-MISC     I-MISC     [25]\n",
            "المفتوحة             I-MISC     I-MISC     [25]\n",
            "للتنس                O          I-MISC     [25]\n",
            "-------------------------------------------------------------------------\n",
            "بطولات               O          B-MISC     [25]\n",
            "كأس                  O          I-MISC     [25]\n",
            "العالم               O          I-MISC     [25]\n",
            "-------------------------------------------------------------------------\n",
            "البطولة              O          B-MISC     [26]\n",
            "والكأس               O          I-MISC     [26]\n",
            "-------------------------------------------------------------------------\n",
            "داود                 B-PERS     B-MISC     [28]\n",
            "-------------------------------------------------------------------------\n",
            "بطولة                B-MISC     B-MISC     [31]\n",
            "تايلند               I-MISC     I-MISC     [31]\n",
            "الدولية              I-MISC     O          [31]\n",
            "-------------------------------------------------------------------------\n",
            "إديلاييد             B-MISC     B-MISC     [31]\n",
            "ولاس                 I-MISC     B-MISC     [31]\n",
            "-------------------------------------------------------------------------\n",
            "ولاس                 I-MISC     B-MISC     [31]\n",
            "فيغاس                I-MISC     I-MISC     [31]\n",
            "-------------------------------------------------------------------------\n",
            "بطولة                O          B-MISC     [31]\n",
            "بلاده                O          I-MISC     [31]\n",
            "-------------------------------------------------------------------------\n",
            "سيزيف                I-MISC     B-MISC     [32]\n",
            "-------------------------------------------------------------------------\n",
            "اتش                  I-MISC     B-MISC     [33]\n",
            "آي                   I-MISC     I-MISC     [33]\n",
            "في                   I-MISC     I-MISC     [33]\n",
            "-------------------------------------------------------------------------\n",
            "اتش                  I-MISC     B-MISC     [33]\n",
            "آي                   I-MISC     I-MISC     [33]\n",
            "في                   I-MISC     I-MISC     [33]\n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     B-MISC     [36]\n",
            "العالم               I-MISC     I-MISC     [36]\n",
            "للإسكواش             I-MISC     I-MISC     [36]\n",
            "للسيدات              O          I-MISC     [36]\n",
            "-------------------------------------------------------------------------\n",
            "البطولة              O          B-MISC     [36]\n",
            "-------------------------------------------------------------------------\n",
            "بطولة                O          B-MISC     [37]\n",
            "العالم               O          I-MISC     [37]\n",
            "لفرق                 O          I-MISC     [37]\n",
            "الرجال               O          I-MISC     [37]\n",
            "-------------------------------------------------------------------------\n",
            "الحرب                O          B-MISC     [38]\n",
            "الباردة              O          I-MISC     [38]\n",
            "-------------------------------------------------------------------------\n",
            "حرب                  O          B-MISC     [39]\n",
            "الخليج               B-LOC      I-MISC     [39]\n",
            "-------------------------------------------------------------------------\n",
            "harrass              O          B-MISC     [42]\n",
            "-------------------------------------------------------------------------\n",
            "دولارا               B-ORG      B-MISC     [42]\n",
            "-------------------------------------------------------------------------\n",
            "إصرار                O          B-MISC     [43]\n",
            "الذاكرة              O          I-MISC     [43]\n",
            "-------------------------------------------------------------------------\n",
            "الحياة               B-MISC     B-MISC     [43]\n",
            "السرية               I-MISC     I-MISC     [43]\n",
            "لسلفادور             I-MISC     B-PERS     [43]\n",
            "-------------------------------------------------------------------------\n",
            "الدرع                O          B-MISC     [45]\n",
            "والكأس               O          I-MISC     [45]\n",
            "-------------------------------------------------------------------------\n",
            "ذيابات               O          B-MISC     [47]\n",
            "-------------------------------------------------------------------------\n",
            "البندقية             I-MISC     B-MISC     [48]\n",
            "-------------------------------------------------------------------------\n",
            "أنا                  B-MISC     B-MISC     [48]\n",
            "وترانه               I-MISC     B-MISC     [48]\n",
            "-------------------------------------------------------------------------\n",
            "وترانه               I-MISC     B-MISC     [48]\n",
            "و15                  I-MISC     I-MISC     [48]\n",
            "سنة                  I-MISC     I-MISC     [48]\n",
            "-------------------------------------------------------------------------\n",
            "كوبلي                B-ORG      B-MISC     [50]\n",
            "بلازا                I-ORG      I-MISC     [50]\n",
            "-------------------------------------------------------------------------\n",
            "51\n",
            "TP:  [0, 0, 0, 151]\n",
            "FN:  [0, 0, 0, 78]\n",
            "FP:  [0, 0, 0, 51]\n",
            "FPC:  [0, 0, 0, 151]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_n5KwRCamPA",
        "outputId": "a338f0b1-74ca-4f4a-877f-3414d13bf155"
      },
      "source": [
        "##  Person\n",
        "\n",
        "#=== False negative=========\n",
        "count=0\n",
        "i=0\n",
        "added=[]\n",
        "window=3\n",
        "print(\"{:20} {:10} {:10} {:10} {}\".format(\"Word\", \"True\", \"Pred\",  \"sentence\", \"contetx\"))\n",
        "while(i<np.shape(pred_labels)[0]):\n",
        "  j=0\n",
        "  pred= pred_labels[i]\n",
        "  true=test_labels[i]\n",
        "  word=X_words_te[i]\n",
        "  while(j<sent_len):\n",
        "    if(j<window):\n",
        "      context=window\n",
        "    elif(j+window>=sent_len):\n",
        "      context=sent_len-3\n",
        "    else:\n",
        "      context= j\n",
        "\n",
        "    subCounter=1\n",
        "    if(pred[j] != true[j] and true[j] in ['B-PERS', 'I-PERS']) or (pred[j-1]==true[j-1] and true[j-1] in ['B-PERS', 'I-PERS'] and true[j]=='O' and pred[j] in [ 'I-PERS']):\n",
        "      while(True):\n",
        "        if(true[j] in ['B-PERS']):\n",
        "          break\n",
        "        if(true[j-subCounter] in ['B-PERS'] ):\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j-subCounter],true[j-subCounter],pred[j-subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          break\n",
        "        else:\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j-subCounter],true[j-subCounter],pred[j-subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          subCounter+=1\n",
        "\n",
        "      print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j],true[j],pred[j], i, \" \".join(word[context-window: context+window])))\n",
        "      count+=1\n",
        "      subCounter=1\n",
        "      while(True):\n",
        "        if(true[j+subCounter] in ['I-PERS']):\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j+subCounter],true[j+subCounter],pred[j+subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          subCounter+=1\n",
        "        else:\n",
        "          break\n",
        "\n",
        "      print(\"-------------------------------------------------------------------------\")\n",
        "    j+=subCounter\n",
        "  i+=1\n",
        "print(count)\n",
        "\n",
        "\n",
        "\n",
        "##  false positive\n",
        "\n",
        "count=0\n",
        "i=0\n",
        "added=[]\n",
        "window=3\n",
        "print(\"{:20} {:10} {:10} {:10} {}\".format(\"Word\", \"True\", \"Pred\",  \"sentence\", \"contetx\"))\n",
        "while(i<np.shape(pred_labels)[0]):\n",
        "  j=0\n",
        "  pred= pred_labels[i]\n",
        "  true=test_labels[i]\n",
        "  word=X_words_te[i]\n",
        "  while(j<sent_len):\n",
        "    if(j<window):\n",
        "      context=window\n",
        "    elif(j+window>=sent_len):\n",
        "      context=sent_len-3\n",
        "    else:\n",
        "      context= j\n",
        "\n",
        "    subCounter=1\n",
        "    if( true[j] =='O'and pred[j] in ['B-PERS', 'I-PERS']):\n",
        "      print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j],true[j],pred[j], i, \" \".join(word[context-window: context+window])))\n",
        "      count+=1\n",
        "\n",
        "      print(\"-------------------------------------------------------------------------\")\n",
        "    j+=subCounter\n",
        "  i+=1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word                 True       Pred       sentence   contetx\n",
            "تراب                 B-PERS     O          [1]          الاستقرار في كامل تراب البلاد ،                   \n",
            "-------------------------------------------------------------------------\n",
            "حظر                  B-PERS     O          [3]          قال فيه إن حظر مسعود البارزاني                    \n",
            "مسعود                I-PERS     B-PERS     [3]          قال فيه إن حظر مسعود البارزاني                    \n",
            "البارزاني            I-PERS     I-PERS     [3]          قال فيه إن حظر مسعود البارزاني                    \n",
            "-------------------------------------------------------------------------\n",
            "لاريجاني             B-PERS     I-PERS     [5]          خافيير سولانا وعلي لاريجاني في برلين              \n",
            "-------------------------------------------------------------------------\n",
            "البابا               B-PERS     O          [5]          موقفه من تصريحات البابا بنديكت ال                 \n",
            "بنديكت               I-PERS     B-PERS     [5]          موقفه من تصريحات البابا بنديكت ال                 \n",
            "ال                   I-PERS     O          [5]          موقفه من تصريحات البابا بنديكت ال                 \n",
            "-------------------------------------------------------------------------\n",
            "ـ                    O          O          [5]          بنديكت ال ـ 16 التي ربط                           \n",
            "ال                   I-PERS     O          [5]          بنديكت ال ـ 16 التي ربط                           \n",
            "بنديكت               I-PERS     B-PERS     [5]          بنديكت ال ـ 16 التي ربط                           \n",
            "البابا               B-PERS     O          [5]          بنديكت ال ـ 16 التي ربط                           \n",
            "16                   I-PERS     O          [5]          بنديكت ال ـ 16 التي ربط                           \n",
            "-------------------------------------------------------------------------\n",
            "الظواهري             B-PERS     B-PERS     [6]          كلمته وصف الظواهري البابا بنديكت ال               \n",
            "البابا               I-PERS     O          [6]          كلمته وصف الظواهري البابا بنديكت ال               \n",
            "بنديكت               I-PERS     B-PERS     [6]          كلمته وصف الظواهري البابا بنديكت ال               \n",
            "ال                   I-PERS     O          [6]          كلمته وصف الظواهري البابا بنديكت ال               \n",
            "-------------------------------------------------------------------------\n",
            "ـ                    O          O          [6]          بنديكت ال ـ 16 بأنه دجال                          \n",
            "ال                   I-PERS     O          [6]          بنديكت ال ـ 16 بأنه دجال                          \n",
            "بنديكت               I-PERS     B-PERS     [6]          بنديكت ال ـ 16 بأنه دجال                          \n",
            "البابا               I-PERS     O          [6]          بنديكت ال ـ 16 بأنه دجال                          \n",
            "الظواهري             B-PERS     B-PERS     [6]          بنديكت ال ـ 16 بأنه دجال                          \n",
            "16                   I-PERS     O          [6]          بنديكت ال ـ 16 بأنه دجال                          \n",
            "-------------------------------------------------------------------------\n",
            "البشير               B-PERS     I-PERS     [6]          السوداني عمر حسن البشير من أنه                    \n",
            "-------------------------------------------------------------------------\n",
            "روما                 B-PERS     I-PERS     [10]          ان الاسباني خوان روما ألهب حماس                   \n",
            "-------------------------------------------------------------------------\n",
            "ديسبري               B-PERS     I-PERS     [10]          الصدارة الفرنسي سيريل ديسبري ، بينما              \n",
            "-------------------------------------------------------------------------\n",
            "شينوزوكا             B-PERS     O          [10]          . 8 - شينوزوكا اليابان متسوبيشي                   \n",
            "-------------------------------------------------------------------------\n",
            "الهاجري              B-PERS     O          [10]          42ث . 10 الهاجري قطر متسوبيشي                     \n",
            "-------------------------------------------------------------------------\n",
            "روما                 B-PERS     B-LOC      [10]          الدراجات 1 - روما اسبانيا كي                      \n",
            "-------------------------------------------------------------------------\n",
            "سينكت                B-PERS     B-ORG      [11]          4 - سينكت فرنسا كي تي                             \n",
            "-------------------------------------------------------------------------\n",
            "كوما                 B-PERS     B-ORG      [11]          . 6 - كوما ايطاليا سوزوكي                         \n",
            "-------------------------------------------------------------------------\n",
            "سالا                 B-PERS     B-MISC     [11]          . 7 - سالا ايطاليا كي                             \n",
            "-------------------------------------------------------------------------\n",
            "كوكس                 B-PERS     B-ORG      [11]          . 8 - كوكس جنوب افريقيا                           \n",
            "-------------------------------------------------------------------------\n",
            "ميوني                B-PERS     O          [11]          . 10 - ميوني ايطاليا كي                           \n",
            "-------------------------------------------------------------------------\n",
            "وفريدل               B-PERS     I-PERS     [11]          الزوجي التشيكي راديك وفريدل 6 /                   \n",
            "-------------------------------------------------------------------------\n",
            "وبالمر               B-PERS     I-PERS     [11]          الزوجي الأميركي دونالد وبالمر علي الزوجي          \n",
            "-------------------------------------------------------------------------\n",
            "وبورتاس              B-PERS     I-PERS     [11]          الزوجي الأسباني فيسنت وبورتاس 6 /                 \n",
            "-------------------------------------------------------------------------\n",
            "وفيزنر               B-PERS     I-PERS     [11]          الزوجي التشيكي بالا وفيزنر علي الزوجي             \n",
            "-------------------------------------------------------------------------\n",
            "وجون                 B-PERS     I-PERS     [11]          علي الزوجي روبي وجون 2 /                          \n",
            "-------------------------------------------------------------------------\n",
            "وريكل                B-PERS     I-PERS     [11]          الزوجي التشيكي نوفاك وريكل مع الزوجي              \n",
            "-------------------------------------------------------------------------\n",
            "ونيبورج              B-PERS     I-PERS     [11]          الزوجي السويدي اسبيلين ونيبورج مع الزوجي          \n",
            "-------------------------------------------------------------------------\n",
            "وقاسيك               B-PERS     I-PERS     [12]          الزوجي التشيكي دام وقاسيك مع الزوجي               \n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-PERS     B-LOC      [12]          التدخل \" مع الولايات المتحدة الأميركية            \n",
            "المتحدة              I-PERS     I-LOC      [12]          التدخل \" مع الولايات المتحدة الأميركية            \n",
            "-------------------------------------------------------------------------\n",
            "بلعاوي               B-PERS     I-PERS     [12]          أمس الأول الحكم بلعاوي عضو اللجنة                 \n",
            "-------------------------------------------------------------------------\n",
            "تبليسي               B-PERS     B-LOC      [15]          انطلاقا من خرق تبليسي للاتفاقات المبرمة           \n",
            "-------------------------------------------------------------------------\n",
            "تبليسي               B-PERS     B-LOC      [16]          مشيرا إلى أن تبليسي تعمد إلى                      \n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 B-PERS     B-ORG      [16]          . والاثنين سيجري مجلس الامن عملية                 \n",
            "الامن                I-PERS     I-ORG      [16]          . والاثنين سيجري مجلس الامن عملية                 \n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 B-PERS     B-ORG      [16]          الدائمة العضوية في مجلس الامن عن                  \n",
            "الامن                I-PERS     I-ORG      [16]          الدائمة العضوية في مجلس الامن عن                  \n",
            "-------------------------------------------------------------------------\n",
            "لاريجاني             B-PERS     I-PERS     [18]          المفاوضين الإيرانيين علي لاريجاني ، الذي          \n",
            "-------------------------------------------------------------------------\n",
            "ووليامز              B-PERS     I-PERS     [22]          حل محل فينوجرادوف ووليامز على المحطة              \n",
            "-------------------------------------------------------------------------\n",
            "فولكسفاجن            B-PERS     B-ORG      [23]          في إعادة هيكلة فولكسفاجن . \"                      \n",
            "-------------------------------------------------------------------------\n",
            "المقدسي              B-PERS     O          [23]          يونيو الماضي . المقدسي يعتبر المرشد               \n",
            "-------------------------------------------------------------------------\n",
            "المجيد               I-PERS     I-PERS     [23]          منزل عبد المجيد الذنيبات المراقب العام            \n",
            "عبد                  B-PERS     B-PERS     [23]          منزل عبد المجيد الذنيبات المراقب العام            \n",
            "الذنيبات             O          I-PERS     [23]          منزل عبد المجيد الذنيبات المراقب العام            \n",
            "-------------------------------------------------------------------------\n",
            "الحسين               B-PERS     B-LOC      [24]          والسجن في مدينة الحسين الطبية نتيجة               \n",
            "-------------------------------------------------------------------------\n",
            "شاه                  B-PERS     I-PERS     [28]          في الشرطة علي شاه باكتيوال في                     \n",
            "باكتيوال             I-PERS     I-PERS     [28]          في الشرطة علي شاه باكتيوال في                     \n",
            "-------------------------------------------------------------------------\n",
            "داود                 B-PERS     B-MISC     [28]          , وربط نجمة داود بشعارات النازية                  \n",
            "-------------------------------------------------------------------------\n",
            "الساعدي              B-PERS     B-PERS     [29]          الأحد إلى الساعدي نجل الزعيم الليبي               \n",
            "نجل                  I-PERS     O          [29]          الأحد إلى الساعدي نجل الزعيم الليبي               \n",
            "-------------------------------------------------------------------------\n",
            "القذافي              B-PERS     I-PERS     [30]          التي يأمل الساعدي القذافي أن تبدأ                 \n",
            "-------------------------------------------------------------------------\n",
            "وإنديانابوليس        B-PERS     B-LOC      [31]          إديلاييد ولاس فيغاس وإنديانابوليس ، فيما          \n",
            "-------------------------------------------------------------------------\n",
            "الربيعي              B-PERS     I-PERS     [34]          الأمن الوطني موفق الربيعي . امتدح                 \n",
            "-------------------------------------------------------------------------\n",
            "البابا               B-PERS     O          [35]          السادس عشر دعا البابا العراقيين للحفاظ            \n",
            "-------------------------------------------------------------------------\n",
            "سيلفا                B-PERS     I-PERS     [35]          الجاري بين دا سيلفا والاشتراكي الديموقراطي        \n",
            "-------------------------------------------------------------------------\n",
            "سيلفا                B-PERS     I-PERS     [35]          المحكمة أن دا سيلفا \" ينقصه                       \n",
            "-------------------------------------------------------------------------\n",
            "الصباح               B-PERS     I-PERS     [37]          جابر الأحمد الجابر الصباح ضمنها تهانيه            \n",
            "-------------------------------------------------------------------------\n",
            "نوبل                 B-PERS     I-PERS     [39]          وقد أسس ألفريد نوبل السويديي الذي                 \n",
            "-------------------------------------------------------------------------\n",
            "والجراح              B-PERS     O          [40]          . وبدا عطا والجراح في هيئة                        \n",
            "-------------------------------------------------------------------------\n",
            "والجراح              B-PERS     O          [40]          ببرج التجارة العالمي والجراح أحد خاطفي            \n",
            "-------------------------------------------------------------------------\n",
            "الجراح               B-PERS     O          [40]          البريطانية إنها وصية الجراح . على                 \n",
            "-------------------------------------------------------------------------\n",
            "وايزنغر              B-PERS     I-PERS     [41]          بكل من جولي وايزنغر ( 40                          \n",
            "-------------------------------------------------------------------------\n",
            "وايزنغر              B-PERS     I-PERS     [41]          الدعوى جارته جولي وايزنغر بأنها كانت              \n",
            "-------------------------------------------------------------------------\n",
            "Salvador             B-PERS     B-PERS     [42]          ) ( Salvador Dalí ) كان                           \n",
            "Dalí                 I-PERS     O          [42]          ) ( Salvador Dalí ) كان                           \n",
            "-------------------------------------------------------------------------\n",
            "عبده                 B-PERS     O          [45]          طريق جديد ، عبده الحسين بالفوز                    \n",
            "الحسين               I-PERS     B-PERS     [45]          طريق جديد ، عبده الحسين بالفوز                    \n",
            "-------------------------------------------------------------------------\n",
            "والزبون              B-PERS     O          [45]          لاوي واصبح الرياحنة والزبون يتبادلان التقدم       \n",
            "-------------------------------------------------------------------------\n",
            "وخير                 B-PERS     O          [45]          رد عليه مكاوي وخير بفاصل من                       \n",
            "-------------------------------------------------------------------------\n",
            "الشرمان              B-PERS     O          [46]          ، حتى تمكن الشرمان من الافلات                     \n",
            "-------------------------------------------------------------------------\n",
            "للحفناوي             B-PERS     O          [46]          ومرر كرة عرضية للحفناوي المتربص داخل              \n",
            "-------------------------------------------------------------------------\n",
            "الدينمو              B-PERS     O          [46]          ، فقد نفذ الدينمو الحسنات كرة                     \n",
            "الحسنات              I-PERS     O          [46]          ، فقد نفذ الدينمو الحسنات كرة                     \n",
            "-------------------------------------------------------------------------\n",
            "ورامي                B-PERS     B-PERS     [46]          عريضة وذيابات ورامي الذين شكلوا ترسانة            \n",
            "الذين                I-PERS     O          [46]          عريضة وذيابات ورامي الذين شكلوا ترسانة            \n",
            "-------------------------------------------------------------------------\n",
            "والمصري              B-PERS     O          [46]          عقل وقصي هاشم والمصري من توفير                    \n",
            "-------------------------------------------------------------------------\n",
            "الحسنات              B-PERS     O          [47]          الذي قام فيه الحسنات قبل أن                       \n",
            "-------------------------------------------------------------------------\n",
            "ومقابلة              B-PERS     O          [47]          ورامي وضع بشار ومقابلة وسامر وماجد                \n",
            "-------------------------------------------------------------------------\n",
            "المصري               B-PERS     O          [47]          هايل من عرضية المصري فيما مرت                     \n",
            "-------------------------------------------------------------------------\n",
            "لاريجاني             B-PERS     I-PERS     [49]          النووي الإيراني علي لاريجاني الأسبوع الماضي       \n",
            "-------------------------------------------------------------------------\n",
            "رضا                  B-PERS     I-PERS     [49]          الذرية الإيرانية غلام رضا آغا زاده                \n",
            "آغا                  I-PERS     I-PERS     [49]          الذرية الإيرانية غلام رضا آغا زاده                \n",
            "-------------------------------------------------------------------------\n",
            "آغا                  I-PERS     I-PERS     [49]          غلام رضا آغا زاده وتم توقيع                       \n",
            "رضا                  B-PERS     I-PERS     [49]          غلام رضا آغا زاده وتم توقيع                       \n",
            "زاده                 O          I-PERS     [49]          غلام رضا آغا زاده وتم توقيع                       \n",
            "-------------------------------------------------------------------------\n",
            "طلال                 B-PERS     I-PERS     [50]          ثروة الوليد بن طلال وما إذا                       \n",
            "-------------------------------------------------------------------------\n",
            "طلال                 B-PERS     I-PERS     [50]          يتابع الوليد بن طلال أعماله التجارية              \n",
            "-------------------------------------------------------------------------\n",
            "وللوليد              B-PERS     O          [50]          في العالم . وللوليد ابن وابنة                     \n",
            "-------------------------------------------------------------------------\n",
            "72\n",
            "Word                 True       Pred       sentence   contetx\n",
            "وعلي                 O          B-PERS     [5]          محادثات خافيير سولانا وعلي لاريجاني في            \n",
            "-------------------------------------------------------------------------\n",
            "الهاجري              O          B-PERS     [10]          الرباط ، توقع الهاجري ان تحمل                     \n",
            "-------------------------------------------------------------------------\n",
            "بان                  O          B-PERS     [16]          غير ان تعيين بان ( 62عاما                         \n",
            "-------------------------------------------------------------------------\n",
            "بان                  O          B-PERS     [16]          وانغ غوانغيا ان بان حصل على                       \n",
            "-------------------------------------------------------------------------\n",
            "بان                  O          B-PERS     [16]          من الدبلوماسيين فان بان تقدم على                  \n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [18]          كبير المفاوضين الإيرانيين علي لاريجاني ،          \n",
            "-------------------------------------------------------------------------\n",
            "الذنيبات             O          I-PERS     [23]          منزل عبد المجيد الذنيبات المراقب العام            \n",
            "-------------------------------------------------------------------------\n",
            "الذنيبات             O          B-PERS     [24]          الإفطار على مأدبة الذنيبات إلى جانب               \n",
            "-------------------------------------------------------------------------\n",
            "الزواوي              O          B-PERS     [27]          إلا أن التزام الزواوي مع فريقه                    \n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [28]          الجنائية في الشرطة علي شاه باكتيوال               \n",
            "-------------------------------------------------------------------------\n",
            "زافي                 O          B-PERS     [30]          وإثر تمريرة من زافي هرنانديز أضاف                 \n",
            "-------------------------------------------------------------------------\n",
            "دا                   O          B-PERS     [35]          الشهر الجاري بين دا سيلفا والاشتراكي              \n",
            "-------------------------------------------------------------------------\n",
            "لولا                 O          B-PERS     [35]          من الاصوات حصل لولا على 48                        \n",
            "-------------------------------------------------------------------------\n",
            "دا                   O          B-PERS     [35]          إعلان المحكمة أن دا سيلفا \"                       \n",
            "-------------------------------------------------------------------------\n",
            "جور                  O          B-PERS     [38]          الرئاسي الديمقراطي ال جور في انتخابات             \n",
            "-------------------------------------------------------------------------\n",
            "دالي                 O          B-PERS     [43]          وبرشلونة ، استوعب دالي عددا كبيرا                 \n",
            "-------------------------------------------------------------------------\n",
            "دالي                 O          B-PERS     [43]          اللاشعوري ، بدأ دالي بإقناع الحالات               \n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [45]          لبناء هجماته بواسطة علي عقاب واحمد                \n",
            "-------------------------------------------------------------------------\n",
            "عقاب                 O          I-PERS     [45]          هجماته بواسطة علي عقاب واحمد غازي                 \n",
            "-------------------------------------------------------------------------\n",
            "قتيبة                O          B-PERS     [46]          واجه في الاولى قتيبة عرسان المرمى                 \n",
            "-------------------------------------------------------------------------\n",
            "عرسان                O          I-PERS     [46]          في الاولى قتيبة عرسان المرمى وسدد                 \n",
            "-------------------------------------------------------------------------\n",
            "شهابات               O          B-PERS     [46]          الذي جاء بامضاء شهابات حين وصلته                  \n",
            "-------------------------------------------------------------------------\n",
            "الزريقي              O          B-PERS     [47]          يستبدل بثابت ومعه الزريقي وانتشار الوريكات        \n",
            "-------------------------------------------------------------------------\n",
            "ذيابات               O          B-PERS     [47]          الأطراف والمسندين من ذيابات ورامي وضع             \n",
            "-------------------------------------------------------------------------\n",
            "ورامي                O          B-PERS     [47]          والمسندين من ذيابات ورامي وضع بشار                \n",
            "-------------------------------------------------------------------------\n",
            "رامي                 O          B-PERS     [47]          وأحدثا مع تقدم رامي ثغرة كاد                      \n",
            "-------------------------------------------------------------------------\n",
            "علي                  O          B-PERS     [49]          الملف النووي الإيراني علي لاريجاني الأسبوع        \n",
            "-------------------------------------------------------------------------\n",
            "زاده                 O          I-PERS     [49]          غلام رضا آغا زاده وتم توقيع                       \n",
            "-------------------------------------------------------------------------\n",
            "ما                   O          B-PERS     [49]          اسرة مسلمة تدعى ما من قومية                       \n",
            "-------------------------------------------------------------------------\n",
            "29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guOdGq00nQa-"
      },
      "source": [
        "# Location\n",
        "\n",
        "count=0\n",
        "i=0\n",
        "added=[]\n",
        "window=3\n",
        "print(\"{:20} {:10} {:10} {:10} {}\".format(\"Word\", \"True\", \"Pred\",  \"sentence\", \"contetx\"))\n",
        "while(i<np.shape(pred_labels)[0]):\n",
        "  j=0\n",
        "  pred= pred_labels[i]\n",
        "  true=test_labels[i]\n",
        "  word=X_words_te[i]\n",
        "  while(j<sent_len):\n",
        "    if(j<window):\n",
        "      context=window\n",
        "    elif(j+window>=sent_len):\n",
        "      context=sent_len-3\n",
        "    else:\n",
        "      context= j\n",
        "\n",
        "    subCounter=1\n",
        "    if(pred[j] != true[j] and true[j] in ['B-LOC', 'I-LOC']):\n",
        "      while(True):\n",
        "        if(true[j] in ['B-LOC']):\n",
        "          break\n",
        "        if(true[j-subCounter] in ['B-LOC'] ):\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j-subCounter],true[j-subCounter],pred[j-subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          break\n",
        "        else:\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j-subCounter],true[j-subCounter],pred[j-subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          subCounter+=1\n",
        "\n",
        "      print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j],true[j],pred[j], i, \" \".join(word[context-window: context+window])))\n",
        "      count+=1\n",
        "      subCounter=1\n",
        "      while(True):\n",
        "        if(true[j+subCounter] in ['I-LOC']):\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j+subCounter],true[j+subCounter],pred[j+subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          subCounter+=1\n",
        "        else:\n",
        "          break\n",
        "\n",
        "      print(\"-------------------------------------------------------------------------\")\n",
        "    j+=subCounter\n",
        "  i+=1\n",
        "print(count)\n",
        "\n",
        "\n",
        "##  false positive\n",
        "\n",
        "count=0\n",
        "i=0\n",
        "added=[]\n",
        "window=3\n",
        "print(\"{:20} {:10} {:10} {:10} {}\".format(\"Word\", \"True\", \"Pred\",  \"sentence\", \"contetx\"))\n",
        "while(i<np.shape(pred_labels)[0]):\n",
        "  j=0\n",
        "  pred= pred_labels[i]\n",
        "  true=test_labels[i]\n",
        "  word=X_words_te[i]\n",
        "  while(j<sent_len):\n",
        "    if(j<window):\n",
        "      context=window\n",
        "    elif(j+window>=sent_len):\n",
        "      context=sent_len-3\n",
        "    else:\n",
        "      context= j\n",
        "\n",
        "    subCounter=1\n",
        "    if( true[j] =='O'and pred[j] in ['B-LOC', 'I-LOC']):\n",
        "      print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j],true[j],pred[j], i, \" \".join(word[context-window: context+window])))\n",
        "      count+=1\n",
        "\n",
        "      print(\"-------------------------------------------------------------------------\")\n",
        "    j+=subCounter\n",
        "  i+=1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGdTww7QoFgG",
        "outputId": "d06155e8-7405-45ba-a31f-de906e935263"
      },
      "source": [
        "# Organization\n",
        "\n",
        "count=0\n",
        "i=0\n",
        "added=[]\n",
        "window=3\n",
        "print(\"{:20} {:10} {:10} {:10} {}\".format(\"Word\", \"True\", \"Pred\",  \"sentence\", \"contetx\"))\n",
        "while(i<np.shape(pred_labels)[0]):\n",
        "  j=0\n",
        "  pred= pred_labels[i]\n",
        "  true=test_labels[i]\n",
        "  word=X_words_te[i]\n",
        "  while(j<sent_len):\n",
        "    if(j<window):\n",
        "      context=window\n",
        "    elif(j+window>=sent_len):\n",
        "      context=sent_len-3\n",
        "    else:\n",
        "      context= j\n",
        "\n",
        "    subCounter=1\n",
        "    if(pred[j] != true[j] and true[j] in ['B-ORG', 'I-ORG']):\n",
        "      while(True):\n",
        "        if(true[j] in ['B-ORG']):\n",
        "          break\n",
        "        if(true[j-subCounter] in ['B-ORG'] ):\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j-subCounter],true[j-subCounter],pred[j-subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          break\n",
        "        else:\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j-subCounter],true[j-subCounter],pred[j-subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          subCounter+=1\n",
        "\n",
        "      print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j],true[j],pred[j], i, \" \".join(word[context-window: context+window])))\n",
        "      count+=1\n",
        "      subCounter=1\n",
        "      while(True):\n",
        "        if(true[j+subCounter] in ['I-ORG']):\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j+subCounter],true[j+subCounter],pred[j+subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          subCounter+=1\n",
        "        else:\n",
        "          break\n",
        "\n",
        "      print(\"-------------------------------------------------------------------------\")\n",
        "    j+=subCounter\n",
        "  i+=1\n",
        "print(count)\n",
        "\n",
        "\n",
        "##  false positive\n",
        "\n",
        "count=0\n",
        "i=0\n",
        "added=[]\n",
        "window=3\n",
        "print(\"{:20} {:10} {:10} {:10} {}\".format(\"Word\", \"True\", \"Pred\",  \"sentence\", \"contetx\"))\n",
        "while(i<np.shape(pred_labels)[0]):\n",
        "  j=0\n",
        "  pred= pred_labels[i]\n",
        "  true=test_labels[i]\n",
        "  word=X_words_te[i]\n",
        "  while(j<sent_len):\n",
        "    if(j<window):\n",
        "      context=window\n",
        "    elif(j+window>=sent_len):\n",
        "      context=sent_len-3\n",
        "    else:\n",
        "      context= j\n",
        "\n",
        "    subCounter=1\n",
        "    if( true[j] =='O'and pred[j] in ['B-ORG', 'I-ORG']):\n",
        "      print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j],true[j],pred[j], i, \" \".join(word[context-window: context+window])))\n",
        "      count+=1\n",
        "\n",
        "      print(\"-------------------------------------------------------------------------\")\n",
        "    j+=subCounter\n",
        "  i+=1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word                 True       Pred       sentence   contetx\n",
            "المتحدة              B-ORG      I-LOC      [1]          حال استندت الولايات المتحدة مثلا إلى              \n",
            "-------------------------------------------------------------------------\n",
            "الأمن                B-ORG      O          [1]          العاصمة كابول وفوضت الأمن للمجاهدين في            \n",
            "-------------------------------------------------------------------------\n",
            "دار                  B-ORG      O          [2]          صدر حديثا عن دار الهيئة المصرية                   \n",
            "الهيئة               I-ORG      O          [2]          صدر حديثا عن دار الهيئة المصرية                   \n",
            "المصرية              I-ORG      O          [2]          صدر حديثا عن دار الهيئة المصرية                   \n",
            "العامة               I-ORG      O          [2]          صدر حديثا عن دار الهيئة المصرية                   \n",
            "-------------------------------------------------------------------------\n",
            "حزب                  B-ORG      O          [2]          رفعت السعيد رئيس حزب التجمع المصري                \n",
            "التجمع               I-ORG      O          [2]          رفعت السعيد رئيس حزب التجمع المصري                \n",
            "المصري               I-ORG      O          [2]          رفعت السعيد رئيس حزب التجمع المصري                \n",
            "-------------------------------------------------------------------------\n",
            "قناة                 B-ORG      O          [2]          ماليا من شركة قناة السويس الاستعمارية             \n",
            "السويس               I-ORG      I-ORG      [2]          ماليا من شركة قناة السويس الاستعمارية             \n",
            "الاستعمارية          I-ORG      O          [2]          ماليا من شركة قناة السويس الاستعمارية             \n",
            "-------------------------------------------------------------------------\n",
            "الشرق                B-ORG      B-LOC      [2]          وفق عرض في الشرق الأوسط اللندنية                  \n",
            "الأوسط               I-ORG      I-LOC      [2]          وفق عرض في الشرق الأوسط اللندنية                  \n",
            "-------------------------------------------------------------------------\n",
            "الجماعة              B-ORG      O          [3]          خروجه من السجن الجماعة المسلمة أي                 \n",
            "المسلمة              I-ORG      O          [3]          خروجه من السجن الجماعة المسلمة أي                 \n",
            "-------------------------------------------------------------------------\n",
            "بجماعة               B-ORG      O          [3]          التي أسميت إعلاميا بجماعة التكفير والهجرة         \n",
            "التكفير              I-ORG      O          [3]          التي أسميت إعلاميا بجماعة التكفير والهجرة         \n",
            "والهجرة              I-ORG      O          [3]          التي أسميت إعلاميا بجماعة التكفير والهجرة         \n",
            "-------------------------------------------------------------------------\n",
            "جماعة                B-ORG      O          [3]          أكثر تشددا مثل جماعة الجهاد والجماعة              \n",
            "الجهاد               I-ORG      O          [3]          أكثر تشددا مثل جماعة الجهاد والجماعة              \n",
            "-------------------------------------------------------------------------\n",
            "والجماعة             B-ORG      O          [3]          مثل جماعة الجهاد والجماعة الإسلامية وما           \n",
            "الإسلامية            I-ORG      O          [3]          مثل جماعة الجهاد والجماعة الإسلامية وما           \n",
            "-------------------------------------------------------------------------\n",
            "السنة                B-ORG      B-ORG      [3]          والأخرى بين السنة والشيعة ربما بدأ                \n",
            "والشيعة              I-ORG      B-ORG      [3]          والأخرى بين السنة والشيعة ربما بدأ                \n",
            "-------------------------------------------------------------------------\n",
            "جماعة                B-ORG      O          [6]          القيادات الخطيرة من جماعة قاعدة الجهاد            \n",
            "قاعدة                I-ORG      O          [6]          القيادات الخطيرة من جماعة قاعدة الجهاد            \n",
            "-------------------------------------------------------------------------\n",
            "الجهاد               B-ORG      O          [6]          من جماعة قاعدة الجهاد , وأن                       \n",
            "-------------------------------------------------------------------------\n",
            "حركة                 B-ORG      O          [7]          في المفاوضات مع حركة المقاومة الإسلامية           \n",
            "المقاومة             I-ORG      B-ORG      [7]          في المفاوضات مع حركة المقاومة الإسلامية           \n",
            "الإسلامية            I-ORG      I-ORG      [7]          في المفاوضات مع حركة المقاومة الإسلامية           \n",
            "-------------------------------------------------------------------------\n",
            "هوائيتين             B-ORG      O          [7]          حانون على دراجتين هوائيتين عندما أطلقت            \n",
            "-------------------------------------------------------------------------\n",
            "البوينغ              B-ORG      B-MISC     [8]          الغفران . طائرة البوينغ كانت ستتوقف               \n",
            "-------------------------------------------------------------------------\n",
            "GOL                  B-ORG      O          [8]          الطائرة التابعة لشركة GOL التي كانت               \n",
            "-------------------------------------------------------------------------\n",
            "البوينغ              B-ORG      B-MISC     [8]          . أما طائرة البوينغ فانقطعت أخبارها               \n",
            "-------------------------------------------------------------------------\n",
            "رابطة                B-ORG      O          [8]          كابوتشيوني المتحدث باسم رابطة البنوك الايطالية    \n",
            "البنوك               I-ORG      O          [8]          كابوتشيوني المتحدث باسم رابطة البنوك الايطالية    \n",
            "الايطالية            I-ORG      O          [8]          كابوتشيوني المتحدث باسم رابطة البنوك الايطالية    \n",
            "-------------------------------------------------------------------------\n",
            "المركزي              I-ORG      I-ORG      [8]          في البنك المركزي الايطالي اضرابا عن               \n",
            "البنك                B-ORG      B-ORG      [8]          في البنك المركزي الايطالي اضرابا عن               \n",
            "الايطالي             I-ORG      O          [8]          في البنك المركزي الايطالي اضرابا عن               \n",
            "-------------------------------------------------------------------------\n",
            "ايطاليا              I-ORG      I-ORG      [8]          مقار بنك ايطاليا المركزي في الثاني                \n",
            "بنك                  B-ORG      B-ORG      [8]          مقار بنك ايطاليا المركزي في الثاني                \n",
            "المركزي              I-ORG      O          [8]          مقار بنك ايطاليا المركزي في الثاني                \n",
            "-------------------------------------------------------------------------\n",
            "بنك                  B-ORG      O          [9]          باريس قال محافظ بنك فرنسا المركزي                 \n",
            "فرنسا                I-ORG      B-LOC      [9]          باريس قال محافظ بنك فرنسا المركزي                 \n",
            "المركزي              I-ORG      O          [9]          باريس قال محافظ بنك فرنسا المركزي                 \n",
            "-------------------------------------------------------------------------\n",
            "مدريد                B-ORG      B-LOC      [9]          مخاطر التض . مدريد : فاز                          \n",
            "-------------------------------------------------------------------------\n",
            "حماس                 B-ORG      O          [10]          خوان روما ألهب حماس مواطنيه إذ                    \n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-PERS     [10]          - ماسوكا اليابان متسوبيشي باجيرو 40د              \n",
            "باجيرو               I-ORG      I-PERS     [10]          - ماسوكا اليابان متسوبيشي باجيرو 40د              \n",
            "-------------------------------------------------------------------------\n",
            "متسوبيشي             B-ORG      B-PERS     [10]          - شينوزوكا اليابان متسوبيشي باجيرو 41د            \n",
            "-------------------------------------------------------------------------\n",
            "شليسير               B-ORG      B-LOC      [10]          - سيرفيا اسبانيا شليسير 42د 42ث                   \n",
            "-------------------------------------------------------------------------\n",
            "اندرسون              I-ORG      I-ORG      [12]          شركة ارثر اندرسون للمحاسبة امس الاول              \n",
            "ارثر                 B-ORG      B-ORG      [12]          شركة ارثر اندرسون للمحاسبة امس الاول              \n",
            "للمحاسبة             I-ORG      O          [12]          شركة ارثر اندرسون للمحاسبة امس الاول              \n",
            "-------------------------------------------------------------------------\n",
            "اندرسون              B-ORG      B-LOC      [12]          تدمير العاملين في اندرسون لوثائق والاجراءات       \n",
            "-------------------------------------------------------------------------\n",
            "اندرسون              B-ORG      B-PERS     [12]          انرون . وباعتبار اندرسون الشركة التي              \n",
            "-------------------------------------------------------------------------\n",
            "انرون                B-ORG      B-MISC     [12]          عليها اعتماد ممارسات انرون المحاسبية التي         \n",
            "-------------------------------------------------------------------------\n",
            "الاناضول             B-ORG      B-LOC      [14]          في جنوب شرق الاناضول حيث تقيم                     \n",
            "-------------------------------------------------------------------------\n",
            "الحزب                B-ORG      O          [14]          المسلح الذي اعلنه الحزب الكردي الانفصالي          \n",
            "الكردي               I-ORG      O          [14]          المسلح الذي اعلنه الحزب الكردي الانفصالي          \n",
            "الانفصالي            I-ORG      O          [14]          المسلح الذي اعلنه الحزب الكردي الانفصالي          \n",
            "-------------------------------------------------------------------------\n",
            "الاناضول             B-ORG      B-LOC      [14]          في جنوب شرق الاناضول حيث تقيم                     \n",
            "-------------------------------------------------------------------------\n",
            "ادامنتوس             B-ORG      B-PERS     [17]          لدى المنظمة الدولية ادامنتوس فاسيلاكيس للصحافيين  \n",
            "فاسيلاكيس            I-ORG      I-PERS     [17]          لدى المنظمة الدولية ادامنتوس فاسيلاكيس للصحافيين  \n",
            "-------------------------------------------------------------------------\n",
            "للجماعة              B-ORG      O          [17]          لجماعة مسلحة تنتمي للجماعة السلفية للتبشير        \n",
            "السلفية              I-ORG      O          [17]          لجماعة مسلحة تنتمي للجماعة السلفية للتبشير        \n",
            "للتبشير              I-ORG      O          [17]          لجماعة مسلحة تنتمي للجماعة السلفية للتبشير        \n",
            "والجهاد              I-ORG      O          [17]          لجماعة مسلحة تنتمي للجماعة السلفية للتبشير        \n",
            "-------------------------------------------------------------------------\n",
            "مجموعة               B-ORG      O          [17]          المنطقة . وتواصل مجموعة السلفية للتبشير           \n",
            "السلفية              I-ORG      O          [17]          المنطقة . وتواصل مجموعة السلفية للتبشير           \n",
            "للتبشير              I-ORG      O          [17]          المنطقة . وتواصل مجموعة السلفية للتبشير           \n",
            "والجهاد              I-ORG      O          [17]          المنطقة . وتواصل مجموعة السلفية للتبشير           \n",
            "-------------------------------------------------------------------------\n",
            "الجماعة              B-ORG      O          [17]          الماضي . وأكدت الجماعة السلفية للتبشير            \n",
            "السلفية              I-ORG      O          [17]          الماضي . وأكدت الجماعة السلفية للتبشير            \n",
            "للتبشير              I-ORG      O          [17]          الماضي . وأكدت الجماعة السلفية للتبشير            \n",
            "والجهاد              I-ORG      O          [17]          الماضي . وأكدت الجماعة السلفية للتبشير            \n",
            "-------------------------------------------------------------------------\n",
            "للمعهد               B-ORG      O          [17]          . أفاد تقرير للمعهد الملكي البريطاني              \n",
            "الملكي               I-ORG      O          [17]          . أفاد تقرير للمعهد الملكي البريطاني              \n",
            "البريطاني            I-ORG      O          [17]          . أفاد تقرير للمعهد الملكي البريطاني              \n",
            "للدراسات             I-ORG      O          [17]          . أفاد تقرير للمعهد الملكي البريطاني              \n",
            "الدولية              I-ORG      O          [17]          . أفاد تقرير للمعهد الملكي البريطاني              \n",
            "-------------------------------------------------------------------------\n",
            "المتحدة              B-ORG      I-LOC      [17]          التي تقودها الولايات المتحدة عززت دور             \n",
            "-------------------------------------------------------------------------\n",
            "سان                  B-ORG      I-ORG      [17]          الحديث في جامعة سان اندرو احد                     \n",
            "اندرو                I-ORG      I-ORG      [17]          الحديث في جامعة سان اندرو احد                     \n",
            "-------------------------------------------------------------------------\n",
            "الجامعة              B-ORG      O          [19]          كيف تقيم أعمال الجامعة المغربية ؟                 \n",
            "المغربية             I-ORG      O          [19]          كيف تقيم أعمال الجامعة المغربية ؟                 \n",
            "-------------------------------------------------------------------------\n",
            "اتحاد                B-ORG      O          [19]          الاحترافية . يعكف اتحاد المجامع اللغوية           \n",
            "المجامع              I-ORG      O          [19]          الاحترافية . يعكف اتحاد المجامع اللغوية           \n",
            "اللغوية              I-ORG      O          [19]          الاحترافية . يعكف اتحاد المجامع اللغوية           \n",
            "العربية              I-ORG      O          [19]          الاحترافية . يعكف اتحاد المجامع اللغوية           \n",
            "-------------------------------------------------------------------------\n",
            "وDell                B-ORG      O          [19]          مماثل من Apple وDell إعلان IBM                    \n",
            "-------------------------------------------------------------------------\n",
            "وDell                B-ORG      O          [19]          مماثل من Apple وDell نيويورك ،                    \n",
            "-------------------------------------------------------------------------\n",
            "وLenovo              B-ORG      I-ORG      [19]          أعلنت شركتا IBM وLenovo لصناعة الكمبيوتر          \n",
            "-------------------------------------------------------------------------\n",
            "وLenovo              B-ORG      O          [19]          خلال شركتي IBM وLenovo ، حسب                      \n",
            "-------------------------------------------------------------------------\n",
            "وDell                B-ORG      O          [20]          من بينها Apple وDell ، لنفس                       \n",
            "-------------------------------------------------------------------------\n",
            "باناسونيك            B-ORG      B-MISC     [20]          الموضوعة في كمبيوترات باناسونيك المحمولة ،        \n",
            "-------------------------------------------------------------------------\n",
            "الحركة               B-ORG      O          [20]          تلقوا دعما من الحركة الطلابية الإسلامية           \n",
            "الطلابية             I-ORG      O          [20]          تلقوا دعما من الحركة الطلابية الإسلامية           \n",
            "الإسلامية            I-ORG      O          [20]          تلقوا دعما من الحركة الطلابية الإسلامية           \n",
            "-------------------------------------------------------------------------\n",
            "لوكالة               B-ORG      O          [21]          مسؤولون بوزارة الداخلية لوكالة الأنباء الهندية    \n",
            "الأنباء              I-ORG      O          [21]          مسؤولون بوزارة الداخلية لوكالة الأنباء الهندية    \n",
            "-------------------------------------------------------------------------\n",
            "الحركة               B-ORG      O          [21]          استجوبت نشطاء في الحركة الطلابية المحظورة         \n",
            "الطلابية             I-ORG      O          [21]          استجوبت نشطاء في الحركة الطلابية المحظورة         \n",
            "-------------------------------------------------------------------------\n",
            "الحركة               B-ORG      O          [21]          تقارير سابقة أن الحركة الطلابية قدمت              \n",
            "الطلابية             I-ORG      O          [21]          تقارير سابقة أن الحركة الطلابية قدمت              \n",
            "-------------------------------------------------------------------------\n",
            "للاتهامات            B-ORG      O          [21]          ، عن استغرابها للاتهامات الهندية بتورط            \n",
            "-------------------------------------------------------------------------\n",
            "ناسا                 B-ORG      I-ORG      [21]          لوكالة الفضاء الأمريكية ناسا صورا جديدة           \n",
            "-------------------------------------------------------------------------\n",
            "للحركة               B-ORG      O          [24]          أبو السكر تكريما للحركة الإسلامية ووجوه           \n",
            "الإسلامية            I-ORG      O          [24]          أبو السكر تكريما للحركة الإسلامية ووجوه           \n",
            "-------------------------------------------------------------------------\n",
            "المجلس               B-ORG      O          [24]          ، بحسب تفسير المجلس العالي للدستور                \n",
            "العالي               I-ORG      O          [24]          ، بحسب تفسير المجلس العالي للدستور                \n",
            "للدستور              I-ORG      O          [24]          ، بحسب تفسير المجلس العالي للدستور                \n",
            "-------------------------------------------------------------------------\n",
            "والملعب              B-ORG      O          [26]          تعادل مع الأفريقي والملعب التونسي وقوافل          \n",
            "التونسي              I-ORG      O          [26]          تعادل مع الأفريقي والملعب التونسي وقوافل          \n",
            "-------------------------------------------------------------------------\n",
            "حزب                  B-ORG      O          [29]          فيرنر شيرر من حزب الاتحاد الديمقراطي              \n",
            "الاتحاد              I-ORG      O          [29]          فيرنر شيرر من حزب الاتحاد الديمقراطي              \n",
            "الديمقراطي           I-ORG      O          [29]          فيرنر شيرر من حزب الاتحاد الديمقراطي              \n",
            "-------------------------------------------------------------------------\n",
            "مركز                 B-ORG      O          [29]          . أما رئيس مركز إينتسر اليهودي                    \n",
            "إينتسر               I-ORG      B-ORG      [29]          . أما رئيس مركز إينتسر اليهودي                    \n",
            "-------------------------------------------------------------------------\n",
            "بمركز                B-ORG      O          [32]          أربعة أيام متوالية بمركز الغوري للتراث            \n",
            "الغوري               I-ORG      O          [32]          أربعة أيام متوالية بمركز الغوري للتراث            \n",
            "للتراث               I-ORG      O          [32]          أربعة أيام متوالية بمركز الغوري للتراث            \n",
            "الموسيقي             I-ORG      O          [32]          أربعة أيام متوالية بمركز الغوري للتراث            \n",
            "-------------------------------------------------------------------------\n",
            "ومعهد                B-ORG      O          [32]          الغوري للتراث الموسيقي ومعهد الموسيقى العربية     \n",
            "الموسيقى             I-ORG      O          [32]          الغوري للتراث الموسيقي ومعهد الموسيقى العربية     \n",
            "العربية              I-ORG      O          [32]          الغوري للتراث الموسيقي ومعهد الموسيقى العربية     \n",
            "-------------------------------------------------------------------------\n",
            "الأزهر               B-ORG      O          [32]          ومسرح الجنينة بحديقة الأزهر . وأشار               \n",
            "-------------------------------------------------------------------------\n",
            "رويان                I-ORG      I-ORG      [33]          رئيس معهد رويان للبحوث العلمية حميد               \n",
            "معهد                 B-ORG      B-ORG      [33]          رئيس معهد رويان للبحوث العلمية حميد               \n",
            "للبحوث               I-ORG      O          [33]          رئيس معهد رويان للبحوث العلمية حميد               \n",
            "العلمية              I-ORG      O          [33]          رئيس معهد رويان للبحوث العلمية حميد               \n",
            "حميد                 I-ORG      B-PERS     [33]          رئيس معهد رويان للبحوث العلمية حميد               \n",
            "كورابى               I-ORG      I-PERS     [33]          رئيس معهد رويان للبحوث العلمية حميد               \n",
            "-------------------------------------------------------------------------\n",
            "معهد                 B-ORG      O          [33]          التي يقوم بها معهد رويان هي                       \n",
            "رويان                I-ORG      B-ORG      [33]          التي يقوم بها معهد رويان هي                       \n",
            "-------------------------------------------------------------------------\n",
            "تارسو                B-ORG      B-PERS     [35]          العلاقات بين المؤسسات تارسو جينرو صرح             \n",
            "جينرو                I-ORG      I-PERS     [35]          العلاقات بين المؤسسات تارسو جينرو صرح             \n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [36]          في النهائي على مصر التي حققت                      \n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [36]          تاريخها . وخسرت مصر نهائي البطولة                 \n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]          وكان منتخب مصر تصدر مجموعته بالدور                \n",
            "-------------------------------------------------------------------------\n",
            "فرنسا                B-ORG      B-LOC      [37]          على كل من فرنسا وإسبانيا وكندا                    \n",
            "-------------------------------------------------------------------------\n",
            "وإسبانيا             B-ORG      B-LOC      [37]          كل من فرنسا وإسبانيا وكندا ثم                     \n",
            "-------------------------------------------------------------------------\n",
            "وكندا                B-ORG      B-LOC      [37]          من فرنسا وإسبانيا وكندا ثم واصل                   \n",
            "-------------------------------------------------------------------------\n",
            "جنوب                 B-ORG      B-LOC      [37]          دور الثمانية على جنوب أفريقيا ثم                  \n",
            "أفريقيا              I-ORG      I-LOC      [37]          دور الثمانية على جنوب أفريقيا ثم                  \n",
            "-------------------------------------------------------------------------\n",
            "ماليزيا              B-ORG      B-LOC      [37]          قبل النهائي على ماليزيا ، بينما                   \n",
            "-------------------------------------------------------------------------\n",
            "إنجلترا              B-ORG      B-LOC      [37]          ، بينما فازت إنجلترا على هولندا                   \n",
            "-------------------------------------------------------------------------\n",
            "هولندا               B-ORG      B-LOC      [37]          فازت إنجلترا على هولندا . جدير                    \n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]          جدير بالذكر أن مصر احتلت المركز                   \n",
            "-------------------------------------------------------------------------\n",
            "إنجلترا              B-ORG      B-LOC      [37]          الماضي وفازت بها إنجلترا ، كما                    \n",
            "-------------------------------------------------------------------------\n",
            "مصر                  B-ORG      B-LOC      [37]          كما حقق لاعبو مصر نتائج جيدة                      \n",
            "-------------------------------------------------------------------------\n",
            "العربية              I-ORG      I-ORG      [37]          تقرير المؤسسة العربية لضمان الاستثمار حول         \n",
            "المؤسسة              B-ORG      B-ORG      [37]          تقرير المؤسسة العربية لضمان الاستثمار حول         \n",
            "لضمان                I-ORG      O          [37]          تقرير المؤسسة العربية لضمان الاستثمار حول         \n",
            "الاستثمار            I-ORG      O          [37]          تقرير المؤسسة العربية لضمان الاستثمار حول         \n",
            "-------------------------------------------------------------------------\n",
            "جورجتاون             B-ORG      I-ORG      [38]          القاها في جامعة جورجتاون في واشنطن                \n",
            "-------------------------------------------------------------------------\n",
            "البنك                B-ORG      O          [39]          نوبل بل أسسها البنك المركزي السويدي               \n",
            "المركزي              I-ORG      O          [39]          نوبل بل أسسها البنك المركزي السويدي               \n",
            "السويدي              I-ORG      O          [39]          نوبل بل أسسها البنك المركزي السويدي               \n",
            "-------------------------------------------------------------------------\n",
            "القاعدة              B-ORG      O          [40]          أن مصادر من القاعدة وأخرى أمريكية                 \n",
            "-------------------------------------------------------------------------\n",
            "القاعدة              B-ORG      O          [41]          الفيديو عن طريق القاعدة أوجهاز أمني               \n",
            "-------------------------------------------------------------------------\n",
            "الولايات             B-ORG      B-LOC      [41]          فغرمته أيوا ، الولايات المتحدة (                  \n",
            "المتحدة              I-ORG      I-LOC      [41]          فغرمته أيوا ، الولايات المتحدة (                  \n",
            "-------------------------------------------------------------------------\n",
            "نيويورك              B-ORG      B-LOC      [42]          التعاملات الالكترونية لبورصة نيويورك ، ظهرا       \n",
            "-------------------------------------------------------------------------\n",
            "دولارا               B-ORG      B-MISC     [42]          78 . 4 دولارا في 14                               \n",
            "-------------------------------------------------------------------------\n",
            "مدمر                 B-ORG      O          [42]          من موسم أعاصير مدمر في خليج                       \n",
            "-------------------------------------------------------------------------\n",
            "لؤي                  B-ORG      B-PERS     [45]          0 عمان - لؤي العبادي لم                           \n",
            "العبادي              I-ORG      I-PERS     [45]          0 عمان - لؤي العبادي لم                           \n",
            "-------------------------------------------------------------------------\n",
            "فالحسين              B-ORG      B-PERS     [45]          مرمى الفريقين ، فالحسين كان افضل                  \n",
            "-------------------------------------------------------------------------\n",
            "فالحسين              B-ORG      O          [45]          التسجيل لديهما حاضرا فالحسين كثف من               \n",
            "-------------------------------------------------------------------------\n",
            "الحسين               B-ORG      B-PERS     [45]          الفريق ، لكن الحسين لم يقف                        \n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]          العرضيات امام مرمى الاتحاد الذي انكمش             \n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]          بينية ضربت دفاع الاتحاد وتركت المهاجم             \n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]          من خروج مدافع الاتحاد بلال اللحام                 \n",
            "-------------------------------------------------------------------------\n",
            "الاتحاد              B-ORG      O          [46]          الشطناوي . ولأن الاتحاد استمر في                  \n",
            "-------------------------------------------------------------------------\n",
            "الرياحنة             B-ORG      O          [46]          رأسية على رأس الرياحنة في العمق                   \n",
            "-------------------------------------------------------------------------\n",
            "التحرير              B-ORG      O          [47]          - وخاصة حركتي التحرير الوطني (                    \n",
            "الوطني               I-ORG      O          [47]          - وخاصة حركتي التحرير الوطني (                    \n",
            "-------------------------------------------------------------------------\n",
            "والمقاومة            B-ORG      O          [47]          ( فتح ) والمقاومة الإسلامية (                     \n",
            "الإسلامية            I-ORG      O          [47]          ( فتح ) والمقاومة الإسلامية (                     \n",
            "-------------------------------------------------------------------------\n",
            "فتح                  B-ORG      O          [47]          بين مسلحين من فتح والقوة التنفيذية                \n",
            "-------------------------------------------------------------------------\n",
            "الله                 B-ORG      I-LOC      [48]          وفي مدينة رام الله بالضفة الغربية                 \n",
            "-------------------------------------------------------------------------\n",
            "الله                 B-ORG      I-LOC      [48]          . وفي رام الله أيضا اجتمع                         \n",
            "-------------------------------------------------------------------------\n",
            "طهران                B-ORG      B-LOC      [48]          الضغوط الغربية على طهران بشأن برنامجها            \n",
            "-------------------------------------------------------------------------\n",
            "هيئة                 B-ORG      O          [49]          موسكو مع رئيس هيئة الطاقة الذرية                  \n",
            "الطاقة               I-ORG      O          [49]          موسكو مع رئيس هيئة الطاقة الذرية                  \n",
            "الذرية               I-ORG      O          [49]          موسكو مع رئيس هيئة الطاقة الذرية                  \n",
            "الإيرانية            I-ORG      O          [49]          موسكو مع رئيس هيئة الطاقة الذرية                  \n",
            "-------------------------------------------------------------------------\n",
            "كوبلي                B-ORG      B-MISC     [50]          باريس و \" كوبلي بلازا \"                           \n",
            "بلازا                I-ORG      I-MISC     [50]          باريس و \" كوبلي بلازا \"                           \n",
            "-------------------------------------------------------------------------\n",
            "الشركة               B-ORG      O          [50]          الإعلام إذ أسس الشركة العربية للإنتاج             \n",
            "العربية              I-ORG      O          [50]          الإعلام إذ أسس الشركة العربية للإنتاج             \n",
            "للإنتاج              I-ORG      O          [50]          الإعلام إذ أسس الشركة العربية للإنتاج             \n",
            "الإعلامي             I-ORG      O          [50]          الإعلام إذ أسس الشركة العربية للإنتاج             \n",
            "-------------------------------------------------------------------------\n",
            "شركة                 B-ORG      O          [50]          تحت اسم \" شركة المملكة القابضة                    \n",
            "المملكة              I-ORG      B-ORG      [50]          تحت اسم \" شركة المملكة القابضة                    \n",
            "القابضة              I-ORG      I-ORG      [50]          تحت اسم \" شركة المملكة القابضة                    \n",
            "-------------------------------------------------------------------------\n",
            "107\n",
            "Word                 True       Pred       sentence   contetx\n",
            "ونايفة               O          B-ORG      [0]          الصالحية ونايفة المفرق - غيث الطراونة             \n",
            "-------------------------------------------------------------------------\n",
            "الإخوان              O          B-ORG      [2]          مقولات وأقاويل جماعة الإخوان المسلمين ،           \n",
            "-------------------------------------------------------------------------\n",
            "المسلمين             O          I-ORG      [2]          وأقاويل جماعة الإخوان المسلمين ، فتارة            \n",
            "-------------------------------------------------------------------------\n",
            "الأكراد              O          B-ORG      [3]          بدءا بالتصعيد بين الأكراد والعرب وانتهاء          \n",
            "-------------------------------------------------------------------------\n",
            "وسنة                 O          B-ORG      [3]          إحداهما بين الأميركيين وسنة العراق والأخرى        \n",
            "-------------------------------------------------------------------------\n",
            "والأكراد             O          B-ORG      [3]          ثالثة بين العرب والأكراد في المناطق               \n",
            "-------------------------------------------------------------------------\n",
            "بمنظمة               O          B-ORG      [5]          التراث الإنساني الخاصة بمنظمة الأمم المتحدة       \n",
            "-------------------------------------------------------------------------\n",
            "للتربية              O          I-ORG      [5]          بمنظمة الأمم المتحدة للتربية والعلوم والثقافة     \n",
            "-------------------------------------------------------------------------\n",
            "والعلوم              O          I-ORG      [5]          الأمم المتحدة للتربية والعلوم والثقافة (          \n",
            "-------------------------------------------------------------------------\n",
            "والثقافة             O          I-ORG      [5]          المتحدة للتربية والعلوم والثقافة ( يونيسكو        \n",
            "-------------------------------------------------------------------------\n",
            "حماس                 O          B-ORG      [7]          كافة بما فيها حماس والسلطة لديها                  \n",
            "-------------------------------------------------------------------------\n",
            "بحماس                O          B-ORG      [7]          ذلك قال القيادي بحماس إسماعيل رضوان               \n",
            "-------------------------------------------------------------------------\n",
            "للراليات             O          I-ORG      [10]          سيارة فريق قطر للراليات متسوبيشي ال               \n",
            "-------------------------------------------------------------------------\n",
            "من                   O          B-ORG      [14]          باسم \" الحزب من اجل مجتمع                         \n",
            "-------------------------------------------------------------------------\n",
            "اجل                  O          I-ORG      [14]          \" الحزب من اجل مجتمع ديمقراطي                     \n",
            "-------------------------------------------------------------------------\n",
            "مجتمع                O          I-ORG      [14]          الحزب من اجل مجتمع ديمقراطي \"                     \n",
            "-------------------------------------------------------------------------\n",
            "ديمقراطي             O          I-ORG      [14]          من اجل مجتمع ديمقراطي \" لوكالة                    \n",
            "-------------------------------------------------------------------------\n",
            "الاكراد              O          B-ORG      [14]          لدعمه المفترض للمتمردين الاكراد \" اذا             \n",
            "-------------------------------------------------------------------------\n",
            "مجلس                 O          B-ORG      [16]          على توصية من مجلس الامن وفي                       \n",
            "-------------------------------------------------------------------------\n",
            "الامن                O          I-ORG      [16]          توصية من مجلس الامن وفي الواقع                    \n",
            "-------------------------------------------------------------------------\n",
            "جامعة                O          B-ORG      [17]          التاريخ الحديث في جامعة سان اندرو                 \n",
            "-------------------------------------------------------------------------\n",
            "الوكالة              O          B-ORG      [18]          المحافظة على دور الوكالة الدولية للطاقة           \n",
            "-------------------------------------------------------------------------\n",
            "الدولية              O          I-ORG      [18]          على دور الوكالة الدولية للطاقة الذرية             \n",
            "-------------------------------------------------------------------------\n",
            "للطاقة               O          I-ORG      [18]          دور الوكالة الدولية للطاقة الذرية والحيلولة       \n",
            "-------------------------------------------------------------------------\n",
            "الذرية               O          I-ORG      [18]          الوكالة الدولية للطاقة الذرية والحيلولة دون       \n",
            "-------------------------------------------------------------------------\n",
            "العسكر               O          B-ORG      [21]          التفجيرات بمساعدة حركة العسكر الطيبة .            \n",
            "-------------------------------------------------------------------------\n",
            "الطيبة               O          I-ORG      [21]          بمساعدة حركة العسكر الطيبة . وذكرت                \n",
            "-------------------------------------------------------------------------\n",
            "لوكالة               O          B-ORG      [21]          أوبورتشينيتي \" التابعة لوكالة الفضاء الأمريكية    \n",
            "-------------------------------------------------------------------------\n",
            "الفضاء               O          I-ORG      [21]          \" التابعة لوكالة الفضاء الأمريكية ناسا            \n",
            "-------------------------------------------------------------------------\n",
            "الأمريكية            O          I-ORG      [21]          التابعة لوكالة الفضاء الأمريكية ناسا صورا         \n",
            "-------------------------------------------------------------------------\n",
            "الرياضي              O          I-ORG      [26]          مجلس إدارة الترجي الرياضي التونسي مدرب            \n",
            "-------------------------------------------------------------------------\n",
            "النجم                O          B-ORG      [26]          من غريمه المحلي النجم الساحلي .                   \n",
            "-------------------------------------------------------------------------\n",
            "الساحلي              O          I-ORG      [26]          غريمه المحلي النجم الساحلي . ورغم                 \n",
            "-------------------------------------------------------------------------\n",
            "سني                  O          B-ORG      [34]          عبد المهدي والأخر سني وهو طارق                    \n",
            "-------------------------------------------------------------------------\n",
            "الريال               O          B-ORG      [36]          أن حارس مرمى الريال كاسياس تدخل                   \n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [44]          ، اخرج فيها الصريح - احد                          \n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [44]          شغب من جماهير الصريح احتواه رجال                  \n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [45]          له صدها حارس البقعة ، مواصلا                      \n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [45]          والكأس ، واكد البقعة تجذر الأصرار                 \n",
            "-------------------------------------------------------------------------\n",
            "الشباب               O          B-ORG      [45]          ابو عرقوب لاعب الشباب البطاقة الحمراء             \n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]          علي غرايبة طبق الصريح منذ البداية                 \n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]          . كان قبلها الصريح يعتمد على                      \n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]          الحفناوي . تخلى الصريح مع بداية                   \n",
            "-------------------------------------------------------------------------\n",
            "الصريح               O          B-ORG      [46]          في دفاعه واصل الصريح اندفاعه وهو                  \n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [46]          سرعة من قبل البقعة الذي كشف                       \n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [46]          عددية على دفاع البقعة وأضحت تمريراتهم             \n",
            "-------------------------------------------------------------------------\n",
            "البقعة               O          B-ORG      [47]          مقابله على ميمنة البقعة كان يحتاج                 \n",
            "-------------------------------------------------------------------------\n",
            "فتح                  O          B-ORG      [47]          مسيرة نظمها مؤيدو فتح للتنديد بالاقتتال           \n",
            "-------------------------------------------------------------------------\n",
            "لمجلس                O          B-ORG      [49]          يجري الأمين العام لمجلس الأمن القومي              \n",
            "-------------------------------------------------------------------------\n",
            "الأمن                O          I-ORG      [49]          الأمين العام لمجلس الأمن القومي الروسي            \n",
            "-------------------------------------------------------------------------\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH_wNg287Ckv"
      },
      "source": [
        "Word                 True       Pred       sentence   contetx\n",
        "ونايفة               O          B-ORG      [0]          الصالحية ونايفة المفرق - غيث الطراونة            fail \n",
        "-------------------------------------------------------------------------\n",
        "الإخوان              O          B-ORG      [2]          مقولات وأقاويل جماعة الإخوان المسلمين ،           wrong\n",
        "-------------------------------------------------------------------------\n",
        "المسلمين             O          I-ORG      [2]          وأقاويل جماعة الإخوان المسلمين ، فتارة            \n",
        "-------------------------------------------------------------------------\n",
        "الأكراد              O          B-ORG      [3]          بدءا بالتصعيد بين الأكراد والعرب وانتهاء          fail\n",
        "-------------------------------------------------------------------------\n",
        "وسنة                 O          B-ORG      [3]          إحداهما بين الأميركيين وسنة العراق والأخرى        fail\n",
        "-------------------------------------------------------------------------\n",
        "والأكراد             O          B-ORG      [3]          ثالثة بين العرب والأكراد في المناطق               fail\n",
        "-------------------------------------------------------------------------\n",
        "بمنظمة               O          B-ORG      [5]          التراث الإنساني الخاصة بمنظمة الأمم المتحدة       wrong\n",
        "-------------------------------------------------------------------------\n",
        "للتربية              O          I-ORG      [5]          بمنظمة الأمم المتحدة للتربية والعلوم والثقافة     \n",
        "-------------------------------------------------------------------------\n",
        "والعلوم              O          I-ORG      [5]          الأمم المتحدة للتربية والعلوم والثقافة (          \n",
        "-------------------------------------------------------------------------\n",
        "والثقافة             O          I-ORG      [5]          المتحدة للتربية والعلوم والثقافة ( يونيسكو        \n",
        "-------------------------------------------------------------------------\n",
        "حماس                 O          B-ORG      [7]          كافة بما فيها حماس والسلطة لديها            wrong      \n",
        "-------------------------------------------------------------------------\n",
        "بحماس                O          B-ORG      [7]          ذلك قال القيادي بحماس إسماعيل رضوان              wrong \n",
        "-------------------------------------------------------------------------\n",
        "للراليات             O          I-ORG      [10]          سيارة فريق قطر للراليات متسوبيشي ال               convention\n",
        "-------------------------------------------------------------------------\n",
        "من                   O          B-ORG      [14]          باسم \" الحزب من اجل مجتمع            wrong             \n",
        "-------------------------------------------------------------------------\n",
        "اجل                  O          I-ORG      [14]          \" الحزب من اجل مجتمع ديمقراطي                     \n",
        "-------------------------------------------------------------------------\n",
        "مجتمع                O          I-ORG      [14]          الحزب من اجل مجتمع ديمقراطي \"                     \n",
        "-------------------------------------------------------------------------\n",
        "ديمقراطي             O          I-ORG      [14]          من اجل مجتمع ديمقراطي \" لوكالة                    \n",
        "-------------------------------------------------------------------------\n",
        "الاكراد              O          B-ORG      [14]          لدعمه المفترض للمتمردين الاكراد \" اذا     fail        \n",
        "-------------------------------------------------------------------------\n",
        "مجلس                 O          B-ORG      [16]          على توصية من مجلس الامن وفي                   wrong    \n",
        "-------------------------------------------------------------------------\n",
        "الامن                O          I-ORG      [16]          توصية من مجلس الامن وفي الواقع                    wrong\n",
        "-------------------------------------------------------------------------\n",
        "جامعة                O          B-ORG      [17]          التاريخ الحديث في جامعة سان اندرو                 \n",
        "-------------------------------------------------------------------------\n",
        "الوكالة              O          B-ORG      [18]          المحافظة على دور الوكالة الدولية للطاقة    wrong       \n",
        "-------------------------------------------------------------------------\n",
        "الدولية              O          I-ORG      [18]          على دور الوكالة الدولية للطاقة الذرية             \n",
        "-------------------------------------------------------------------------\n",
        "للطاقة               O          I-ORG      [18]          دور الوكالة الدولية للطاقة الذرية والحيلولة       \n",
        "-------------------------------------------------------------------------\n",
        "الذرية               O          I-ORG      [18]          الوكالة الدولية للطاقة الذرية والحيلولة دون       \n",
        "-------------------------------------------------------------------------\n",
        "العسكر               O          B-ORG      [21]          التفجيرات بمساعدة حركة العسكر الطيبة .          wrong  \n",
        "-------------------------------------------------------------------------\n",
        "الطيبة               O          I-ORG      [21]          بمساعدة حركة العسكر الطيبة . وذكرت               \n",
        "-------------------------------------------------------------------------\n",
        "لوكالة               O          B-ORG      [21]          أوبورتشينيتي \" التابعة لوكالة الفضاء الأمريكية   wrong \n",
        "-------------------------------------------------------------------------\n",
        "الفضاء               O          I-ORG      [21]          \" التابعة لوكالة الفضاء الأمريكية ناسا            \n",
        "-------------------------------------------------------------------------\n",
        "الأمريكية            O          I-ORG      [21]          التابعة لوكالة الفضاء الأمريكية ناسا صورا         \n",
        "-------------------------------------------------------------------------\n",
        "الرياضي              O          I-ORG      [26]          مجلس إدارة الترجي الرياضي التونسي مدرب            fail\n",
        "-------------------------------------------------------------------------\n",
        "النجم                O          B-ORG      [26]          من غريمه المحلي النجم الساحلي .                   wrong\n",
        "-------------------------------------------------------------------------\n",
        "الساحلي              O          I-ORG      [26]          غريمه المحلي النجم الساحلي . ورغم                 \n",
        "-------------------------------------------------------------------------\n",
        "سني                  O          B-ORG      [34]          عبد المهدي والأخر سني وهو طارق     fail               \n",
        "-------------------------------------------------------------------------\n",
        "الريال               O          B-ORG      [36]          أن حارس مرمى الريال كاسياس تدخل        wrong           \n",
        "-------------------------------------------------------------------------\n",
        "الصريح               O          B-ORG      [44]          ، اخرج فيها الصريح - احد                    wrong      \n",
        "-------------------------------------------------------------------------\n",
        "الصريح               O          B-ORG      [44]          شغب من جماهير الصريح احتواه رجال                 wrong \n",
        "-------------------------------------------------------------------------\n",
        "البقعة               O          B-ORG      [45]          له صدها حارس البقعة ، مواصلا                      wrong\n",
        "-------------------------------------------------------------------------\n",
        "البقعة               O          B-ORG      [45]          والكأس ، واكد البقعة تجذر الأصرار                 wrong\n",
        "-------------------------------------------------------------------------\n",
        "الشباب               O          B-ORG      [45]          ابو عرقوب لاعب الشباب البطاقة الحمراء             wrong\n",
        "-------------------------------------------------------------------------\n",
        "الصريح               O          B-ORG      [46]          علي غرايبة طبق الصريح منذ البداية                 wrong\n",
        "-------------------------------------------------------------------------\n",
        "الصريح               O          B-ORG      [46]          . كان قبلها الصريح يعتمد على                      wrong\n",
        "-------------------------------------------------------------------------\n",
        "الصريح               O          B-ORG      [46]          الحفناوي . تخلى الصريح مع بداية                   wrong\n",
        "-------------------------------------------------------------------------\n",
        "الصريح               O          B-ORG      [46]          في دفاعه واصل الصريح اندفاعه وهو                  wrong\n",
        "-------------------------------------------------------------------------\n",
        "البقعة               O          B-ORG      [46]          سرعة من قبل البقعة الذي كشف                       wrong\n",
        "-------------------------------------------------------------------------\n",
        "البقعة               O          B-ORG      [46]          عددية على دفاع البقعة وأضحت تمريراتهم             wrong\n",
        "-------------------------------------------------------------------------\n",
        "البقعة               O          B-ORG      [47]          مقابله على ميمنة البقعة كان يحتاج                 wrong\n",
        "-------------------------------------------------------------------------\n",
        "فتح                  O          B-ORG      [47]          مسيرة نظمها مؤيدو فتح للتنديد بالاقتتال           wrong\n",
        "-------------------------------------------------------------------------\n",
        "لمجلس                O          B-ORG      [49]          يجري الأمين العام لمجلس الأمن القومي              wrong\n",
        "-------------------------------------------------------------------------\n",
        "الأمن                O          I-ORG      [49]          الأمين العام لمجلس الأمن القومي الروسي            \n",
        "-------------------------------------------------------------------------\n",
        "50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9CNGlPRoFi-",
        "outputId": "7147057a-0e62-41f4-da05-09e4141aa034"
      },
      "source": [
        "# Miscellaneous\n",
        "\n",
        "count=0\n",
        "i=0\n",
        "added=[]\n",
        "window=3\n",
        "print(\"{:20} {:10} {:10} {:10} {}\".format(\"Word\", \"True\", \"Pred\",  \"sentence\", \"contetx\"))\n",
        "while(i<np.shape(pred_labels)[0]):\n",
        "  j=0\n",
        "  pred= pred_labels[i]\n",
        "  true=test_labels[i]\n",
        "  word=X_words_te[i]\n",
        "  while(j<sent_len):\n",
        "    if(j<window):\n",
        "      context=window\n",
        "    elif(j+window>=sent_len):\n",
        "      context=sent_len-3\n",
        "    else:\n",
        "      context= j\n",
        "    subCounter=1\n",
        "    if(pred[j] != true[j] and true[j] in ['B-MISC', 'I-MISC']):\n",
        "      while(True):\n",
        "        if(true[j] in ['B-MISC']):\n",
        "          break\n",
        "        if(true[j-subCounter] in ['B-MISC'] ):\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j-subCounter],true[j-subCounter],pred[j-subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          break\n",
        "        else:\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j-subCounter],true[j-subCounter],pred[j-subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          subCounter+=1\n",
        "\n",
        "      print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j],true[j],pred[j], i, \" \".join(word[context-window: context+window])))\n",
        "      count+=1\n",
        "      subCounter=1\n",
        "      while(True):\n",
        "        if(true[j+subCounter] in ['I-MISC']):\n",
        "          print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j+subCounter],true[j+subCounter],pred[j+subCounter], i, \" \".join(word[context-window: context+window])))\n",
        "          subCounter+=1\n",
        "        else:\n",
        "          break\n",
        "\n",
        "      print(\"-------------------------------------------------------------------------\")\n",
        "    j+=subCounter\n",
        "  i+=1\n",
        "print(count)\n",
        "\n",
        "\n",
        "##  false positive\n",
        "\n",
        "count=0\n",
        "i=0\n",
        "added=[]\n",
        "window=3\n",
        "print(\"{:20} {:10} {:10} {:10} {}\".format(\"Word\", \"True\", \"Pred\",  \"sentence\", \"contetx\"))\n",
        "while(i<np.shape(pred_labels)[0]):\n",
        "  j=0\n",
        "  pred= pred_labels[i]\n",
        "  true=test_labels[i]\n",
        "  word=X_words_te[i]\n",
        "  while(j<sent_len):\n",
        "    if(j<window):\n",
        "      context=window\n",
        "    elif(j+window>=sent_len):\n",
        "      context=sent_len-3\n",
        "    else:\n",
        "      context= j\n",
        "\n",
        "    subCounter=1\n",
        "    if( true[j] =='O'and pred[j] in ['B-MISC', 'I-MISC']):\n",
        "      print(\"{:20} {:10} {:10} [{}]          {:50}\".format(word[j],true[j],pred[j], i, \" \".join(word[context-window: context+window])))\n",
        "      count+=1\n",
        "\n",
        "      print(\"-------------------------------------------------------------------------\")\n",
        "    j+=subCounter\n",
        "  i+=1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word                 True       Pred       sentence   contetx\n",
            "التأسلم              B-MISC     O          [2]          العامة كتاب \" التأسلم السياسي .                   \n",
            "السياسي              I-MISC     O          [2]          العامة كتاب \" التأسلم السياسي .                   \n",
            "-------------------------------------------------------------------------\n",
            ".                    O          O          [2]          السياسي . . جماعة الإخوان المسلمين                \n",
            ".                    O          O          [2]          السياسي . . جماعة الإخوان المسلمين                \n",
            "السياسي              I-MISC     O          [2]          السياسي . . جماعة الإخوان المسلمين                \n",
            "التأسلم              B-MISC     O          [2]          السياسي . . جماعة الإخوان المسلمين                \n",
            "جماعة                I-MISC     O          [2]          السياسي . . جماعة الإخوان المسلمين                \n",
            "الإخوان              I-MISC     B-ORG      [2]          السياسي . . جماعة الإخوان المسلمين                \n",
            "المسلمين             I-MISC     I-ORG      [2]          السياسي . . جماعة الإخوان المسلمين                \n",
            "نموذجا               I-MISC     O          [2]          السياسي . . جماعة الإخوان المسلمين                \n",
            "-------------------------------------------------------------------------\n",
            "الخلفاء              B-MISC     O          [2]          في نهاية عهد الخلفاء الراشدين واستمرت             \n",
            "-------------------------------------------------------------------------\n",
            "الراشدين             B-MISC     O          [2]          نهاية عهد الخلفاء الراشدين واستمرت خلال           \n",
            "-------------------------------------------------------------------------\n",
            "الدولة               B-MISC     B-ORG      [2]          الراشدين واستمرت خلال الدولة الأموية ثم           \n",
            "الأموية              I-MISC     I-ORG      [2]          الراشدين واستمرت خلال الدولة الأموية ثم           \n",
            "-------------------------------------------------------------------------\n",
            "العباسية             B-MISC     O          [2]          الدولة الأموية ثم العباسية وتمادت إلى             \n",
            "-------------------------------------------------------------------------\n",
            "بوصوله               B-MISC     O          [5]          وينبئ مسار الإعصار بوصوله إلى مقاطعة              \n",
            "-------------------------------------------------------------------------\n",
            "المسيحية             B-MISC     O          [6]          الاحترام \" بين المسيحية والإسلام .                \n",
            "-------------------------------------------------------------------------\n",
            "مانوس                B-MISC     B-LOC      [8]          اليوم من مطار مانوس شمالي البرازيل                \n",
            "-------------------------------------------------------------------------\n",
            "مانوس                B-MISC     B-LOC      [8]          تحطمت . وفي مانوس أكد مصدر                        \n",
            "-------------------------------------------------------------------------\n",
            "الليرة               B-MISC     O          [8]          ان الايطاليين ودعوا الليرة قبل طرح                \n",
            "-------------------------------------------------------------------------\n",
            "بالليرة              B-MISC     O          [8]          عن استبدال اليورو بالليرة في مقار                 \n",
            "-------------------------------------------------------------------------\n",
            "ماراثون              B-MISC     O          [9]          الأوروبية الأخيرة من ماراثون باريس -              \n",
            "باريس                I-MISC     B-LOC      [9]          الأوروبية الأخيرة من ماراثون باريس -              \n",
            "-------------------------------------------------------------------------\n",
            "-                    O          O          [9]          ماراثون باريس - داكار التي اقيمت                  \n",
            "باريس                I-MISC     B-LOC      [9]          ماراثون باريس - داكار التي اقيمت                  \n",
            "ماراثون              B-MISC     O          [9]          ماراثون باريس - داكار التي اقيمت                  \n",
            "داكار                I-MISC     B-MISC     [9]          ماراثون باريس - داكار التي اقيمت                  \n",
            "-------------------------------------------------------------------------\n",
            "بيك                  B-MISC     B-MISC     [10]          علي متن بيك آب نيسان البقاء                       \n",
            "آب                   I-MISC     I-PERS     [10]          علي متن بيك آب نيسان البقاء                       \n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-ORG      [10]          في سيارتها متسوبيشي باجيرو . من                   \n",
            "-------------------------------------------------------------------------\n",
            "الرالي               B-MISC     O          [10]          ممثل العرب في الرالي القطري سعيد                  \n",
            "القطري               I-MISC     O          [10]          ممثل العرب في الرالي القطري سعيد                  \n",
            "-------------------------------------------------------------------------\n",
            "ال                   B-MISC     O          [10]          قطر للراليات متسوبيشي ال ، 200                    \n",
            "-------------------------------------------------------------------------\n",
            "،                    O          O          [10]          متسوبيشي ال ، 200 وهو سيكون                       \n",
            "ال                   B-MISC     O          [10]          متسوبيشي ال ، 200 وهو سيكون                       \n",
            "200                  I-MISC     O          [10]          متسوبيشي ال ، 200 وهو سيكون                       \n",
            "-------------------------------------------------------------------------\n",
            "رالي                 B-MISC     B-MISC     [10]          الأوروبي من رالي باريس - داكار                    \n",
            "باريس                I-MISC     B-LOC      [10]          الأوروبي من رالي باريس - داكار                    \n",
            "-------------------------------------------------------------------------\n",
            "-                    O          O          [10]          رالي باريس - داكار ضمن العشرة                     \n",
            "باريس                I-MISC     B-LOC      [10]          رالي باريس - داكار ضمن العشرة                     \n",
            "رالي                 B-MISC     B-MISC     [10]          رالي باريس - داكار ضمن العشرة                     \n",
            "داكار                I-MISC     B-LOC      [10]          رالي باريس - داكار ضمن العشرة                     \n",
            "-------------------------------------------------------------------------\n",
            "سي4                  I-MISC     I-MISC     [10]          إم إل سي4 660 . وسوف                              \n",
            "إل                   I-MISC     I-MISC     [10]          إم إل سي4 660 . وسوف                              \n",
            "إم                   I-MISC     I-MISC     [10]          إم إل سي4 660 . وسوف                              \n",
            "تي                   I-MISC     I-MISC     [10]          إم إل سي4 660 . وسوف                              \n",
            "كي                   B-MISC     B-MISC     [10]          إم إل سي4 660 . وسوف                              \n",
            "660                  I-MISC     O          [10]          إم إل سي4 660 . وسوف                              \n",
            "-------------------------------------------------------------------------\n",
            "للرالي               B-MISC     O          [10]          وهنا الترتيب العام للرالي : السيارات              \n",
            "-------------------------------------------------------------------------\n",
            "بيك                  B-MISC     I-ORG      [10]          ميفيوس بلجيكا نيسان بيك آب 39                     \n",
            "آب                   I-MISC     I-ORG      [10]          ميفيوس بلجيكا نيسان بيك آب 39                     \n",
            "-------------------------------------------------------------------------\n",
            "بيك                  B-MISC     I-ORG      [10]          هانسل فرنسا نيسان بيك آب 40د                      \n",
            "آب                   I-MISC     I-ORG      [10]          هانسل فرنسا نيسان بيك آب 40د                      \n",
            "-------------------------------------------------------------------------\n",
            "ال                   B-MISC     O          [10]          سوسا اسبانيا متسوبيشي ال ، 200                    \n",
            "-------------------------------------------------------------------------\n",
            "،                    O          O          [10]          متسوبيشي ال ، 200 40د 41ث                         \n",
            "ال                   B-MISC     O          [10]          متسوبيشي ال ، 200 40د 41ث                         \n",
            "200                  I-MISC     O          [10]          متسوبيشي ال ، 200 40د 41ث                         \n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-PERS     [10]          شميت المانيا متسوبيشي باجيرو 40د 59ث              \n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-PERS     [10]          فونتيناي فرنسا متسوبيشي باجيرو 40د 58ث            \n",
            "-------------------------------------------------------------------------\n",
            "باجيرو               B-MISC     I-PERS     [10]          شينوزوكا اليابان متسوبيشي باجيرو 41د 32ث          \n",
            "-------------------------------------------------------------------------\n",
            "ال                   B-MISC     O          [10]          الهاجري قطر متسوبيشي ال ، 200                     \n",
            "-------------------------------------------------------------------------\n",
            "200                  B-MISC     O          [10]          متسوبيشي ال ، 200 43د 16ث                         \n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [10]          - روما اسبانيا كي تي إم                           \n",
            "تي                   I-MISC     I-MISC     [10]          - روما اسبانيا كي تي إم                           \n",
            "إم                   I-MISC     I-MISC     [10]          - روما اسبانيا كي تي إم                           \n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [10]          - ديسبري فرنسا كي تي إم                           \n",
            "تي                   I-MISC     O          [10]          - ديسبري فرنسا كي تي إم                           \n",
            "إم                   I-MISC     O          [10]          - ديسبري فرنسا كي تي إم                           \n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [10]          - تيانين فنلندا كي تي إم                          \n",
            "تي                   I-MISC     O          [10]          - تيانين فنلندا كي تي إم                          \n",
            "إم                   I-MISC     O          [10]          - تيانين فنلندا كي تي إم                          \n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]          - سينكت فرنسا كي تي إم                            \n",
            "تي                   I-MISC     O          [11]          - سينكت فرنسا كي تي إم                            \n",
            "إم                   I-MISC     O          [11]          - سينكت فرنسا كي تي إم                            \n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]          استيف بوجول اسبانيا كي تي إم                      \n",
            "تي                   I-MISC     O          [11]          استيف بوجول اسبانيا كي تي إم                      \n",
            "إم                   I-MISC     O          [11]          استيف بوجول اسبانيا كي تي إم                      \n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]          - سالا ايطاليا كي تي إم                           \n",
            "تي                   I-MISC     O          [11]          - سالا ايطاليا كي تي إم                           \n",
            "إم                   I-MISC     O          [11]          - سالا ايطاليا كي تي إم                           \n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]          كوكس جنوب افريقيا كي تم إم                        \n",
            "تم                   I-MISC     O          [11]          كوكس جنوب افريقيا كي تم إم                        \n",
            "إم                   I-MISC     O          [11]          كوكس جنوب افريقيا كي تم إم                        \n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]          - فيرهوف هولندا كي تم إم                          \n",
            "تم                   I-MISC     O          [11]          - فيرهوف هولندا كي تم إم                          \n",
            "إم                   I-MISC     O          [11]          - فيرهوف هولندا كي تم إم                          \n",
            "-------------------------------------------------------------------------\n",
            "كي                   B-MISC     O          [11]          - ميوني ايطاليا كي تم إم                          \n",
            "تم                   I-MISC     O          [11]          - ميوني ايطاليا كي تم إم                          \n",
            "إم                   I-MISC     O          [11]          - ميوني ايطاليا كي تم إم                          \n",
            "-------------------------------------------------------------------------\n",
            "ياسوكوني             B-MISC     B-LOC      [15]          كويزومي الى مزار ياسوكوني الوطني في               \n",
            "-------------------------------------------------------------------------\n",
            "معجم                 B-MISC     O          [19]          على وضع \" معجم تاريخي للغة                        \n",
            "تاريخي               I-MISC     O          [19]          على وضع \" معجم تاريخي للغة                        \n",
            "للغة                 I-MISC     O          [19]          على وضع \" معجم تاريخي للغة                        \n",
            "العربية              I-MISC     O          [19]          على وضع \" معجم تاريخي للغة                        \n",
            "-------------------------------------------------------------------------\n",
            "نوت                  I-MISC     I-MISC     [20]          \" لتس نوت CF - w4g                                \n",
            "لتس                  B-MISC     B-MISC     [20]          \" لتس نوت CF - w4g                                \n",
            "CF                   I-MISC     B-MISC     [20]          \" لتس نوت CF - w4g                                \n",
            "-------------------------------------------------------------------------\n",
            "-                    O          O          [20]          نوت CF - w4g \" ،                                  \n",
            "CF                   I-MISC     B-MISC     [20]          نوت CF - w4g \" ،                                  \n",
            "نوت                  I-MISC     I-MISC     [20]          نوت CF - w4g \" ،                                  \n",
            "لتس                  B-MISC     B-MISC     [20]          نوت CF - w4g \" ،                                  \n",
            "w4g                  I-MISC     O          [20]          نوت CF - w4g \" ،                                  \n",
            "-------------------------------------------------------------------------\n",
            "بيكنور               B-MISC     B-ORG      [22]          الفضاء من مركز بيكنور الفضائي في                  \n",
            "-------------------------------------------------------------------------\n",
            "الدولية              I-MISC     I-MISC     [25]          التنس الفردي الدولية المفتوحة للسيدات في          \n",
            "الفردي               I-MISC     I-MISC     [25]          التنس الفردي الدولية المفتوحة للسيدات في          \n",
            "التنس                I-MISC     I-MISC     [25]          التنس الفردي الدولية المفتوحة للسيدات في          \n",
            "ببطولة               B-MISC     B-MISC     [25]          التنس الفردي الدولية المفتوحة للسيدات في          \n",
            "المفتوحة             I-MISC     O          [25]          التنس الفردي الدولية المفتوحة للسيدات في          \n",
            "-------------------------------------------------------------------------\n",
            "ببطولة               B-MISC     O          [25]          بعد أن فازت ببطولة ويمبلدون الدولية               \n",
            "ويمبلدون             I-MISC     B-MISC     [25]          بعد أن فازت ببطولة ويمبلدون الدولية               \n",
            "الدولية              I-MISC     O          [25]          بعد أن فازت ببطولة ويمبلدون الدولية               \n",
            "للتنس                I-MISC     O          [25]          بعد أن فازت ببطولة ويمبلدون الدولية               \n",
            "-------------------------------------------------------------------------\n",
            "ويمبلدون             B-MISC     B-ORG      [25]          فقط فيما بين ويمبلدون والبطولة الامريكية          \n",
            "-------------------------------------------------------------------------\n",
            "السمبا               B-MISC     B-ORG      [26]          ليبدد آمال فريق السمبا في الفوز                   \n",
            "-------------------------------------------------------------------------\n",
            "كأس                  B-MISC     O          [26]          المباراة النهائية من كأس الاتحاد الأفريقي         \n",
            "الاتحاد              I-MISC     I-MISC     [26]          المباراة النهائية من كأس الاتحاد الأفريقي         \n",
            "الأفريقي             I-MISC     I-MISC     [26]          المباراة النهائية من كأس الاتحاد الأفريقي         \n",
            "لكرة                 I-MISC     O          [26]          المباراة النهائية من كأس الاتحاد الأفريقي         \n",
            "القدم                I-MISC     O          [26]          المباراة النهائية من كأس الاتحاد الأفريقي         \n",
            "-------------------------------------------------------------------------\n",
            "غاتويك               B-MISC     B-LOC      [30]          ازدحام المسافرين بمطار غاتويك البريطاني بسبب      \n",
            "-------------------------------------------------------------------------\n",
            "دوري                 B-MISC     O          [30]          حامل اللقب وبطل دوري أبطال أوروبا                 \n",
            "أبطال                I-MISC     O          [30]          حامل اللقب وبطل دوري أبطال أوروبا                 \n",
            "أوروبا               I-MISC     B-LOC      [30]          حامل اللقب وبطل دوري أبطال أوروبا                 \n",
            "-------------------------------------------------------------------------\n",
            "تايلند               I-MISC     I-MISC     [31]          نهائي بطولة تايلند الدولية للتنس ويلاقي           \n",
            "بطولة                B-MISC     B-MISC     [31]          نهائي بطولة تايلند الدولية للتنس ويلاقي           \n",
            "الدولية              I-MISC     O          [31]          نهائي بطولة تايلند الدولية للتنس ويلاقي           \n",
            "للتنس                I-MISC     O          [31]          نهائي بطولة تايلند الدولية للتنس ويلاقي           \n",
            "-------------------------------------------------------------------------\n",
            "إديلاييد             B-MISC     B-MISC     [31]          فاز ببطولات إديلاييد ولاس فيغاس وإنديانابوليس     \n",
            "ولاس                 I-MISC     B-MISC     [31]          فاز ببطولات إديلاييد ولاس فيغاس وإنديانابوليس     \n",
            "فيغاس                I-MISC     I-MISC     [31]          فاز ببطولات إديلاييد ولاس فيغاس وإنديانابوليس     \n",
            "-------------------------------------------------------------------------\n",
            "الإيغور              B-MISC     O          [31]          المنفى عن أقلية الإيغور المسلمة الصينية           \n",
            "-------------------------------------------------------------------------\n",
            "لدار                 B-MISC     O          [32]          الموسيقى العربية التابع لدار الأوبرا المصرية      \n",
            "الأوبرا              I-MISC     O          [32]          الموسيقى العربية التابع لدار الأوبرا المصرية      \n",
            "المصرية              I-MISC     O          [32]          الموسيقى العربية التابع لدار الأوبرا المصرية      \n",
            "-------------------------------------------------------------------------\n",
            "ومسرح                B-MISC     O          [32]          لدار الأوبرا المصرية ومسرح الجنينة بحديقة         \n",
            "الجنينة              I-MISC     O          [32]          لدار الأوبرا المصرية ومسرح الجنينة بحديقة         \n",
            "-------------------------------------------------------------------------\n",
            "منظر                 B-MISC     O          [32]          مثل لوحات \" منظر للنيل \"                          \n",
            "للنيل                I-MISC     O          [32]          مثل لوحات \" منظر للنيل \"                          \n",
            "-------------------------------------------------------------------------\n",
            "الأولاد              B-MISC     O          [32]          \" ، \" الأولاد في النيل                            \n",
            "في                   I-MISC     O          [32]          \" ، \" الأولاد في النيل                            \n",
            "النيل                I-MISC     O          [32]          \" ، \" الأولاد في النيل                            \n",
            "-------------------------------------------------------------------------\n",
            "تمثال                B-MISC     O          [32]          بصمته الخاصة منها تمثال سيزيف الموجود             \n",
            "سيزيف                I-MISC     B-MISC     [32]          بصمته الخاصة منها تمثال سيزيف الموجود             \n",
            "-------------------------------------------------------------------------\n",
            "الأطفال              B-MISC     O          [32]          حملت عنوان \" الأطفال والفنانون وحدهم              \n",
            "والفنانون            I-MISC     O          [32]          حملت عنوان \" الأطفال والفنانون وحدهم              \n",
            "وحدهم                I-MISC     O          [32]          حملت عنوان \" الأطفال والفنانون وحدهم              \n",
            "قادرون               I-MISC     O          [32]          حملت عنوان \" الأطفال والفنانون وحدهم              \n",
            "على                  I-MISC     O          [32]          حملت عنوان \" الأطفال والفنانون وحدهم              \n",
            "إنقاذ                I-MISC     O          [32]          حملت عنوان \" الأطفال والفنانون وحدهم              \n",
            "العالم               I-MISC     O          [32]          حملت عنوان \" الأطفال والفنانون وحدهم              \n",
            "-------------------------------------------------------------------------\n",
            "الجائزة              B-MISC     O          [33]          الجمعة في إيطاليا الجائزة الدولية الإيطالية       \n",
            "الدولية              I-MISC     O          [33]          الجمعة في إيطاليا الجائزة الدولية الإيطالية       \n",
            "الإيطالية            I-MISC     O          [33]          الجمعة في إيطاليا الجائزة الدولية الإيطالية       \n",
            "لحوض                 I-MISC     O          [33]          الجمعة في إيطاليا الجائزة الدولية الإيطالية       \n",
            "البحر                I-MISC     B-LOC      [33]          الجمعة في إيطاليا الجائزة الدولية الإيطالية       \n",
            "الأبيض               I-MISC     I-LOC      [33]          الجمعة في إيطاليا الجائزة الدولية الإيطالية       \n",
            "المتوسط              I-MISC     I-LOC      [33]          الجمعة في إيطاليا الجائزة الدولية الإيطالية       \n",
            "-------------------------------------------------------------------------\n",
            "دولي                 B-MISC     O          [33]          المستخدم لاستنساخ النعجة دولي ( رويترز            \n",
            "-------------------------------------------------------------------------\n",
            "دولي                 B-MISC     O          [33]          استخدمت لاستنساخ النعجة دولي التي جرت             \n",
            "-------------------------------------------------------------------------\n",
            "المؤتمر              B-MISC     O          [33]          كلمة خلال افتتاح المؤتمر الدولي السادس            \n",
            "الدولي               I-MISC     O          [33]          كلمة خلال افتتاح المؤتمر الدولي السادس            \n",
            "السادس               I-MISC     O          [33]          كلمة خلال افتتاح المؤتمر الدولي السادس            \n",
            "عشر                  I-MISC     O          [33]          كلمة خلال افتتاح المؤتمر الدولي السادس            \n",
            "-------------------------------------------------------------------------\n",
            "لفيروس               B-MISC     O          [33]          لقاح أكيد بعد لفيروس اتش آي                       \n",
            "اتش                  I-MISC     B-MISC     [33]          لقاح أكيد بعد لفيروس اتش آي                       \n",
            "آي                   I-MISC     I-MISC     [33]          لقاح أكيد بعد لفيروس اتش آي                       \n",
            "في                   I-MISC     I-MISC     [33]          لقاح أكيد بعد لفيروس اتش آي                       \n",
            "-------------------------------------------------------------------------\n",
            "بفيروس               B-MISC     O          [33]          الجنس لمنع إصابتهن بفيروس اتش آي                  \n",
            "اتش                  I-MISC     B-MISC     [33]          الجنس لمنع إصابتهن بفيروس اتش آي                  \n",
            "آي                   I-MISC     I-MISC     [33]          الجنس لمنع إصابتهن بفيروس اتش آي                  \n",
            "في                   I-MISC     I-MISC     [33]          الجنس لمنع إصابتهن بفيروس اتش آي                  \n",
            "-------------------------------------------------------------------------\n",
            "سنتا                 B-MISC     O          [42]          ارتفع الجمعة 15 سنتا واستقر عند                   \n",
            "-------------------------------------------------------------------------\n",
            "المكسيك              B-MISC     I-LOC      [42]          مدمر في خليج المكسيك ، وتبعات                     \n",
            "-------------------------------------------------------------------------\n",
            "الكلب                B-MISC     O          [43]          andalou \" ( الكلب الأندلسي )                      \n",
            "الأندلسي             I-MISC     O          [43]          andalou \" ( الكلب الأندلسي )                      \n",
            "-------------------------------------------------------------------------\n",
            "L                    B-MISC     O          [43]          ، و \" L ' Age                                     \n",
            "'                    I-MISC     O          [43]          ، و \" L ' Age                                     \n",
            "Age                  I-MISC     O          [43]          ، و \" L ' Age                                     \n",
            "d                    I-MISC     O          [43]          ، و \" L ' Age                                     \n",
            "'                    I-MISC     O          [43]          ، و \" L ' Age                                     \n",
            "or                   I-MISC     O          [43]          ، و \" L ' Age                                     \n",
            "-------------------------------------------------------------------------\n",
            "السرية               I-MISC     I-MISC     [43]          \" الحياة السرية لسلفادور دالي \"                   \n",
            "الحياة               B-MISC     B-MISC     [43]          \" الحياة السرية لسلفادور دالي \"                   \n",
            "لسلفادور             I-MISC     B-PERS     [43]          \" الحياة السرية لسلفادور دالي \"                   \n",
            "دالي                 I-MISC     I-PERS     [43]          \" الحياة السرية لسلفادور دالي \"                   \n",
            "-------------------------------------------------------------------------\n",
            "ستاد                 B-MISC     O          [44]          الماضية مفاجأة في ستاد الحسن ،                    \n",
            "الحسن                I-MISC     B-LOC      [44]          الماضية مفاجأة في ستاد الحسن ،                    \n",
            "-------------------------------------------------------------------------\n",
            "ستاد                 B-MISC     O          [45]          اما على ستاد عمان ، فقد                           \n",
            "عمان                 I-MISC     B-LOC      [45]          اما على ستاد عمان ، فقد                           \n",
            "-------------------------------------------------------------------------\n",
            "ستاد                 B-MISC     O          [45]          الإنتصارات . وعلى ستاد الملك عبدالله              \n",
            "-------------------------------------------------------------------------\n",
            "لمهرجان              B-MISC     O          [48]          جائزة الأسد الذهبي لمهرجان البندقية عام           \n",
            "البندقية             I-MISC     B-MISC     [48]          جائزة الأسد الذهبي لمهرجان البندقية عام           \n",
            "-------------------------------------------------------------------------\n",
            "أنا                  B-MISC     B-MISC     [48]          وفيلم \" أنا وترانه و15 سنة                        \n",
            "وترانه               I-MISC     B-MISC     [48]          وفيلم \" أنا وترانه و15 سنة                        \n",
            "و15                  I-MISC     I-MISC     [48]          وفيلم \" أنا وترانه و15 سنة                        \n",
            "سنة                  I-MISC     I-MISC     [48]          وفيلم \" أنا وترانه و15 سنة                        \n",
            "-------------------------------------------------------------------------\n",
            "البوب                B-MISC     O          [48]          اليوم نجم موسيقى البوب جورج مايكل                 \n",
            "-------------------------------------------------------------------------\n",
            "البوب                B-MISC     O          [48]          الحميم إن مغني البوب ليس لديه                     \n",
            "-------------------------------------------------------------------------\n",
            "البوب                B-MISC     O          [48]          وباع نجم موسيقى البوب - الذي                      \n",
            "-------------------------------------------------------------------------\n",
            "هوي                  B-MISC     B-LOC      [49]          ما من قومية هوي بمقاطعة يونان                     \n",
            "-------------------------------------------------------------------------\n",
            "82\n",
            "Word                 True       Pred       sentence   contetx\n",
            "الإسلام              O          B-MISC     [2]          الحل والعقد في الإسلام ، وأخيرا                   \n",
            "-------------------------------------------------------------------------\n",
            "حرب                  O          B-MISC     [3]          شبه مستقلة منذ حرب الخليج 1991                    \n",
            "-------------------------------------------------------------------------\n",
            "الخليج               O          I-MISC     [3]          مستقلة منذ حرب الخليج 1991 ,                      \n",
            "-------------------------------------------------------------------------\n",
            "حالة                 O          B-MISC     [3]          في كتابه \" حالة النكران \"                         \n",
            "-------------------------------------------------------------------------\n",
            "النكران              O          I-MISC     [3]          كتابه \" حالة النكران \" صورة                       \n",
            "-------------------------------------------------------------------------\n",
            "بالإسلام             O          B-MISC     [5]          ربط فيها العنف بالإسلام , أما                     \n",
            "-------------------------------------------------------------------------\n",
            "الإسلام              O          B-MISC     [6]          البابا تطاولا على الإسلام ( رويترز                \n",
            "-------------------------------------------------------------------------\n",
            "دولار                O          B-MISC     [12]          كانت تتقاضي مليون دولار في الاسبوع                \n",
            "-------------------------------------------------------------------------\n",
            "الحرب                O          B-MISC     [14]          حكومة لم يشهد الحرب العالمية الثانية              \n",
            "-------------------------------------------------------------------------\n",
            "العالمية             O          I-MISC     [14]          لم يشهد الحرب العالمية الثانية ،                  \n",
            "-------------------------------------------------------------------------\n",
            "الثانية              O          I-MISC     [14]          يشهد الحرب العالمية الثانية ، ويرغب               \n",
            "-------------------------------------------------------------------------\n",
            "الأورو               O          B-MISC     [18]          في المجموعة الأولى الأورو / إفريقية               \n",
            "-------------------------------------------------------------------------\n",
            "ليثيوم               O          B-MISC     [20]          1 مليون بطارية ليثيوم يتم استخدامها               \n",
            "-------------------------------------------------------------------------\n",
            "سنتا                 O          B-MISC     [23]          في فنزويلا 42 سنتا خلال الأسبوع                   \n",
            "-------------------------------------------------------------------------\n",
            "دولار                O          B-MISC     [23]          8 . 85 دولار عن متوسط                             \n",
            "-------------------------------------------------------------------------\n",
            "دولار                O          B-MISC     [23]          63 . 13 دولار ) ويوليو                            \n",
            "-------------------------------------------------------------------------\n",
            "للتنس                O          I-MISC     [25]          ببطولة فرنسا المفتوحة للتنس إلا أنها              \n",
            "-------------------------------------------------------------------------\n",
            "بطولات               O          B-MISC     [25]          لعبت في تاريخ بطولات كأس العالم                   \n",
            "-------------------------------------------------------------------------\n",
            "كأس                  O          I-MISC     [25]          في تاريخ بطولات كأس العالم ويعد                   \n",
            "-------------------------------------------------------------------------\n",
            "العالم               O          I-MISC     [25]          تاريخ بطولات كأس العالم ويعد هذا                  \n",
            "-------------------------------------------------------------------------\n",
            "البطولة              O          B-MISC     [26]          إلى استعادة ثنائي البطولة والكأس في               \n",
            "-------------------------------------------------------------------------\n",
            "والكأس               O          I-MISC     [26]          استعادة ثنائي البطولة والكأس في تونس              \n",
            "-------------------------------------------------------------------------\n",
            "بطولة                O          B-MISC     [31]          في الفوز بلقب بطولة بلاده وفاز                    \n",
            "-------------------------------------------------------------------------\n",
            "بلاده                O          I-MISC     [31]          الفوز بلقب بطولة بلاده وفاز عليه                  \n",
            "-------------------------------------------------------------------------\n",
            "للسيدات              O          I-MISC     [36]          ببطولة العالم للإسكواش للسيدات بعد تغلبها         \n",
            "-------------------------------------------------------------------------\n",
            "البطولة              O          B-MISC     [36]          وخسرت مصر نهائي البطولة التي جرت                  \n",
            "-------------------------------------------------------------------------\n",
            "بطولة                O          B-MISC     [37]          المركز الثاني في بطولة العالم لفرق                \n",
            "-------------------------------------------------------------------------\n",
            "العالم               O          I-MISC     [37]          الثاني في بطولة العالم لفرق الرجال                \n",
            "-------------------------------------------------------------------------\n",
            "لفرق                 O          I-MISC     [37]          في بطولة العالم لفرق الرجال التي                  \n",
            "-------------------------------------------------------------------------\n",
            "الرجال               O          I-MISC     [37]          بطولة العالم لفرق الرجال التي جرت                 \n",
            "-------------------------------------------------------------------------\n",
            "الحرب                O          B-MISC     [38]          الي النصر في الحرب الباردة .                      \n",
            "-------------------------------------------------------------------------\n",
            "الباردة              O          I-MISC     [38]          النصر في الحرب الباردة . وقال                     \n",
            "-------------------------------------------------------------------------\n",
            "حرب                  O          B-MISC     [39]          لهزيمته المهينة في حرب الخليج .                   \n",
            "-------------------------------------------------------------------------\n",
            "harrass              O          B-MISC     [42]          كلمة وكتبتها \" harrass \" وليس                     \n",
            "-------------------------------------------------------------------------\n",
            "إصرار                O          B-MISC     [43]          المبهمة هي \" إصرار الذاكرة \"                      \n",
            "-------------------------------------------------------------------------\n",
            "الذاكرة              O          I-MISC     [43]          هي \" إصرار الذاكرة \" (                            \n",
            "-------------------------------------------------------------------------\n",
            "الدرع                O          B-MISC     [45]          مغادرته السريعة لبطولتي الدرع والكأس ،            \n",
            "-------------------------------------------------------------------------\n",
            "والكأس               O          I-MISC     [45]          السريعة لبطولتي الدرع والكأس ، واكد               \n",
            "-------------------------------------------------------------------------\n",
            "ذيابات               O          B-MISC     [47]          فيما مرت كرة ذيابات الزاحفة من                    \n",
            "-------------------------------------------------------------------------\n",
            "39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFgoJheCAY4Q",
        "outputId": "2912f173-a3fa-472b-d158-b154093f0c79"
      },
      "source": [
        "\n",
        "## features effect\n",
        "test_pred = model.predict(np.array(X_test), verbose=1)   \n",
        "pred_labels1 = pred2label(test_pred)\n",
        "test_labels = pred2label(Y_test)\n",
        "\n",
        "X_words_te=X_words[834:]\n",
        "count=0\n",
        "i=0\n",
        "added=[]\n",
        "print(\"{:20}: ({:8}): {:8}:{}\".format(\"Word\", \"True\", \"Pred\", \"features\"))\n",
        "while(i<np.shape(pred_labels1)[0]):\n",
        "  j=0\n",
        "  pred= pred_labels1[i]\n",
        "  true=test_labels[i]\n",
        "  word=X_words_te[i]\n",
        "  features=  pred_labels2[i]\n",
        "  while(j<sent_len):\n",
        "    if(pred[j] != features[j] and true[j] != features[j]):\n",
        "      print(\"{:20}: ({:8}): {:8} :{}\".format(word[j],true[j],pred[j], features[j]))\n",
        "      count+=1\n",
        "      #break\n",
        "    j+=1\n",
        "  #added.append((Y_Test_Named[i],Y_Pred2[i]))\n",
        "  i+=1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word                : (True    ): Pred    :features\n",
            "ونايفة              : (B-LOC   ): B-LOC    :I-LOC\n",
            "البادية             : (O       ): O        :B-LOC\n",
            "الجنوبية            : (O       ): O        :I-LOC\n",
            "البادية             : (O       ): O        :B-LOC\n",
            "الشمالية            : (O       ): O        :I-LOC\n",
            "العامة              : (I-ORG   ): I-ORG    :O\n",
            "جماعة               : (I-MISC  ): O        :B-ORG\n",
            "الإخوان             : (I-MISC  ): B-ORG    :I-ORG\n",
            "قناة                : (B-ORG   ): B-ORG    :O\n",
            "التأسلم             : (O       ): O        :B-MISC\n",
            "السياسي             : (O       ): O        :I-MISC\n",
            "الراشدين            : (B-MISC  ): B-PERS   :O\n",
            "الخليج              : (O       ): I-MISC   :B-LOC\n",
            "ووترغيت             : (B-MISC  ): B-MISC   :B-LOC\n",
            "تشانغسين            : (B-MISC  ): B-LOC    :B-PERS\n",
            "الأمم               : (B-ORG   ): B-ORG    :I-ORG\n",
            "مجلس                : (O       ): O        :B-ORG\n",
            "النواب              : (O       ): O        :I-ORG\n",
            "بالاتحاد            : (O       ): O        :B-ORG\n",
            "البابا              : (B-PERS  ): B-PERS   :O\n",
            "البابا              : (I-PERS  ): I-PERS   :O\n",
            "ال                  : (I-PERS  ): I-PERS   :O\n",
            "حركة                : (O       ): O        :B-ORG\n",
            "حماس                : (B-ORG   ): B-ORG    :I-ORG\n",
            "بنك                 : (B-ORG   ): B-ORG    :O\n",
            "ايطاليا             : (I-ORG   ): I-ORG    :B-LOC\n",
            "المركزي             : (I-ORG   ): I-ORG    :O\n",
            "بنك                 : (B-ORG   ): B-ORG    :O\n",
            "فرنسا               : (I-ORG   ): I-ORG    :B-LOC\n",
            "المركزي             : (I-ORG   ): I-ORG    :O\n",
            "-                   : (O       ): O        :I-MISC\n",
            "الرالي              : (B-MISC  ): B-MISC   :O\n",
            "قطر                 : (B-ORG   ): B-ORG    :B-LOC\n",
            "للراليات            : (O       ): O        :I-MISC\n",
            "ال                  : (B-MISC  ): I-MISC   :O\n",
            "660                 : (I-MISC  ): I-MISC   :O\n",
            "سيات                : (B-ORG   ): B-ORG    :O\n",
            "كوردوبا             : (B-MISC  ): I-PERS   :B-PERS\n",
            "متسوبيشي            : (B-ORG   ): B-ORG    :B-PERS\n",
            "فونتيناي            : (B-PERS  ): B-PERS   :B-ORG\n",
            "سيرفيا              : (B-PERS  ): B-ORG    :O\n",
            "شليسير              : (B-ORG   ): B-PERS   :B-LOC\n",
            "كوما                : (B-PERS  ): B-ORG    :O\n",
            "سوزوكي              : (B-ORG   ): B-PERS   :B-LOC\n",
            "سالا                : (B-PERS  ): B-ORG    :O\n",
            "كي                  : (B-MISC  ): B-ORG    :O\n",
            "تي                  : (I-MISC  ): I-ORG    :O\n",
            "إم                  : (I-MISC  ): I-ORG    :O\n",
            "كوكس                : (B-PERS  ): B-PERS   :O\n",
            "ميوني               : (B-PERS  ): B-PERS   :O\n",
            "الباهامي            : (O       ): O        :B-LOC\n",
            "الاكراد             : (O       ): O        :B-ORG\n",
            "الاكراد             : (O       ): O        :B-ORG\n",
            "وابيه               : (B-PERS  ): B-PERS   :O\n",
            "المنظمة             : (O       ): O        :B-ORG\n",
            "الجورجية            : (O       ): O        :B-LOC\n",
            "الجورجي             : (O       ): O        :B-LOC\n",
            "الجورجية            : (O       ): O        :B-LOC\n",
            "السريلانكية         : (O       ): O        :B-LOC\n",
            "السريلانكي          : (O       ): O        :B-LOC\n",
            "السلفية             : (I-ORG   ): I-ORG    :B-ORG\n",
            "البريطاني           : (I-ORG   ): I-ORG    :O\n",
            "للدراسات            : (I-ORG   ): I-ORG    :O\n",
            "الدولية             : (I-ORG   ): I-ORG    :O\n",
            "الليثيوم            : (O       ): O        :B-MISC\n",
            "وLenovo             : (B-ORG   ): I-ORG    :O\n",
            "ليثيوم              : (O       ): O        :B-MISC\n",
            "باناسونيك           : (B-ORG   ): B-ORG    :B-MISC\n",
            "ليثيوم              : (O       ): O        :B-MISC\n",
            "العسكر              : (O       ): O        :B-ORG\n",
            "الطيبة              : (O       ): O        :I-ORG\n",
            "لوكالة              : (O       ): O        :B-ORG\n",
            "الفضاء              : (O       ): O        :I-ORG\n",
            "المريخ              : (O       ): B-LOC    :B-MISC\n",
            "المريخ              : (B-LOC   ): B-LOC    :O\n",
            "الذنيبات            : (O       ): I-PERS   :B-PERS\n",
            "Grand               : (O       ): B-MISC   :I-MISC\n",
            "الزهايمر            : (B-MISC  ): O        :B-ORG\n",
            "داود                : (B-PERS  ): O        :B-MISC\n",
            "إسرائيل             : (I-ORG   ): I-ORG    :B-LOC\n",
            "للسيد               : (O       ): O        :B-PERS\n",
            "المسيح              : (B-PERS  ): B-PERS   :I-PERS\n",
            "الإنجيل             : (B-MISC  ): B-MISC   :O\n",
            "غاتويك              : (B-MISC  ): B-MISC   :B-LOC\n",
            "ولاس                : (I-MISC  ): B-LOC    :B-MISC\n",
            "وإنديانابوليس       : (B-PERS  ): B-LOC    :B-ORG\n",
            "موسيقى              : (O       ): O        :B-MISC\n",
            "قديمة               : (O       ): O        :I-MISC\n",
            "الغوري              : (I-ORG   ): B-LOC    :B-MISC\n",
            "ومعهد               : (B-ORG   ): B-ORG    :O\n",
            "الموسيقى            : (I-ORG   ): I-ORG    :O\n",
            "العربية             : (I-ORG   ): I-ORG    :O\n",
            "لدار                : (B-MISC  ): B-ORG    :O\n",
            "الأوبرا             : (I-MISC  ): I-ORG    :O\n",
            "الجنينة             : (I-MISC  ): B-ORG    :O\n",
            "النيل               : (B-LOC   ): B-LOC    :B-MISC\n",
            "هوهمان              : (B-MISC  ): B-LOC    :B-ORG\n",
            "العلمية             : (I-ORG   ): I-ORG    :O\n",
            "رويانا              : (B-MISC  ): B-MISC   :I-MISC\n",
            "معهد                : (B-ORG   ): B-ORG    :O\n",
            "رويان               : (I-ORG   ): I-ORG    :B-ORG\n",
            "البابا              : (B-PERS  ): B-PERS   :O\n",
            "مدريد               : (I-ORG   ): I-ORG    :B-LOC\n",
            "برشلونة             : (B-ORG   ): B-ORG    :B-LOC\n",
            "أفريقيا             : (I-ORG   ): I-LOC    :B-LOC\n",
            "الوسطي              : (O       ): O        :I-LOC\n",
            "جور                 : (O       ): I-PERS   :B-PERS\n",
            "البنك               : (B-ORG   ): B-ORG    :O\n",
            "المركزي             : (I-ORG   ): I-ORG    :O\n",
            "القاعدة             : (B-ORG   ): B-ORG    :O\n",
            "والجراح             : (B-PERS  ): I-PERS   :O\n",
            "القاعدة             : (B-ORG   ): B-ORG    :O\n",
            "بمقضاته             : (O       ): O        :I-PERS\n",
            "Black               : (I-MISC  ): I-MISC   :B-MISC\n",
            "سنتا                : (B-MISC  ): B-MISC   :O\n",
            "كاتالانيا           : (O       ): B-PERS   :B-LOC\n",
            "عبدالله             : (B-PERS  ): B-PERS   :I-MISC\n",
            "فالحسين             : (B-ORG   ): O        :B-PERS\n",
            "فالحسين             : (B-ORG   ): O        :B-PERS\n",
            "زخذ                 : (O       ): O        :B-PERS\n",
            "الحسنات             : (B-PERS  ): B-PERS   :O\n",
            "فتح                 : (B-ORG   ): B-ORG    :O\n",
            "بناهي               : (I-PERS  ): I-PERS   :B-PERS\n",
            "هوليود              : (O       ): I-ORG    :B-ORG\n",
            "هيئة                : (B-ORG   ): B-ORG    :O\n",
            "الطاقة              : (I-ORG   ): I-ORG    :O\n",
            "الذرية              : (I-ORG   ): I-ORG    :O\n",
            "كوبلي               : (B-ORG   ): B-ORG    :B-MISC\n",
            "بلازا               : (I-ORG   ): I-ORG    :I-MISC\n",
            "العربية             : (I-ORG   ): I-ORG    :B-ORG\n",
            "art                 : (I-ORG   ): I-ORG    :B-ORG\n",
            "131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flFVs3czxjjr",
        "outputId": "0d042d49-cca3-4b17-dbab-44536ae708c1"
      },
      "source": [
        "\n",
        "\n",
        "X_words_te=X_words[834:]\n",
        "count=0\n",
        "i=0\n",
        "added=[]\n",
        "print(\"{:20}: ({:8}): {:8}:{}\".format(\"Word\", \"True\", \"Pred\", \"features\"))\n",
        "while(i<np.shape(pred_labels1)[0]):\n",
        "  j=0\n",
        "  pred= pred_labels1[i]\n",
        "  true=test_labels[i]\n",
        "  word=X_words_te[i]\n",
        "  features=  pred_labels2[i]\n",
        "  while(j<sent_len):\n",
        "    if(pred[j] != features[j] and true[j] == features[j]):\n",
        "      print(\"{:20}: ({:8}): {:8} :{}\".format(word[j],true[j],pred[j], features[j]))\n",
        "      count+=1\n",
        "      #break\n",
        "    j+=1\n",
        "  #added.append((Y_Test_Named[i],Y_Pred2[i]))\n",
        "  i+=1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word                : (True    ): Pred    :features\n",
            "فأميركا             : (B-LOC   ): O        :B-LOC\n",
            "التأسلم             : (B-MISC  ): O        :B-MISC\n",
            "حزب                 : (B-ORG   ): O        :B-ORG\n",
            "التجمع              : (I-ORG   ): O        :I-ORG\n",
            "بجماعة              : (B-ORG   ): O        :B-ORG\n",
            "التكفير             : (I-ORG   ): O        :I-ORG\n",
            "والهجرة             : (I-ORG   ): O        :I-ORG\n",
            "جماعة               : (B-ORG   ): O        :B-ORG\n",
            "الجهاد              : (I-ORG   ): O        :I-ORG\n",
            "والجماعة            : (B-ORG   ): O        :B-ORG\n",
            "الإسلامية           : (I-ORG   ): O        :I-ORG\n",
            "حرب                 : (O       ): B-MISC   :O\n",
            "الإعصار             : (O       ): B-MISC   :O\n",
            "تشانغسين            : (B-MISC  ): B-LOC    :B-MISC\n",
            "الدفاع              : (O       ): I-ORG    :O\n",
            "المدني              : (O       ): I-ORG    :O\n",
            "الأوسط              : (O       ): I-LOC    :O\n",
            "وشانغسين            : (B-MISC  ): B-LOC    :B-MISC\n",
            "لاريجاني            : (B-PERS  ): I-PERS   :B-PERS\n",
            "كتائب               : (B-ORG   ): O        :B-ORG\n",
            "عز                  : (I-ORG   ): B-ORG    :I-ORG\n",
            "حانون               : (I-LOC   ): B-LOC    :I-LOC\n",
            "دو                  : (I-LOC   ): B-LOC    :I-LOC\n",
            "الليرة              : (B-MISC  ): O        :B-MISC\n",
            "اليورو              : (B-LOC   ): B-MISC   :B-LOC\n",
            "باريس               : (I-MISC  ): B-LOC    :I-MISC\n",
            "داكار               : (I-MISC  ): B-LOC    :I-MISC\n",
            "كوردوبا             : (B-MISC  ): I-MISC   :B-MISC\n",
            "بيك                 : (B-MISC  ): O        :B-MISC\n",
            "هانسل               : (I-PERS  ): B-PERS   :I-PERS\n",
            "بالبطولة            : (O       ): B-MISC   :O\n",
            "واليوغسلافي         : (O       ): B-PERS   :O\n",
            "سيمونجك             : (B-PERS  ): I-PERS   :B-PERS\n",
            "والكازاخستاني       : (O       ): B-PERS   :O\n",
            "جيرل                : (B-PERS  ): I-PERS   :B-PERS\n",
            "واندرسون            : (B-ORG   ): B-LOC    :B-ORG\n",
            "مجتمع               : (O       ): I-ORG    :O\n",
            "ديمقراطي            : (O       ): I-ORG    :O\n",
            "الرياض              : (B-LOC   ): B-ORG    :B-LOC\n",
            "للجماعة             : (B-ORG   ): O        :B-ORG\n",
            "والقصور             : (I-LOC   ): B-LOC    :I-LOC\n",
            "بالقصور             : (O       ): B-LOC    :O\n",
            "الجماعة             : (B-ORG   ): O        :B-ORG\n",
            "لصناعة              : (O       ): I-ORG    :O\n",
            "الكمبيوتر           : (O       ): I-ORG    :O\n",
            "حماية               : (O       ): I-ORG    :O\n",
            "المستهلك            : (O       ): I-ORG    :O\n",
            "لإنتاج              : (O       ): I-ORG    :O\n",
            "w4g                 : (I-MISC  ): O        :I-MISC\n",
            "العسكر              : (O       ): B-ORG    :O\n",
            "الطيبة              : (O       ): I-ORG    :O\n",
            "حرب                 : (O       ): B-MISC   :O\n",
            "سبيريت              : (B-MISC  ): B-ORG    :B-MISC\n",
            "سويوز               : (B-MISC  ): B-ORG    :B-MISC\n",
            "ووليامز             : (B-PERS  ): I-PERS   :B-PERS\n",
            "الألمانية           : (O       ): I-ORG    :O\n",
            "لصناعة              : (O       ): I-ORG    :O\n",
            "السيارات            : (O       ): I-ORG    :O\n",
            "سنتا                : (O       ): B-MISC   :O\n",
            "جبهة                : (O       ): B-ORG    :O\n",
            "العمل               : (O       ): I-ORG    :O\n",
            "الإسلامي            : (O       ): I-ORG    :O\n",
            "بطولة               : (O       ): B-MISC   :O\n",
            "والكأس              : (O       ): I-MISC   :O\n",
            "الغيني              : (O       ): I-ORG    :O\n",
            "نادي                : (O       ): B-ORG    :O\n",
            "موناكو              : (B-ORG   ): I-ORG    :B-ORG\n",
            "غينيس               : (B-MISC  ): B-ORG    :B-MISC\n",
            "للفلسطينيين         : (O       ): B-LOC    :O\n",
            "العمل               : (B-ORG   ): I-ORG    :B-ORG\n",
            "اليهودي             : (O       ): I-ORG    :O\n",
            "الخطوط              : (O       ): B-ORG    :O\n",
            "الجوية              : (O       ): I-ORG    :O\n",
            "الأوروبية           : (O       ): I-ORG    :O\n",
            "الدوري              : (O       ): I-MISC   :O\n",
            "الإسباني            : (O       ): I-MISC   :O\n",
            "فيغاس               : (I-MISC  ): I-LOC    :I-MISC\n",
            "للسلام              : (O       ): I-MISC   :O\n",
            "للآداب              : (O       ): I-MISC   :O\n",
            "رحلة                : (B-MISC  ): O        :B-MISC\n",
            "هارت                : (B-MISC  ): B-LOC    :B-MISC\n",
            "منظر                : (B-MISC  ): O        :B-MISC\n",
            "للنيل               : (I-MISC  ): O        :I-MISC\n",
            "الحياة              : (B-MISC  ): O        :B-MISC\n",
            "في                  : (I-MISC  ): O        :I-MISC\n",
            "النيل               : (I-MISC  ): O        :I-MISC\n",
            "مركب                : (B-MISC  ): O        :B-MISC\n",
            "النيل               : (I-MISC  ): O        :I-MISC\n",
            "الأولاد             : (B-MISC  ): O        :B-MISC\n",
            "في                  : (I-MISC  ): O        :I-MISC\n",
            "النيل               : (I-MISC  ): O        :I-MISC\n",
            "المؤتمر             : (B-MISC  ): O        :B-MISC\n",
            "بالايدز             : (B-MISC  ): O        :B-MISC\n",
            "القاعدة             : (B-ORG   ): O        :B-ORG\n",
            "الخضراء             : (O       ): B-LOC    :O\n",
            "سني                 : (O       ): B-ORG    :O\n",
            "الفاتيكان           : (B-LOC   ): B-ORG    :B-LOC\n",
            "قطر                 : (I-MISC  ): B-LOC    :I-MISC\n",
            "آل                  : (I-PERS  ): I-ORG    :I-PERS\n",
            "ثاني                : (I-PERS  ): I-ORG    :I-PERS\n",
            "ال                  : (O       ): B-PERS   :O\n",
            "حرب                 : (O       ): B-MISC   :O\n",
            "الخليج              : (B-LOC   ): I-MISC   :B-LOC\n",
            "وواشنطن             : (B-LOC   ): I-LOC    :B-LOC\n",
            "سنتا                : (O       ): B-MISC   :O\n",
            "للبرميل             : (O       ): B-MISC   :O\n",
            "Dalí                : (I-PERS  ): O        :I-PERS\n",
            "الشباب              : (O       ): B-ORG    :O\n",
            "الشباب              : (O       ): B-ORG    :O\n",
            "ز75س                : (O       ): B-PERS   :O\n",
            "الشباب              : (O       ): B-ORG    :O\n",
            "الوريكات            : (B-PERS  ): O        :B-PERS\n",
            "والرياحنة           : (B-PERS  ): I-PERS   :B-PERS\n",
            "والمقاومة           : (B-ORG   ): O        :B-ORG\n",
            "الإسلامية           : (I-ORG   ): O        :I-ORG\n",
            "و15                 : (I-MISC  ): O        :I-MISC\n",
            "سنة                 : (I-MISC  ): O        :I-MISC\n",
            "أكاديمية            : (O       ): B-ORG    :O\n",
            "ما                  : (O       ): B-PERS   :O\n",
            "المكرمة             : (I-LOC   ): O        :I-LOC\n",
            "بلازا               : (B-ORG   ): B-MISC   :B-ORG\n",
            "121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gND8D23N1cPe"
      },
      "source": [
        "#previous model\n",
        "def create_model(lstm_units, embedding_dropout, lstm_dropout,activation_function, optimizer,dense_dropout , second_layer, dense_units):\n",
        "\n",
        "  ##word input as indecies relvent to total number of words\n",
        "  word_input = Input(shape=(sent_len,emb_size),name='word_input') ##sent_len is sentence length \n",
        "\n",
        "  ## word embedding layer\n",
        "  '''embeddings =Embedding(    \n",
        "                            n_words,\n",
        "                            np.shape(embedding_matrix)[1],\n",
        "                            embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                            trainable=False,\n",
        "                            )(word_input)'''\n",
        "\n",
        "  embeddings = word_input\n",
        "\n",
        "  if (use_features):\n",
        "    feature_in = Input(shape=(sent_len, max_fea_len,),name='feature_input')\n",
        "    embeddings = concatenate([word_input, feature_in])\n",
        "\n",
        "\n",
        "  ## Character embedding\n",
        "  if (character_embedding  is Char_type.LSTM):\n",
        "    char_in = Input(shape=(sent_len, char_len,),name='char_input')\n",
        "    emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2 , output_dim=25, \n",
        "                              input_length=char_len))(char_in)\n",
        "    char_enc = TimeDistributed(LSTM(units=25, return_sequences=False, \n",
        "                                    recurrent_dropout=0.5))(emb_char)\n",
        "    embeddings = concatenate([word_input, char_enc])\n",
        "\n",
        "\n",
        "  if (character_embedding  is Char_type.CNN):\n",
        "    char_in=Input(shape=(sent_len,char_len,1,),name='char_input')\n",
        "    emb_char=TimeDistributed(Embedding(input_dim=n_chars + 2,output_dim=25,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(char_in)\n",
        "    conv2d_out= TimeDistributed(Conv2D(kernel_size=3, filters=25, padding='same',activation='tanh', strides=1))(emb_char)\n",
        "    maxpool_out=TimeDistributed(MaxPooling2D(1))(conv2d_out)\n",
        "    char_enc = TimeDistributed(Flatten())(maxpool_out)\n",
        "    embeddings = concatenate([word_input, char_enc])\n",
        "\n",
        "  '''\n",
        "  ## attention layer \n",
        "  embeddings = SeqSelfAttention(\n",
        "              units=32,\n",
        "              attention_width=1,\n",
        "              attention_type=SeqSelfAttention.ATTENTION_TYPE_ADD,\n",
        "              use_additive_bias=True,\n",
        "              use_attention_bias=True,\n",
        "              attention_activation=\"softmax\",\n",
        "              kernel_regularizer=keras.regularizers.l2((1e-4)*(10**-1)),\n",
        "              bias_regularizer=keras.regularizers.l2((1e-4)*(10**-1)),\n",
        "              attention_regularizer_weight=1e-4*(10**-1),  \n",
        "          )()'''\n",
        "\n",
        "  ##dropout layer on embedding layer\n",
        "  model= Dropout(embedding_dropout)(embeddings)\n",
        "\n",
        "\n",
        "  ## 2 bidirectional LSTM layers \n",
        "  model = Bidirectional(LSTM(units=lstm_units, \n",
        "                            return_sequences=True, \n",
        "                            dropout=lstm_dropout, \n",
        "                            recurrent_dropout=lstm_dropout, \n",
        "                            kernel_initializer=keras.initializers.he_normal()))(model)\n",
        "  if (second_layer):\n",
        "    model = (LSTM(units=lstm_units*2 , \n",
        "                            return_sequences=True, \n",
        "                            dropout=lstm_dropout,\n",
        "                            recurrent_dropout=lstm_dropout, \n",
        "                            kernel_initializer=keras.initializers.he_normal()))(model)\n",
        "\n",
        "  '''\n",
        "  ## self attention layer \n",
        "  model = SeqSelfAttention(\n",
        "              units=32,\n",
        "              attention_width=1,\n",
        "              attention_type=SeqSelfAttention.ATTENTION_TYPE_ADD,\n",
        "              use_additive_bias=True,\n",
        "              use_attention_bias=True,\n",
        "              attention_activation=\"softmax\",\n",
        "              kernel_regularizer=keras.regularizers.l2((1e-4)*(10**-1)),\n",
        "              bias_regularizer=keras.regularizers.l2((1e-4)*(10**-1)),\n",
        "              attention_regularizer_weight=1e-4*(10**-1),  \n",
        "          )(model)'''\n",
        "\n",
        "  model = TimeDistributed(Dense(dense_units, activation=activation_function))(model)  # previously softmax output layer\n",
        "  model= Dropout(dense_dropout)(model)\n",
        "\n",
        "  ##CRF layer\n",
        "  crf = CRF(9)  \n",
        "  out = crf(model) \n",
        "\n",
        "\n",
        "\n",
        "  if (use_features and character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "      inputs = [word_input,char_in, feature_in]\n",
        "  elif (character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "      inputs = [word_input,char_in]\n",
        "  elif (use_features):\n",
        "      inputs = [word_input,feature_in]\n",
        "  else:\n",
        "    inputs = word_input\n",
        "\n",
        "\n",
        "  ##compile model \n",
        "  model = Model(inputs, out)\n",
        "  #adam= keras.optimizers.Adam(lr=optimizer, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "  #nadam =keras.optimizers.Nadam(\n",
        "    #learning_rate=0, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "  model.compile(optimizer=optimizer, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "\n",
        " \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMc32sS0WcJk"
      },
      "source": [
        "##================================== =========================== modified Features =========================== =====================================\n",
        "\n",
        "max_fea_len=11\n",
        "\n",
        "def embed_pos(value):\n",
        "  if value in ['part_fut', 'part_neg', 'part_interrog', 'part_verb', 'part_focus', 'part_det','part','part_voc']:\n",
        "    return [1.0]\n",
        "  elif value in [ 'pron_rel', 'pron_interrog', 'pron_exclam', 'pron', 'pron_dem']:\n",
        "    return [2.0]\n",
        "  elif value in ['abbrev', 'adv_rel', 'adv_interrog', 'adv' ]:\n",
        "    return [3.0]\n",
        "  elif value in ['verb', 'verb_pseudo' ]:\n",
        "    return [4.0]\n",
        "  elif value in ['conj_sub', 'conj', 'interj']:\n",
        "    return [5.0]\n",
        "  elif value in ['noun_prop' ]:\n",
        "    return [6.0]\n",
        "  elif value in [ 'noun']:\n",
        "    return [7.0]\n",
        "  elif value in [ 'punc' ]:\n",
        "    return [8.0]\n",
        "  elif value in [ 'digit' ]:\n",
        "    return [9.0]\n",
        "  elif value in [ 'prep']:\n",
        "    return [10.0]\n",
        "  elif value in [ 'noun_quant']:\n",
        "    return [11.0]\n",
        "  elif value in [ 'adj']:\n",
        "    return [12.0]\n",
        "  elif value in ['abbrev' ]:\n",
        "    return [13.0]\n",
        "  else:\n",
        "    return [0.0]\n",
        "\n",
        "def embed_enc0(value):\n",
        "  if value in ['0']:\n",
        "    return [1.0]\n",
        "  elif value in [ 'na']:\n",
        "    return [2.0]\n",
        "  elif value in [  '1p_dobj' , '1p_poss','1s_pron', '1s_poss', '1p_pron','1s_dobj' ]:             \n",
        "    return [3.0]\n",
        "  elif value in ['3mp_pron', '3ms_poss', '3ms_pron', '3d_poss','3fp_poss' ,'3fs_poss',\n",
        "                 '3d_dobj', '3fs_pron', '3mp_poss', '3fp_pron', '3d_pron', '3mp_dobj',\n",
        "                 '3ms_dobj', '3fp_dobj', '3fs_dobj']:\n",
        "    return [4.0]\n",
        "  elif value in [ '2mp_poss', '2fs_poss', '2ms_poss', '2fp_poss', '2ms_pron', '2fs_pron',\n",
        "                  '2ms_dobj', '2fs_dobj', '2mp_dobj', '2mp_pron',]:\n",
        "    return [5.0]\n",
        "  elif value in ['mA_sub', 'mA_rel', 'lA_neg', 'man_rel', 'ma_interrog' ]:\n",
        "    return [6.0]\n",
        "  else:\n",
        "    return [0.0]\n",
        "\n",
        "def embed_stt(value):\n",
        "  return one_hot(value, ['i', 'c', 'd', 'na'])\n",
        "\n",
        "def embed_num(value):\n",
        "  return one_hot(value, ['p', 's', 'd', 'na']) \n",
        "\n",
        "def embed_per(value):\n",
        "  return one_hot(value, ['1', '2', '3', 'na']) \n",
        "\n",
        "def embed_gen(value):\n",
        "  return one_hot(value, ['f', 'm', 'na']) \n",
        "\n",
        "def embed_prc0(value):\n",
        "  if value in ['0']:\n",
        "    return [1.0]\n",
        "  elif value in ['Al_det']:\n",
        "    return [2.0]\n",
        "  elif value in ['mA_rel']:\n",
        "    return [3.0]\n",
        "  elif value in ['na' ]:\n",
        "    return [4.0]\n",
        "  elif value in ['lA_neg' ]:\n",
        "    return [5.0]\n",
        "  elif value in ['mA_neg' ]:\n",
        "    return [6.0]\n",
        "  else:\n",
        "    return [0.0] \n",
        "\n",
        "def embed_prc1(value):\n",
        "  if value in ['0']:\n",
        "    return [1.0]\n",
        "  elif value in [ 'sa_fut']:\n",
        "    return [2.0]\n",
        "  elif value in ['ka_prep' ]:\n",
        "    return [3.0]\n",
        "  elif value in ['na' ]:\n",
        "    return [4.0]\n",
        "  elif value in ['la_rc']:\n",
        "    return [5.0]\n",
        "  elif value in ['la_emph']:\n",
        "    return [6.0]\n",
        "  elif value in ['li_prep' ]:\n",
        "    return [7.0]\n",
        "  elif value in ['bi_prep' ]:\n",
        "    return [8.0]\n",
        "  else:\n",
        "    return [0.0] \n",
        "\n",
        "def embed_prc2(value):\n",
        "  if value in ['0']:\n",
        "    return [1.0]\n",
        "  elif value in [ 'wa_part', 'wa_sub', 'wa_conj', 'fa_conj']:\n",
        "    return [2.0]\n",
        "  elif value in ['na' ]:\n",
        "    return [3.0]\n",
        "  else:\n",
        "    return [0.0]\n",
        "\n",
        "def embed_prc3(value):\n",
        "  if value in ['0']:\n",
        "    return [1.0]\n",
        "  elif value in [ '>a_ques']:\n",
        "    return [2.0]\n",
        "  elif value in ['na' ]:\n",
        "    return [3.0]\n",
        "  else:\n",
        "    return [0.0]\n",
        "    \n",
        "\n",
        "def one_hot( value, list):\n",
        "  try:\n",
        "    hot_idx =float(list.index(value) +1)\n",
        "    return [hot_idx]\n",
        "  except:\n",
        "    return [0.0]\n",
        "\n",
        "\n",
        "def features( X_words):\n",
        "  X_fea = []\n",
        "  i=0\n",
        "  idx=0\n",
        "  while i<len(X_words):\n",
        "    sent_seq = []\n",
        "    j=0\n",
        "    sent=X_words[i]\n",
        "    while (j<len(sent)):\n",
        "      word=sent[j]\n",
        "      if (word==\"ENDPAD\"):\n",
        "        feature_vector = np.zeros(11)\n",
        "      else:\n",
        "        feature_vector=[]\n",
        "        feature_vector+= embed_pos(data.at[idx,'pos'])\n",
        "        feature_vector+= embed_enc0(data.at[idx,'enc0'])\n",
        "        feature_vector+= embed_stt(data.at[idx,'stt'])\n",
        "        feature_vector+= embed_num(data.at[idx,'num'])\n",
        "        feature_vector+= embed_gen(data.at[idx,'gen'])\n",
        "        feature_vector+= embed_prc0(data.at[idx,'prc0'])\n",
        "        feature_vector+= embed_prc1(data.at[idx,'prc1'])\n",
        "        feature_vector+= embed_prc2(data.at[idx,'prc2'])\n",
        "        feature_vector+= embed_prc3(data.at[idx,'prc3'])\n",
        "        feature_vector+= embed_per(data.at[idx,'per'])\n",
        "\n",
        "        try:\n",
        "          if(data.at[idx,\"gloss\"][0].isupper()):\n",
        "            feature_vector+=[1.0]\n",
        "          else:\n",
        "            feature_vector+=[0.0]\n",
        "        except:\n",
        "          feature_vector+=[0.0]\n",
        "        idx+=1\n",
        "      sent_seq.append(feature_vector)\n",
        "      j+=1\n",
        "      \n",
        "    X_fea.append(sent_seq)\n",
        "    i+=1\n",
        "  return X_fea\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0Hqe7syGFuGC",
        "outputId": "b89570ce-73b6-45c8-a01a-77a30ca41ce5"
      },
      "source": [
        "'''## use stem instead of word\n",
        "\n",
        "data = data.rename(columns={'word': 'dummy', 'stem': 'word'})\n",
        "data_tr = data_tr.rename(columns={'word': 'dummy', 'stem': 'word'})\n",
        "data_te = data_te.rename(columns={'word': 'dummy', 'stem': 'word'})\n",
        "\n",
        "def strip(data):\n",
        "  for i , row in data.iterrows():\n",
        "    data.at[i, 'word']=araby.strip_diacritics (  data.at[i, 'word'])\n",
        "  return data\n",
        "\n",
        "\n",
        "data_tr=strip(data_tr)\n",
        "data_te=strip(data_te)\n",
        "data=strip(data)\n",
        "\n",
        "!pip install pyarabic\n",
        "import pyarabic.araby as araby\n",
        "\n",
        "## use Diac instead of word\n",
        "data = data.rename(columns={'word': 'dummy', 'diac': 'word'})\n",
        "data_tr = data_tr.rename(columns={'word': 'dummy', 'diac': 'word'})\n",
        "data_te = data_te.rename(columns={'word': 'dummy', 'diac': 'word'})\n",
        "\n",
        "def fill(data):\n",
        "  for i , row in data.iterrows():\n",
        "    if(type (data.at[i,'word'])==float):\n",
        "      data.at[i, 'word']='؛'\n",
        "  return data\n",
        "\n",
        "\n",
        "\n",
        "data_tr=fill(data_tr)\n",
        "data_te=fill(data_te)\n",
        "data=fill(data)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef strip(data):\\n  for i , row in data.iterrows():\\n    data.at[i, 'word']=araby.strip_diacritics (  data.at[i, 'word'])\\n  return data\\n\\n\\ndata_tr=strip(data_tr)\\ndata_te=strip(data_te)\\ndata=strip(data)\""
            ]
          },
          "execution_count": 47,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wToRIAs4xPH"
      },
      "source": [
        "#create model ## test charcter embedidings\n",
        "def create_model(lstm_units, embedding_dropout, lstm_dropout,activation_function, optimizer, \n",
        "                 dense_dropout , second_layer, dense_units, variational_dropout,):\n",
        "\n",
        "  ##word input \n",
        "  '''if (emb_size==1):\n",
        "    word_input = Input(shape=(sent_len,),name='word_input') ##sent_len is sentence length \n",
        "    embeddings=Embedding(input_dim=len(words) + 1, output_dim=20,)(word_input)\n",
        "  else:\n",
        "    word_input = Input(shape=(sent_len,emb_size,),name='word_input') ##sent_len is sentence length \n",
        "    embeddings=word_input'''\n",
        "\n",
        "  '''\n",
        "  ##Feature input \n",
        "  if (use_features):\n",
        "    feature_input = Input(shape=(sent_len,max_fea_len,),name='feature_input')\n",
        "    embeddings = concatenate([embeddings, feature_input])\n",
        "\n",
        "  ## Character embedding\n",
        "  if (character_embedding  is Char_type.LSTM):\n",
        "    char_input = Input(shape=(sent_len, char_len,),name='char_input')\n",
        "    emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2 , output_dim=25, \n",
        "                              input_length=char_len))(char_input)\n",
        "    char_enc = TimeDistributed(LSTM(units=25, return_sequences=False, \n",
        "                                    recurrent_dropout=0.5))(emb_char)\n",
        "    embeddings = concatenate([embeddings, char_enc])'''\n",
        "\n",
        "  if (character_embedding  is Char_type.CNN):\n",
        "    char_input=Input(shape=(sent_len,char_len,1,),name='char_input')\n",
        "    emb_char=TimeDistributed(Embedding(input_dim=n_chars + 2,output_dim=16,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(char_input)\n",
        "    conv2d_out= TimeDistributed(Conv2D(kernel_size=3, filters=50, padding='same',activation='tanh', strides=1))(emb_char)\n",
        "    maxpool_out=TimeDistributed(MaxPooling2D(1))(conv2d_out)\n",
        "    char_enc = TimeDistributed(Flatten())(maxpool_out)\n",
        "    #embeddings = concatenate([embeddings, char_enc])\n",
        "\n",
        "  ##dropout layer on embedding layer\n",
        "  #model= Dropout(embedding_dropout, trainable = variational_dropout)(embeddings)\n",
        "  model= Dropout(embedding_dropout, trainable = variational_dropout)(char_enc)\n",
        "\n",
        "\n",
        "  ## 2 bidirectional LSTM layers \n",
        "  model = Bidirectional(LSTM(units=lstm_units, \n",
        "                            return_sequences=True, \n",
        "                            dropout=lstm_dropout, \n",
        "                            recurrent_dropout=lstm_dropout, \n",
        "                            kernel_initializer=keras.initializers.he_normal()))(model)\n",
        "  if (second_layer):\n",
        "    model = (LSTM(units=lstm_units*2 , \n",
        "                            return_sequences=True, \n",
        "                            dropout=lstm_dropout,\n",
        "                            recurrent_dropout=lstm_dropout, \n",
        "                            kernel_initializer=keras.initializers.he_normal()))(model)\n",
        "\n",
        "\n",
        "  model = TimeDistributed(Dense(dense_units, activation=activation_function))(model)  # previously softmax output layer\n",
        "  model= Dropout(dense_dropout)(model)\n",
        "  '''if (use_features):\n",
        "    feature_input = Input(shape=(sent_len,max_fea_len,),name='feature_input')\n",
        "    model = concatenate([model, feature_input])'''\n",
        "  ##CRF layer\n",
        "  crf = CRF(9)  \n",
        "  out = crf(model) \n",
        "\n",
        "  '''\n",
        "  if (use_features and character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "      inputs = [word_input,char_input, feature_input]\n",
        "  elif (character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "      inputs = [word_input,char_input]\n",
        "  elif (use_features):\n",
        "      inputs = [word_input,feature_input]\n",
        "  else:\n",
        "    inputs = word_input'''\n",
        "\n",
        "  ##compile model \n",
        "  #model = Model(inputs, out)\n",
        "  model = Model(char_input, out)\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss=crf.loss_function, metrics=[crf.accuracy, \"accuracy\"])\n",
        "  model.summary()\n",
        "\n",
        "\n",
        " \n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model, batch, epochs,validation_split, callbacks_list):\n",
        "  if (use_features and character_embedding  is Char_type.LSTM ):\n",
        "    history = model.fit([np.array(X_train), np.array(X_char_tr), np.array(X_fea_tr)],\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "  elif (character_embedding is Char_type.LSTM):\n",
        "    history = model.fit([np.array(X_train), np.array(X_char_tr)],\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "  elif (use_features and character_embedding  is Char_type.CNN ):\n",
        "    history = model.fit([np.array(X_train), np.array(X_char_tr).reshape(len(X_char_tr), sent_len, char_len, 1), np.array(X_fea_tr)],\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "  elif (character_embedding is Char_type.CNN):\n",
        "    #history = model.fit([np.array(X_train), np.array(X_char_tr).reshape(len(X_char_tr), sent_len, char_len, 1)],\n",
        "    history = model.fit( np.array(X_char_tr).reshape(len(X_char_tr), sent_len, char_len, 1),\n",
        "\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "    \n",
        "  elif (use_features):\n",
        "    history = model.fit([np.array(X_train), np.array(X_fea_tr)],\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "  else:\n",
        "\n",
        "    history = model.fit(np.array(X_train),\n",
        "                        np.array(Y_train),\n",
        "                        batch_size=batch,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=validation_split,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks_list)\n",
        "    \n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i])\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "\n",
        "def eval_model(model):\n",
        "  if (use_features and character_embedding  is Char_type.LSTM):\n",
        "    test_pred = model.predict([np.array(X_test), np.array(X_char_te), np.array(X_fea_te) ], verbose=1)   \n",
        "\n",
        "  elif (character_embedding  is Char_type.LSTM):\n",
        "    test_pred = model.predict([np.array(X_test), np.array(X_char_te) ], verbose=1)\n",
        "\n",
        "  elif (use_features and character_embedding  is Char_type.CNN):\n",
        "    test_pred = model.predict([np.array(X_test), np.array(X_char_te).reshape(len(X_char_te), sent_len, char_len, 1), np.array(X_fea_te) ], verbose=1)   \n",
        "\n",
        "  elif (character_embedding  is  Char_type.CNN):\n",
        "    #test_pred = model.predict([np.array(X_test), np.array(X_char_te).reshape(len(X_char_te), sent_len, char_len, 1) ], verbose=1)   \n",
        "    test_pred = model.predict(np.array(X_char_te).reshape(len(X_char_te), sent_len, char_len, 1) , verbose=1)   \n",
        "\n",
        "  elif (use_features):\n",
        "    test_pred = model.predict([np.array(X_test), np.array(X_fea_te) ], verbose=1)   \n",
        "\n",
        "  else:\n",
        "    test_pred = model.predict(np.array(X_test), verbose=1)   \n",
        "  pred_labels = pred2label(test_pred)\n",
        "  test_labels = pred2label(Y_test)\n",
        "  results=[]\n",
        "  results+=[round(precision_score(test_labels, pred_labels)*100, 2)]\n",
        "  results+=[round(recall_score(test_labels, pred_labels)*100, 2)]\n",
        "  results+=[round(f1_score(test_labels, pred_labels)*100, 2)]\n",
        "  return(results)\n",
        "  #classification_report(test_labels, pred_labels)\n",
        "\n",
        "\n",
        "X_embeddings= X_char\n",
        "embedding_name='char'\n",
        "random_split=False\n",
        "use_features=False\n",
        "character_embedding =Char_type(\"CNN\")\n",
        "for b in [ \"\"]:\n",
        "  if b==\"\":\n",
        "    X_char, n_chars=char(X_words)\n",
        "  if b==\"all\":\n",
        "    X_char, n_chars =char1(X_words)\n",
        "\n",
        "if (use_features and character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (use_features):\n",
        "  X_train, X_test, Y_train, Y_test, X_fea_tr, X_fea_te, emb_size=split(X_embeddings)\n",
        "\n",
        "elif (character_embedding  in [Char_type.LSTM, Char_type.CNN]):\n",
        "  X_train, X_test, Y_train, Y_test, X_char_tr, X_char_te, emb_size=split(X_embeddings)\n",
        "\n",
        "else:\n",
        "  X_train, X_test, Y_train, Y_test, emb_size=split(X_embeddings)\n",
        "\n",
        "\n",
        "#model= load_model(\"w.h5\", \"params.json\")\n",
        "#eval_model(model)\n",
        "\n",
        "lstm_units=500\n",
        "activation_function=\"relu\"\n",
        "embedding_dropout=0.3\n",
        "lstm_dropout=0.5\n",
        "optimizer=\"nadam\"\n",
        "dense_dropout=0.3\n",
        "second_layer=False\n",
        "dense_units=100\n",
        "val=0.0\n",
        "batch_size=8\n",
        "epochs=1\n",
        "variational_dropout= False\n",
        "\n",
        "for i in [0]:\n",
        "\n",
        "  df1= experiment(40, False, \"CharCNN_50\", epochs) ## experiment ( number of runs, repeate runs or increase epochs , name of csv file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I8p8LWyB-34"
      },
      "source": [
        "## first x digits of arabert, it lead to the same performance\n",
        "X_arabert1 = [[[round(num, 4) for num in word]for word in sent] for sent in X_arabert]\n",
        "X_arabert1 =np.array(X_arabert1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmtSOHJCF5k0"
      },
      "source": [
        "`#fine tune arabertlargev02 with features_2019 and CNN, sent_len = 256\n",
        "#for lstm_units in [50, 100, 150, 200, 250, 300, 350, 400, 450, 500(), 550, 600, 650, 700, 750, 800, 750, 900]\n",
        "#for optimizer in [\"adam\", \"nadam\", \"adagrad\", \"adamax\", \"RMSprop\", \"adadelta\"]\n",
        "#for activation_function in [\"relu\", \"tanh\", \"softplus\", \"linear\", \"softsign\", \"hard_sigmoid\"]:\n",
        "#for embedding_dropout in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
        "#for lstm_dropout in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
        "#for dense_dropout in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
        "#for dense_units in [10,32,64,100,150,200, 500]:\n",
        "for val in [0, 0.05, 0.11111111, 0.15, 0.2, 0.25 ]:\n",
        "#for batch_size in [8, 16, 32, 64]:\n",
        "\n",
        "\n",
        "#sentence length fix length \n",
        "#epochs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIvZUOzopZKa"
      },
      "source": [
        "##================================== =========================== Features =========================== =====================================\n",
        "## values of attributes grouped\n",
        "\n",
        "max_fea_len=60\n",
        "'''\n",
        "pos_values= list(set(data['pos'].values))\n",
        "cas_values = list(set(data[\"cas\"].values))\n",
        "enc0_values = list(set(data[\"enc0\"].values))\n",
        "stt_values = list(set(data[\"stt\"].values))\n",
        "num_values = list(set(data[\"num\"].values))\n",
        "gen_values = list(set(data[\"gen\"].values))\n",
        "vox_values = list(set(data[\"vox\"].values))\n",
        "asp_values = list(set(data[\"asp\"].values))\n",
        "per_values = list(set(data[\"per\"].values))\n",
        "prc0_values = list(set(data[\"prc0\"].values))\n",
        "prc1_values = list(set(data[\"prc1\"].values))\n",
        "prc2_values = list(set(data[\"prc2\"].values))\n",
        "prc3_values = list(set(data[\"prc3\"].values))\n",
        "mod_values = list(set(data[\"mod\"].values))'''\n",
        "\n",
        "def embed_pos(value):\n",
        "  if value in ['part_fut', 'part_neg', 'part_interrog', 'part_verb', 'part_focus', 'part_det','part','part_voc']:\n",
        "    hot_idx=0\n",
        "  elif value in [ 'pron_rel', 'pron_interrog', 'pron_exclam', 'pron', 'pron_dem']:\n",
        "    hot_idx=1\n",
        "  elif value in ['abbrev', 'adv_rel', 'adv_interrog', 'adv' ]:\n",
        "    hot_idx=2\n",
        "  elif value in ['verb', 'verb_pseudo' ]:\n",
        "    hot_idx=3\n",
        "  elif value in ['conj_sub', 'conj', 'interj']:\n",
        "    hot_idx=4\n",
        "  elif value in ['noun_prop' ]:\n",
        "    hot_idx=5\n",
        "  elif value in [ 'noun']:\n",
        "    hot_idx=6\n",
        "  elif value in [ 'punc' ]:\n",
        "    hot_idx=7\n",
        "  elif value in [ 'digit' ]:\n",
        "    hot_idx=8\n",
        "  elif value in [ 'prep']:\n",
        "    hot_idx=9\n",
        "  elif value in [ 'noun_quant']:\n",
        "    hot_idx=10\n",
        "  elif value in [ 'adj']:\n",
        "    hot_idx=11\n",
        "  elif value in ['abbrev' ]:\n",
        "    hot_idx=12\n",
        "  else:\n",
        "    return np.zeros(13).tolist()\n",
        "  return one_hot(hot_idx, 13 )\n",
        "\n",
        "def embed_enc0(value):\n",
        "  if value in ['0']:\n",
        "    hot_idx=0\n",
        "  elif value in [ 'na']:\n",
        "    hot_idx=1\n",
        "  elif value in [  '1p_dobj' , '1p_poss','1s_pron', '1s_poss', '1p_pron','1s_dobj' ]:             \n",
        "    hot_idx=2\n",
        "  elif value in ['3mp_pron', '3ms_poss', '3ms_pron', '3d_poss','3fp_poss' ,'3fs_poss',\n",
        "                 '3d_dobj', '3fs_pron', '3mp_poss', '3fp_pron', '3d_pron', '3mp_dobj',\n",
        "                 '3ms_dobj', '3fp_dobj', '3fs_dobj']:\n",
        "    hot_idx=3\n",
        "  elif value in [ '2mp_poss', '2fs_poss', '2ms_poss', '2fp_poss', '2ms_pron', '2fs_pron',\n",
        "                  '2ms_dobj', '2fs_dobj', '2mp_dobj', '2mp_pron',]:\n",
        "    hot_idx=4\n",
        "  elif value in ['mA_sub', 'mA_rel', 'lA_neg', 'man_rel', 'ma_interrog' ]:\n",
        "    hot_idx=5\n",
        "  else:\n",
        "    return np.zeros(6).tolist()\n",
        "  return one_hot(hot_idx, 6)\n",
        "\n",
        "def embed_stt(value):\n",
        "  out=np.zeros(4)\n",
        "  idx= ['i', 'c', 'd', 'na'].index(value)\n",
        "  out[idx]=1\n",
        "  return out.tolist()\n",
        "\n",
        "def embed_num(value):\n",
        "  out=np.zeros(4)\n",
        "  idx= ['p', 's', 'd', 'na'].index(value)\n",
        "  out[idx]=1\n",
        "  return out.tolist()\n",
        "\n",
        "def embed_per(value):\n",
        "  out=np.zeros(4)\n",
        "  idx= ['1', '2', '3', 'na'].index(value)\n",
        "  out[idx]=1\n",
        "  return out.tolist()\n",
        "\n",
        "def embed_gen(value):\n",
        "  out=np.zeros(3)\n",
        "  idx= ['f', 'm', 'na'].index(value)\n",
        "  out[idx]=1\n",
        "  return out.tolist()\n",
        "  return one_hot(value, ) \n",
        "\n",
        "def embed_prc0(value):\n",
        "  if value in ['0']:\n",
        "    hot_idx=0\n",
        "  elif value in ['Al_det']:\n",
        "    hot_idx=1\n",
        "  elif value in ['mA_rel']:\n",
        "    hot_idx=2\n",
        "  elif value in ['na' ]:\n",
        "    hot_idx=3\n",
        "  elif value in ['lA_neg' ]:\n",
        "    hot_idx=4\n",
        "  elif value in ['mA_neg' ]:\n",
        "    hot_idx=5\n",
        "  else:\n",
        "    return np.zeros(6).tolist()\n",
        "  return one_hot(hot_idx, 6)\n",
        "\n",
        "def embed_prc1(value):\n",
        "  if value in ['0']:\n",
        "    hot_idx=0\n",
        "  elif value in [ 'sa_fut']:\n",
        "    hot_idx=1\n",
        "  elif value in ['ka_prep' ]:\n",
        "    hot_idx=2\n",
        "  elif value in ['na' ]:\n",
        "    hot_idx=3\n",
        "  elif value in ['la_rc']:\n",
        "    hot_idx=4\n",
        "  elif value in ['la_emph']:\n",
        "    hot_idx=5\n",
        "  elif value in ['li_prep' ]:\n",
        "    hot_idx=6\n",
        "  elif value in ['bi_prep' ]:\n",
        "    hot_idx=7\n",
        "  else:\n",
        "    return np.zeros(8).tolist()\n",
        "  return one_hot(hot_idx, 8)\n",
        "\n",
        "def embed_prc2(value):\n",
        "  if value in ['0']:\n",
        "    hot_idx=0\n",
        "  elif value in [ 'wa_part', 'wa_sub', 'wa_conj', 'fa_conj']:\n",
        "    hot_idx=1\n",
        "  elif value in ['na' ]:\n",
        "    hot_idx=2\n",
        "  else:\n",
        "    return np.zeros(3).tolist()\n",
        "  return one_hot(hot_idx, 3)\n",
        "\n",
        "def embed_prc3(value):\n",
        "  if value in ['0']:\n",
        "    hot_idx= 0\n",
        "  elif value in [ '>a_ques']:\n",
        "    hot_idx= 1\n",
        "  elif value in ['na' ]:\n",
        "    hot_idx= 2\n",
        "  else:\n",
        "    return np.zeros(3).tolist()\n",
        "  return one_hot(hot_idx, 3)\n",
        "    \n",
        "\n",
        "def embed_cas(value):\n",
        "  if value in ['na']:\n",
        "    hot_idx= 0\n",
        "  elif value in ['n']:\n",
        "    hot_idx= 1\n",
        "  elif value in ['u']:\n",
        "    hot_idx= 2\n",
        "  elif value in ['a']:\n",
        "    hot_idx= 3\n",
        "  elif value in ['g']:\n",
        "    hot_idx= 4\n",
        "  else:\n",
        "    return np.zeros(5).tolist()\n",
        "  return one_hot(hot_idx, 5)\n",
        "\n",
        "def one_hot( value, size):\n",
        "  x=np.zeros(size)\n",
        "  x[value]=1\n",
        "  return x.tolist()\n",
        "\n",
        "\n",
        "def features( X_words):\n",
        "  X_fea = []\n",
        "  i=0\n",
        "  idx=0\n",
        "  while i<len(X_words):\n",
        "    sent_seq = []\n",
        "    j=0\n",
        "    sent=X_words[i]\n",
        "    while (j<len(sent)):\n",
        "      word=sent[j]\n",
        "      if (word==\"ENDPAD\"):\n",
        "        feature_vector = np.zeros(max_fea_len)\n",
        "      else:\n",
        "        feature_vector=[]\n",
        "        feature_vector+= embed_pos(data.at[idx,'pos'])\n",
        "        feature_vector+= embed_enc0(data.at[idx,'enc0'])\n",
        "        feature_vector+= embed_stt(data.at[idx,'stt'])\n",
        "        feature_vector+= embed_num(data.at[idx,'num'])\n",
        "        feature_vector+= embed_gen(data.at[idx,'gen'])\n",
        "        feature_vector+= embed_prc0(data.at[idx,'prc0'])\n",
        "        feature_vector+= embed_prc1(data.at[idx,'prc1'])\n",
        "        feature_vector+= embed_prc2(data.at[idx,'prc2'])\n",
        "        feature_vector+= embed_prc3(data.at[idx,'prc3'])\n",
        "        feature_vector+= embed_per(data.at[idx,'per'])\n",
        "        feature_vector+= embed_cas(data.at[idx, 'cas'])\n",
        "        try:\n",
        "          if(data.at[idx,\"gloss\"][0].isupper()):\n",
        "            feature_vector+=[1.0]\n",
        "          else:\n",
        "            feature_vector+=[0.0]\n",
        "        except:\n",
        "          feature_vector+=[0.0]\n",
        "        idx+=1\n",
        "      sent_seq.append(feature_vector)\n",
        "      j+=1\n",
        "      \n",
        "    X_fea.append(sent_seq)\n",
        "    i+=1\n",
        "  \n",
        "  print(np.shape(X_fea))\n",
        "  return X_fea\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9i5w9raHrMy"
      },
      "source": [
        "max_fea_len=20\n",
        "\n",
        "def features0( X_words):\n",
        "  X_fea = []\n",
        "  i=0\n",
        "  idx=0\n",
        "  while i<len(X_words):\n",
        "    sent_seq = []\n",
        "    j=0\n",
        "    sent=X_words[i]\n",
        "    while (j<len(sent)):\n",
        "      word=sent[j]\n",
        "      if (word==\"ENDPAD\"):\n",
        "        feature_vector = np.zeros(max_fea_len)\n",
        "      else:\n",
        "        feature_vector=[]\n",
        "        feature_vector+= embed_pos(data.at[idx,'pos'])\n",
        "        feature_vector+= embed_enc0(data.at[idx,'enc0'])\n",
        "        #feature_vector+= embed_stt(data.at[idx,'stt'])\n",
        "        #feature_vector+= embed_num(data.at[idx,'num'])\n",
        "        #feature_vector+= embed_gen(data.at[idx,'gen'])\n",
        "        #feature_vector+= embed_prc0(data.at[idx,'prc0'])\n",
        "        #feature_vector+= embed_prc1(data.at[idx,'prc1'])\n",
        "        #feature_vector+= embed_prc2(data.at[idx,'prc2'])\n",
        "        #feature_vector+= embed_prc3(data.at[idx,'prc3'])\n",
        "        #feature_vector+= embed_per(data.at[idx,'per'])\n",
        "        #feature_vector+= embed_cas(data.at[idx, 'cas'])\n",
        "        try:\n",
        "          if(data.at[idx,\"gloss\"][0].isupper()):\n",
        "            feature_vector+=[1.0]\n",
        "          else:\n",
        "            feature_vector+=[0.0]\n",
        "        except:\n",
        "          feature_vector+=[0.0]\n",
        "        idx+=1\n",
        "      sent_seq.append(feature_vector)\n",
        "      j+=1\n",
        "      \n",
        "    X_fea.append(sent_seq)\n",
        "    i+=1\n",
        "  \n",
        "  print(np.shape(X_fea))\n",
        "  return X_fea\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG07gRN_nNgc"
      },
      "source": [
        "##================================== =========================== Features Separated =========================== =====================================\n",
        "\n",
        "##================================== =========================== Quote Features =========================== =====================================\n",
        "\n",
        "\n",
        "max_fea_len=2\n",
        "quote1 =['«', '\"', '(']\n",
        "quote2 =['»', '\"', ')']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def features_quo( X_words):\n",
        "  X_fea = []\n",
        "  i=0\n",
        "  idx=0\n",
        "  add_quote = False\n",
        "  quote_count = 0\n",
        "  quote_index=-1\n",
        "  even_flag=True, True, True ##to assure the second quote is not considered\n",
        "  while i<len(X_words):\n",
        "    sent_seq = []\n",
        "    j=0\n",
        "    sent=X_words[i]\n",
        "    while (j<len(sent)):\n",
        "      word=sent[j]\n",
        "      if (word==\"ENDPAD\"):\n",
        "        feature_vector = np.zeros(max_fea_len)\n",
        "      else:\n",
        "        feature_vector=[]\n",
        "        idx+=1\n",
        "        ##quote feature\n",
        "        if add_quote :   ## add values\n",
        "          feature_vector+= [quote_index+1]\n",
        "          feature_vector+= [quote_count]\n",
        "          quote_count -= 1\n",
        "        else:\n",
        "          feature_vector+=[0,0]\n",
        "\n",
        "        if not add_quote and word in quote1: # check if words are between quotes\n",
        "          quote_index= quote1.index(word)\n",
        "          if (even_flag or word!='\"'):\n",
        "            for k in [1,2,3,4]:\n",
        "              try:\n",
        "                if sent[i+k] == quote2[quote_index]:\n",
        "                  add_quote= True\n",
        "                  quote_count=4\n",
        "                  break\n",
        "              except:\n",
        "                add_quote= False\n",
        "          if (word =='\"'):  #to avoid the second quote\n",
        "            even_flag= not even_flag\n",
        "             \n",
        "        if (quote_count ==1): #stop adding values\n",
        "          add_quote = False\n",
        "      sent_seq.append(feature_vector)\n",
        "      j+=1\n",
        "      \n",
        "    X_fea.append(sent_seq)\n",
        "    i+=1\n",
        "  \n",
        "  print(np.shape(X_fea))\n",
        "  return X_fea\n",
        "\n",
        "\n",
        "\n",
        "##================================== =========================== Language analysis Feature =========================== =====================================\n",
        "\n",
        "\n",
        "max_fea_len=91\n",
        "def features_analysis( X_words):\n",
        "  X_fea = []\n",
        "  i=0\n",
        "  idx=0\n",
        "  while i<len(X_words):\n",
        "    sent_seq = []\n",
        "    j=0\n",
        "    sent=X_words[i]\n",
        "    while (j<len(sent)):\n",
        "      word=sent[j]\n",
        "      if (word==\"ENDPAD\"):\n",
        "        feature_vector = np.zeros(max_fea_len)\n",
        "      else:\n",
        "        feature_vector=[]\n",
        "        feature_vector+= one_hot1(data.at[idx,'enc0'], enc0_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'stt'], stt_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'num'], num_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'gen'], gen_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'prc0'], prc0_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'prc1'], prc1_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'prc2'], prc2_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'prc3'], prc3_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'per'], per_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'vox'], vox_values)\n",
        "        feature_vector+= one_hot1(data.at[idx,'asp'], asp_values)\n",
        "        feature_vector+= one_hot1(data.at[idx, 'cas'], cas_values)\n",
        "        feature_vector+= one_hot1(data.at[idx, 'mod'], mod_values)\n",
        "        idx+=1\n",
        "      sent_seq.append(feature_vector)\n",
        "      j+=1\n",
        "      \n",
        "    X_fea.append(sent_seq)\n",
        "    i+=1\n",
        "  \n",
        "  print(np.shape(X_fea))\n",
        "  return X_fea\n",
        "\n",
        "\n",
        "\n",
        "def one_hot1( value, list):\n",
        "  x=np.zeros(len(list))\n",
        "  idx= list.index(value)\n",
        "  x[idx]=1\n",
        "  return x.tolist()\n",
        "\n",
        "pos_values= ['pron_interrog', 'part_fut', 'punc', 'part', 'noun', 'adv', 'interj', 'verb', 'conj_sub', 'adv_interrog', 'noun_prop', 'verb_pseudo', 'part_focus', 'part_interrog', 'conj', 'adj', 'part_voc', 'digit', 'abbrev', 'pron', 'pron_rel', 'part_det', 'part_neg', 'part_verb', 'prep', 'pron_dem', 'adv_rel', 'pron_exclam', 'noun_quant']\n",
        "cas_values= ['na', 'n', 'u', 'a', 'g']\n",
        "enc0_values= ['3fp_poss', '3fp_pron', '2mp_poss', 'mA_sub', '3mp_pron', '3ms_dobj', '1s_dobj', '2ms_poss', '1s_pron', '3d_dobj', '1p_dobj', '2ms_pron', '3mp_dobj', '1p_poss', 'ma_interrog', '2fs_pron', '2mp_dobj', '2ms_dobj', 'man_rel', '3ms_poss', '3mp_poss', '3d_poss', '3fs_dobj', '3fs_poss', '2fp_poss', '1p_pron', 'mA_rel', 'lA_neg', '3d_pron', 'na', '2fs_poss', '3ms_pron', '1s_poss', '2fs_dobj', '0', '3fp_dobj', '3fs_pron', '2mp_pron']\n",
        "stt_values= ['c', 'i', 'd', 'na']\n",
        "num_values= ['d', 'p', 'na', 's']\n",
        "gen_values= ['f', 'm', 'na']\n",
        "vox_values= ['a', 'p', 'na']\n",
        "asp_values= ['c', 'i', 'p', 'na']\n",
        "per_values= ['1', '3', 'na', '2']\n",
        "prc0_values= ['mA_rel', 'mA_neg', 'lA_neg', 'na', 'Al_det', '0']\n",
        "prc1_values= ['na', 'ka_prep', 'bi_prep', 'li_prep', 'la_emph', '0', 'la_rc', 'sa_fut']\n",
        "prc2_values = ['na', 'wa_sub', 'wa_conj', 'wa_part', 'fa_conj', '0']\n",
        "prc3_values= ['>a_ques', '0', 'na']\n",
        "mod_values= ['i', 'na', 'u']\n",
        "\n",
        "##================================== =========================== POS Feature =========================== =====================================\n",
        "\n",
        "\n",
        "max_fea_len=29\n",
        "def features_pos( X_words):\n",
        "  X_fea = []\n",
        "  i=0\n",
        "  idx=0\n",
        "  while i<len(X_words):\n",
        "    sent_seq = []\n",
        "    j=0\n",
        "    sent=X_words[i]\n",
        "    while (j<len(sent)):\n",
        "      word=sent[j]\n",
        "      if (word==\"ENDPAD\"):\n",
        "        feature_vector = np.zeros(max_fea_len)\n",
        "      else:\n",
        "        feature_vector=[]\n",
        "        feature_vector+= one_hot1(data.at[idx,'pos'], pos_values)\n",
        "        idx+=1\n",
        "      sent_seq.append(feature_vector)\n",
        "      j+=1\n",
        "      \n",
        "    X_fea.append(sent_seq)\n",
        "    i+=1\n",
        "  \n",
        "  print(np.shape(X_fea))\n",
        "  return X_fea\n",
        "\n",
        "\n",
        "\n",
        "def one_hot1( value, list):\n",
        "  x=np.zeros(len(list))\n",
        "  idx= list.index(value)\n",
        "  x[idx]=1\n",
        "  return x.tolist()\n",
        "\n",
        "pos_values= ['pron_interrog', 'part_fut', 'punc', 'part', 'noun', 'adv', 'interj', 'verb', 'conj_sub', 'adv_interrog', 'noun_prop', 'verb_pseudo', 'part_focus', 'part_interrog', 'conj', 'adj', 'part_voc', 'digit', 'abbrev', 'pron', 'pron_rel', 'part_det', 'part_neg', 'part_verb', 'prep', 'pron_dem', 'adv_rel', 'pron_exclam', 'noun_quant']\n",
        "\n",
        "\n",
        "##================================== =========================== Capitalization Feature =========================== =====================================\n",
        "\n",
        "\n",
        "max_fea_len=1\n",
        "def features_cap( X_words):\n",
        "  X_fea = []\n",
        "  i=0\n",
        "  idx=0\n",
        "  while i<len(X_words):\n",
        "    sent_seq = []\n",
        "    j=0\n",
        "    sent=X_words[i]\n",
        "    while (j<len(sent)):\n",
        "      word=sent[j]\n",
        "      if (word==\"ENDPAD\"):\n",
        "        feature_vector = np.zeros(max_fea_len)\n",
        "      else:\n",
        "        feature_vector=[]\n",
        "        try:\n",
        "          if(data.at[idx,\"gloss\"][0].isupper()):\n",
        "            feature_vector+=[1.0]\n",
        "          else:\n",
        "            feature_vector+=[0.0]\n",
        "        except:\n",
        "          feature_vector+=[0.0]\n",
        "        idx+=1\n",
        "      sent_seq.append(feature_vector)\n",
        "      j+=1\n",
        "      \n",
        "    X_fea.append(sent_seq)\n",
        "    i+=1\n",
        "  \n",
        "  print(np.shape(X_fea))\n",
        "  return X_fea\n",
        "\n",
        "\n",
        "#max_fea_len = 29    ## 123 for all, 1 for cap, 2 for quote, 29 for pos, 91 for analysis\n",
        "#X_fea=features_pos(X_words)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23eVruhwy-ZO"
      },
      "source": [
        "def fill_gaps(test_labels): ## fill gaps in entities\n",
        "  count=0\n",
        "  i=0\n",
        "  while i<len(test_labels):\n",
        "    j=0\n",
        "    while j < len(test_labels[i]): \n",
        "      if 'I-' in test_labels[i][j] and test_labels[i][j-1] =='O':\n",
        "        test_labels[i][j-1] = test_labels[i][j]\n",
        "        count+=1\n",
        "      j+=1\n",
        "    i+=1\n",
        "  if (count!= 0):\n",
        "    test_labels =fill_gaps(test_labels)\n",
        "  return test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2dfX2hopRjo"
      },
      "source": [
        "###================ evaluation method ===============\n",
        "#this method evaluate all NEs, hocwver results are different by a small margin\n",
        "\n",
        "def evaluate(test_labels, pred_labels):\n",
        "  i=0 # loop on sentences\n",
        "  TP=[0,0,0,0]\n",
        "  FN=[0,0,0,0]\n",
        "  FP=[0,0,0,0]\n",
        "  FPC=[0,0,0,0] # FPC is entities that are not FP, they should equal TP but they are not as there is a condition that is not handeled\n",
        "               #to do : add the difference between FPC and TP to FP.\n",
        "\n",
        "  classes = ['PERS', 'LOC', 'ORG', 'MISC']\n",
        "  i=0\n",
        "  while i < len(test_labels):\n",
        "    j=0 # loop on tokens\n",
        "    while j < len (test_labels[i]):\n",
        "      if('B-'in test_labels[i][j]):\n",
        "        class_name= test_labels[i][j] [2:]\n",
        "        while (True):\n",
        "          if (test_labels[i][j] != pred_labels[i][j]):\n",
        "            j+=1\n",
        "            FN[classes.index(class_name)]+=1\n",
        "            break;\n",
        "          elif class_name not in test_labels[i][j+1] or 'B-' in test_labels[i][j+1] :\n",
        "            if class_name in pred_labels[i][j+1] and 'B-' not in pred_labels[i][j+1]: \n",
        "              FN[classes.index(class_name)]+=1\n",
        "            else:\n",
        "              TP[classes.index(class_name)]+=1\n",
        "            j+=1\n",
        "            break;\n",
        "          else:\n",
        "            j+=1\n",
        "      else:\n",
        "        j+=1\n",
        "    i+=1\n",
        "\n",
        "\n",
        "  i=0\n",
        "  while i < len(pred_labels):\n",
        "    j=0 # loop on tokens\n",
        "    while j < len (pred_labels[i]):\n",
        "      if('B-'in pred_labels[i][j]):\n",
        "        class_name= pred_labels[i][j] [2:]\n",
        "        while (True):\n",
        "          if (pred_labels[i][j] != test_labels[i][j]):\n",
        "            j+=1\n",
        "            FP[classes.index(class_name)]+=1\n",
        "            break;\n",
        "          elif class_name not in pred_labels[i][j+1] or 'B-' in pred_labels[i][j+1]:\n",
        "            j+=1\n",
        "            FPC[classes.index(class_name)]+=1\n",
        "\n",
        "            break;\n",
        "          else:\n",
        "            j+=1\n",
        "      else:\n",
        "        j+=1\n",
        "    i+=1\n",
        "  print('TP: ',TP)\n",
        "  print('FN: ',FN)\n",
        "  print('FP: ',FP)\n",
        "  print('FPC: ',FPC)\n",
        "\n",
        "  #recall=[sum(x) for x in zip(TP, FN)]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM1g8JjaQ6QH"
      },
      "source": [
        "\n",
        "def evaluate_one_sent(test_labels, pred_labels):\n",
        "  TP=[0,0,0,0]\n",
        "  FN=[0,0,0,0]\n",
        "  FP=[0,0,0,0]\n",
        "  FPC=[0,0,0,0]\n",
        "\n",
        "  classes = ['PERS', 'LOC', 'ORG', 'MISC']\n",
        "  j=0 # loop on tokens\n",
        "  while j < len (test_labels):\n",
        "    if('B-'in test_labels[j]):\n",
        "      class_name= test_labels[j] [2:]\n",
        "      while (True):\n",
        "        if (test_labels[j] != pred_labels[j]):\n",
        "          j+=1\n",
        "          FN[classes.index(class_name)]+=1\n",
        "          break;\n",
        "        elif class_name not in test_labels[j+1] or 'B-' in test_labels[j+1]  :\n",
        "          if class_name in pred_labels[j+1] and 'B-' not in pred_labels[j+1]: \n",
        "            FN[classes.index(class_name)]+=1\n",
        "          else:\n",
        "            TP[classes.index(class_name)]+=1\n",
        "          j+=1\n",
        "          break;\n",
        "        else:\n",
        "          j+=1\n",
        "    else:\n",
        "      j+=1\n",
        "\n",
        "  j=0 # loop on tokens\n",
        "  while j < len (pred_labels):\n",
        "    if('B-'in pred_labels[j]):\n",
        "      class_name= pred_labels[j] [2:]\n",
        "      while (True):\n",
        "        if (pred_labels[j] != test_labels[j]):\n",
        "          j+=1\n",
        "          FP[classes.index(class_name)]+=1\n",
        "          break;\n",
        "        elif class_name not in pred_labels[j+1] or 'B-' in pred_labels[j+1]  :\n",
        "          j+=1\n",
        "          FPC[classes.index(class_name)]+=1\n",
        "          break;\n",
        "        else:\n",
        "          j+=1\n",
        "    else:\n",
        "      j+=1\n",
        "\n",
        "  return TP, FN, FP, FPC\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "TP, FN =evaluate_one_sent(test_labels[0][0:36], pred_labels[0][0:36])\n",
        "counted_entities=[sum(x) for x in zip(TP, FN)]\n",
        "print(counted_entities)\n",
        "\n",
        "i=0\n",
        "j=0\n",
        "while j < len(test_labels[i]) :\n",
        "  print(test_labels[i][j], pred_labels[i][j])\n",
        "  j+=1\n",
        "\n",
        "  actual_entities =[0,0,0,0]\n",
        "i=0\n",
        "while i <len(test_labels):\n",
        "  actual_entities_temp =[0,0,0,0]\n",
        "  for tag in pred_labels[i]:\n",
        "      if(tag in ['B-PERS', 'B-LOC', 'B-ORG', 'B-MISC']):\n",
        "        actual_entities_temp[classes.index(tag[2:])]+=1\n",
        "  actual_entities=[sum(x) for x in zip(actual_entities, actual_entities_temp)]\n",
        "\n",
        "  \n",
        "  i+=1\n",
        "\n",
        "\n",
        "  i=0\n",
        "count=0\n",
        "FP_all=[0,0,0,0]\n",
        "FPC_all=[0,0,0,0]\n",
        "\n",
        "while i <len(test_labels):\n",
        "  \n",
        "  TP, FN, FP, FPC =evaluate_one_sent(test_labels[i], pred_labels[i])\n",
        "  counted_entities=[sum(x) for x in zip(FP, FPC)]\n",
        "  FP_all=[sum(x) for x in zip(FP_all, FP)]\n",
        "  FPC_all=[sum(x) for x in zip(FPC_all, FPC)]\n",
        "\n",
        "\n",
        "  actual_entities =[0,0,0,0]\n",
        "  for tag in pred_labels[i]:\n",
        "    if(tag in ['B-PERS', 'B-LOC', 'B-ORG', 'B-MISC']):\n",
        "      actual_entities[classes.index(tag[2:])]+=1\n",
        "\n",
        "  if (counted_entities !=actual_entities):\n",
        "    print(counted_entities)\n",
        "    print(actual_entities) \n",
        "    print(i) \n",
        "    print('-------------------------')\n",
        "    count+=1\n",
        "  i+=1\n",
        "\n",
        "print(count)\n",
        "print(FP_all)\n",
        "print(FPC_all)\n",
        "\n",
        "\n",
        "\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}